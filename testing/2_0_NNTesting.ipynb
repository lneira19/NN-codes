{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvh8vl7RxDXb"
      },
      "source": [
        "### Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DjguZ-4dsVNu"
      },
      "outputs": [],
      "source": [
        "# Librerías generales\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8yryE-uP2NK-"
      },
      "outputs": [],
      "source": [
        "# Librerías para entrenamiento\n",
        "\n",
        "D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D, Activation\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.constraints import MaxNorm\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC_aWT25v6UF"
      },
      "source": [
        "### Lectura de datos utilizados para el entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsvoyiTzs2Hh",
        "outputId": "03a34517-4976-4d65-b185-e03eacb33c61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/coarse_label_names.pck\n",
            "/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/x_test.npy\n",
            "/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/fine_label_names.pck\n",
            "/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/x_train.npy\n",
            "/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/y_train_fine.npy\n",
            "/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/y_train_coarse.npy\n"
          ]
        }
      ],
      "source": [
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX5tYxTOtQGf"
      },
      "outputs": [],
      "source": [
        "x_train = np.load(\"/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/x_train.npy\")\n",
        "\n",
        "y_train_fine = np.load(\"/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/y_train_fine.npy\")\n",
        "\n",
        "y_train_coarse = np.load(\"/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/y_train_coarse.npy\")\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/fine_label_names.pck\", \"rb\") as f:\n",
        "    labels_fine = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Redes Neuronales/dl-itba-cifar-100-2024-q-1/coarse_label_names.pck\", \"rb\") as f:\n",
        "    labels_coarse = pickle.load(f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVJ61Zy8t2Cj",
        "outputId": "7f1d594d-202a-44c5-e412-0060e011a6ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de x_train: (50000, 32, 32, 3)\n",
            "Dimensiones de y_train_fine: (50000,)\n",
            "Dimensiones de y_train_coarse: (50000,)\n",
            "Dimensiones de labels_fine: 100\n",
            "Dimensiones de labels_coarse: 20\n"
          ]
        }
      ],
      "source": [
        "print(f'Dimensiones de x_train: {x_train.shape}')\n",
        "print(f'Dimensiones de y_train_fine: {y_train_fine.shape}')\n",
        "print(f'Dimensiones de y_train_coarse: {y_train_coarse.shape}')\n",
        "print(f'Dimensiones de labels_fine: {len(labels_fine)}')\n",
        "print(f'Dimensiones de labels_coarse: {len(labels_coarse)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr9WlZmdEtTX",
        "outputId": "95bc23bb-a3ea-48ad-c69e-2c0e344a6539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 2)\n"
          ]
        }
      ],
      "source": [
        "y_train_union = np.array([[i,j] for i,j in zip(y_train_fine, y_train_coarse)])\n",
        "print(y_train_union.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3-JQyzoFBV-",
        "outputId": "3e7c04ca-fb5d-46e8-ba7e-5b378108e105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 2)\n"
          ]
        }
      ],
      "source": [
        "uniongonza = np.vstack([y_train_fine, y_train_coarse]).T\n",
        "print(uniongonza.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "Q2IIFCRVGMpH",
        "outputId": "c9494b58-d3c6-4c5e-85fe-4bf7450a443f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxHUlEQVR4nO3dfXTU9Z33/9fMJDNJyD0hdxIwgAKKoRWR5rKlKpSb7s/LG7qrrddV7HrpTxs9q2y3LXtaW93dK669TmvbQ/H8dl1Zz4q29hS9dFusooSfLWChUkRrChQFJAl35m6SmUxmvtcfXqaNgn7ekPBJ4vNxzpxDMi/e+Xy/35l555uZeU8oCIJAAACcYWHfCwAAfDTRgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXmT5XsB7ZTIZHTp0SAUFBQqFQr6XAwAwCoJAXV1dqq6uVjh88vOcEdeADh06pJqaGt/LAACcpgMHDmjixIknvX7YGtCqVav0ne98R62trZo9e7Z++MMf6uKLL/7Q/1dQUCBJ+vEP/0Z5uTGnnxVSxnldEeNJVTrS55wNIrbdGdY452wkHLXVzoo4ZzOBbd2B4rZ80OseTtsmQ8WS7gc0HbetO9HbYch2mmqn412mfLiz2znb15u2rSXR75zNpFKm2olu93XHD7tnJSnZ5r6W3rjtdvV2xvbsRHvU/XaYyHe/b0pSq+Exq81wLCWpN+WeT/e778NMEOhId3Lg8fxkhqUB/fjHP9aKFSv0wAMPaN68ebr//vu1ePFiNTc3q7y8/AP/77t/dsvLjWlc3khoQO7/wd6Acpyzw9uAsk21A9ke4ILA/fiYG5Dh+KQztjtnRO77PGzch+l+420l5p7Psh0epTOGBxbDfU2SQtnuD+SZiO1BPxQ23DeN9/uY8c//UUM+bVi3JGUZakeMtcOG2tZ9KOlDn0YZlhchfPe739VNN92kL33pSzrvvPP0wAMPKC8vT//2b/82HD8OADAKDXkD6uvr0/bt27Vw4cI//ZBwWAsXLtTmzZvfl08mk+rs7Bx0AQCMfUPegI4ePap0Oq2KiopB36+oqFBra+v78o2NjSoqKhq48AIEAPho8P4+oJUrV6qjo2PgcuDAAd9LAgCcAUP+IoSysjJFIhG1tbUN+n5bW5sqKyvfl4/FYorF3F5sAAAYO4b8DCgajWrOnDnasGHDwPcymYw2bNig+vr6of5xAIBRalhehr1ixQotX75cF110kS6++GLdf//9isfj+tKXvjQcPw4AMAoNSwO69tprdeTIEd11111qbW3Vxz72Ma1fv/59L0wAAHx0hYIgsL3zb5h1dnaqqKhI6//XlzXOcRJCut/wRtSw8Q2Aafc3L4aMbwBMpd3fvJgMbG+i7OtLOGf733af9iBJmZDtXfxZue7vWM8vcp8OIUmZAvfjmQzZburZWR/8Lu7B2XxT7XQkz5RPhN3ftGx646+kvr6kc7a/z3ZbCXrcpxtEjtreghG8dcQ5277/oKl2+96jpvyR1nbn7L6MbZrETsM7QPcaHgslKW14Y7Hpjb9BIAVpdXR0qLCw8KQ576+CAwB8NNGAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXgzLLLihsP2hnyvH8TPi3064jwfpMU4eChtGW2SlbB+a3t3nvpb2pPtIE0kKx9znAk2bUm6qPWPuDFO+eNI052zOBNsHEgZFxc7ZWNR9nI0kpYOoczbRb/tdri9pG5mihPv4llDKfQyTJGUl4u61e21jmHrix5yz3W8fN9Xu7+pwzvZl2Y5PrMo2KumsfPf7cknI9rDbbxhR1HHENs7oeMYwXifj/pgSKJBLmjMgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBcjdhbcsVffUizkNqfoQMh9Flx3zH2+lyRFQ7nO2VDCfVaSJAUx9/leUy60zWurX1rvnJ14zlxT7VBJmSmfiBU6Z1OhfFNt9bkfn/4+2/FJpNznavWle0y1+9Pu89ckKRR3n5OWPtRqqn38aJtztv3gQVPt9jf3OGdbjrxtql2Wdj/2ZxW4ZyUpPanYlJ/8mQXO2XzD/DVJOvLz/3TOvtrRa6rdG8l2zoYCw9y4IFBnz4fPr+QMCADgBQ0IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4AUNCADgxYgdxbMrf5yyHUfxtPTlONfNsk1j0QTDHpo52zbm58LLi52zU+Z82lQ7t/Szztl0pMRUuz/mPr5DkjKB++85Qa/7eCJJ6gvanbOpvg8fDfLn+o+6j7+J73/LVLutxZZPtLc7Z7Mz/abavePdj+e4ybaRUBNrq52z+Wnb78Pde9z3YV+mw1R7zhV/YcoH5dOds6m9vzfVzg27P66cU1Fpqt1wxSedsyX5Medsb7JPt3z3Pz40xxkQAMALGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwIsROwuuOZlQ2HEWXDSUca77sYluNd+14FL32UozL/q4qXZh9cXO2UzhOabafdEi52x/f8RWO9Vnygd9Ceds8pj7/DVJOv7GXudsx9E2U+1kn/t2ut5W3zVx2tmmfMmECvdwYDs+Heku52xhMmmqnRMyzPbLyjXVTp5zrnN2/6E3TLUjxVNM+Xh/j3O25+0Dpto9x3vdsx3u65CkqeXujxOTKguds929brcTzoAAAF4MeQP69re/rVAoNOgyY8aMof4xAIBRblj+BHf++efrueee+9MPyRqxf+kDAHgyLJ0hKytLlZW2z6UAAHy0DMtzQLt371Z1dbWmTJmi66+/Xvv37z9pNplMqrOzc9AFADD2DXkDmjdvntasWaP169dr9erV2rdvnz71qU+pq+vEr7RpbGxUUVHRwKWmpmaolwQAGIGGvAEtXbpUf/mXf6m6ujotXrxYP//5z9Xe3q6f/OQnJ8yvXLlSHR0dA5cDB2wvUQQAjE7D/uqA4uJinXvuudqzZ88Jr4/FYorF3D9rHAAwNgz7+4C6u7u1d+9eVVVVDfePAgCMIkPegL7yla+oqalJb7zxhn7961/r6quvViQS0ec///mh/lEAgFFsyP8Ed/DgQX3+85/XsWPHNGHCBH3yk5/Uli1bNGHCBFOda+bNVCzLbURMrPvkr7J7r/qr6kzrqJp9kXs47zxT7VTU/QUX6cg4U+1ksts5m+h1z0pSVsg26uXo7tecs2/9boepdn62+3iQs8+1HZ/CiWc5Z8PF7uuQpD8eOWLK/7TpRefsy9tfMtXubGlxztYrx1R7Qcx9zNP4QvexMJL09vRa52yWIStJLXvfNOXzq445Z4vCb5hq52bc72+Ta91vs5JUUOL+9Edvv/tIrUS/2yieIW9Ajz322FCXBACMQcyCAwB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4Mewfx3Cq5pWFlZftNkeq4rJPOtctmrPItI7j4yY5ZyPZJaba/SH3bF+y3VS7r7fDORtKu81tetebf3jdlA/H3ddy8SX1ptp5Z01zzuYUlZlqh/ozztn1G91ntUnSv/z7I6b83t3u+7yk0DY3sKrE/XabXZhvqp0ddp8Fd+xQq6n21rcOOmefb9piqj3n4o+b8v9lWr9zNth/yFR7X2+vc3bmlEpT7YJYyj2ccs9mBW7z6zgDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4MWJH8SjxtpR2G+MRush9vE7aMFpHknJyxztnU6FsU+1Ee9y9dl/aVDtsGPNz8M3dptovvfgrU/6L1/8352xBzVRT7a4+93E5hbGoqXZ3h/tomCefeNxU+419zab8kkvqnLPz57hnJen8GRc6Z+O9tnE5+TH3sUCZw0dMtecedV/La1t3mmo/3bTJlD+y230ETuhot6l2kFXsnJ065SxTbWUMDxQh97FKrlnOgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXtCAAABejNhZcNGpZYrF3JbXGctzrhukbfPAKvPLnLNtPR2m2um0Zb6bYWaTpOws9+18ZcfrptqRWI4pn1NS4pzt6Xef7SZJkWz3+XtHjh431X7o/3vQOfvmvn2m2n/5FwtM+ev/639xzubm2G4rh1rdZ7BNmDLFVDuU7X7so+fNNNUuDtzX/T8XX2Cq/dP/eMGUf/gZ9/mIlaECU+26mHs+mek31c4ocM4Ox9kKZ0AAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL0bsLLhMbp4yjrPgso+5z1RLjLetoyvRY0jbZnCFIxH3cGCsnXGfqZbptM2wm3J2tSmvsPt8qlCmz1Q6Kxpzzr78hz2m2r/YsMk5W11Raqp9/XVXmfLZets5Gyuyzeo7t8Z9BltQUGmq3Z1wv41Hct1nOkpSoutN93Cm11T7rz73GVP+QHenc/aFDTtNtfNC7nMd6xO2+48y7rPggmDos5wBAQC8MDegTZs26YorrlB1dbVCoZCeeOKJQdcHQaC77rpLVVVVys3N1cKFC7V79+6hWi8AYIwwN6B4PK7Zs2dr1apVJ7z+vvvu0w9+8AM98MAD2rp1q8aNG6fFixcrkUic9mIBAGOH+TmgpUuXaunSpSe8LggC3X///frGN76hK6+8UpL08MMPq6KiQk888YSuu+6601stAGDMGNLngPbt26fW1lYtXLhw4HtFRUWaN2+eNm/efML/k0wm1dnZOegCABj7hrQBtba2SpIqKioGfb+iomLguvdqbGxUUVHRwKWmpmYolwQAGKG8vwpu5cqV6ujoGLgcOHDA95IAAGfAkDagysp33iPQ1tY26PttbW0D171XLBZTYWHhoAsAYOwb0gZUW1uryspKbdiwYeB7nZ2d2rp1q+rr64fyRwEARjnzq+C6u7u1Z8+f3lG+b98+7dixQ6WlpZo0aZLuuOMO/eM//qPOOecc1dbW6pvf/Kaqq6t11VVXDeW6AQCjnLkBbdu2TZdddtnA1ytWrJAkLV++XGvWrNFXv/pVxeNx3XzzzWpvb9cnP/lJrV+/Xjk5tvEg6a60+pNu42dyWrvdC5ckTes43n3EPRzONtXOMpx/9odtJ6uWA1uslKn2WePdx99IUjp5zDkbcp8gJEnKyi1wzv76pW2m2m3t7c7ZRZfNNdWuKLeN7klH3bezs6fLVHvq5DnO2Za33cexSNK+ve7jjzI9tlfAxgx3oHGFU0212zq3mPL//S/c9+Hvm23Pc//uoPt+ubrD9vgWCdz3YUaWY+/22G1uQJdeeukHzvkJhUK65557dM8991hLAwA+Qry/Cg4A8NFEAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhhHsVzpqS6u5SKRpyynRPccpKUlbLNm8oN9TtnA2M/j6Tdd3+ecUhalmEeWIEMs/QkjS9KmPKp9Ik/jPBEskJRW+2U+/F564j7OiTJssfPqiwx1T568A1TPpnV55wtnzbdVPvwcffjeeAt97l+kpQXdp8B2Z9jux2OG+9+vy+tPNdU+3DyLVO+bHzcOfuJ+omm2jsf2emc3bprt6n2/Dr3DwANG+6aace7JWdAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvRuwontxYRHlRt+UFqaRz3XSq17SOVJDtnM3LKzbVLijNc84WpmxjSv74yu+cs7k5PabauXkdpnx/2n2sSVIxU+3C8CTnbMWEclNty29nvQn3UTmSlFuQb8qXFI9zzrYesI2Rqaw96pytnWzbh72d7vfNPbvbTLU7W9zvy/kFtnWXVE8z5ZNH3Ufg1J1daqpdVhhyzv76D3801d75Zp1z9uPnuY/tCfW7jUniDAgA4AUNCADgBQ0IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4AUNCADgxYidBff2kYyS2WmnbFXzEee6VefZZnb1F/Y7Z0PJuKl2185m5+yrv9tkql1SGDhnZ8ydaardkzxgyofix52zQdRthtRA7fR05+yUmsmm2pL7Wo632+bptRx1v81KUtW4AudsVsZUWj3tv3fOTj7Ptg9b0u73n5x893l3kpTT775PeozHp7WlxZT/z4efc84G/bbHoFhOoXP26GHbzMiNO/c5Z8+eXOmcjSdSTjnOgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXozYUTwzr/ic8nNznLIHf7PDue7vN282rSMVdhsHJEnxnX801c68tse9duA+zkaSshae75wtrbvMVDuesK2lL+4+1iSWKTHVTsWPOmenTD7bVDsvt9Q5u/PV3abai/7iElO+N+l+OzzbOHLoaNdB5+zxw/tNtXNzqpyzlRXuo14kKScSc86GlTDVfumF35rye/5w2Dl7sLPXVLsn7D66JyK3ETjv+t1u9+P55lvTnLO9SUbxAABGMBoQAMALcwPatGmTrrjiClVXVysUCumJJ54YdP0NN9ygUCg06LJkyZKhWi8AYIwwN6B4PK7Zs2dr1apVJ80sWbJELS0tA5dHH330tBYJABh7zC9CWLp0qZYuXfqBmVgspspK2xOKAICPlmF5Dmjjxo0qLy/X9OnTdeutt+rYsWMnzSaTSXV2dg66AADGviFvQEuWLNHDDz+sDRs26J//+Z/V1NSkpUuXKp0+8ctIGxsbVVRUNHCpqakZ6iUBAEagIX8f0HXXXTfw7wsuuEB1dXWaOnWqNm7cqAULFrwvv3LlSq1YsWLg687OTpoQAHwEDPvLsKdMmaKysjLt2XPiN13GYjEVFhYOugAAxr5hb0AHDx7UsWPHVFXl/o5oAMDYZ/4TXHd396CzmX379mnHjh0qLS1VaWmp7r77bi1btkyVlZXau3evvvrVr2ratGlavHjxkC4cADC6mRvQtm3bdNllf5od9u7zN8uXL9fq1au1c+dO/fu//7va29tVXV2tRYsW6R/+4R8Ui7nPbZKkvPPmalz+OKfs9Cl1znUTiaRpHX2puHP2SMeTptpHX3SfNxXNy5hqR9vc53t1Hdphql1YPcWUP97nvvb+ftvxSXS3OWerqmaZap81eapzduce2+ywX/9mlyk/5wL37PjiYlPtkNzzr77UZKo9LpLnnM0vLjPVTuTkOmf3733FVLtivO2PQyu/9v86Zx9Z97Sp9qbtv3POVhYVmGpPK3ff5x3H3OfpJfrcZsGZG9Cll16qIAhOev0zzzxjLQkA+AhiFhwAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwIsh/zygodIfRJQKIm7ZmPu8qaxxto97yFGJc7b2C1ebaqfaDjtnjz//nKl2qLfPOdt7xDYnK6cw25TPz53unO1KHDDVziSbnbNlZdNMtT992Vzn7K7Xt5lqv7jVts8XL/6sczaeOvmorBPp7g05Zz/2cds8vd073Wfk9fTa5gC2Hjj5Jy2/14wZ7nP9JKn9sG324h+b3WcvHjzSZapdEHGfebe4zjA0UNL5cz7mnD12oNU525dy23+cAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvBixo3jCISkcchsRYumiQTptW0jGfSRHd+UEU+maL/6Vc7b3gG1ETU+3e7443m+rfXy3KV9QebZzNpZjG5XUl253zvZ27TPVXrhgjnN20/9vG1Gz4xXbKJ5V//KIc/ZzV/9XU+3ssPttPDcWM9Xuk3vts8qKTLUj2e4PX681v2GqHQ7cR1lJ0mNPPuuc3fEH97E9klRbWuCcLcnNMdU+dPiIczbU734sU45ZzoAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXozYWXChUEghx1lw1romWe67KDuTbSodmek+P6zyf3zOVPvNhx9wzibesN0MsnJs8/QyBb9xzuaWXGSqHUu4z45LdHaaaldV1zln62a7ZyXplV22WXA//8UG5+xrv91lql3/cffb4ZTJ1abaxSXuc8zeeHWvqXYo5H67fe5XO0y1X3q92ZTvMty2olm2x6Aj8Xbn7Jsp93ltklQTDpyzBaXu+zvc51aXMyAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBcjdhSPMpF3Lg4igfv4CffBE/93GYYWHQts/TxtGAtU8enLTbVz+t33yeu//LGp9ri3U6a8Ko45R/sj+02lC/JmO2d7A9u6+1I9ztnPffb/MdUuG2cb21QYizlncxzHoLzrP5s2OWfXP7/ZVDsadb+N5+XY9klPb9I5+3a8z1S7P2y7L4fD7tuZCdmOT3eq3zn7u9ZWU+2FCz7hnG3eucM5m0y53dc4AwIAeGFqQI2NjZo7d64KCgpUXl6uq666Ss3Ng4f2JRIJNTQ0aPz48crPz9eyZcvU1tY2pIsGAIx+pgbU1NSkhoYGbdmyRc8++6xSqZQWLVqkeDw+kLnzzjv11FNP6fHHH1dTU5MOHTqka665ZsgXDgAY3UzPAa1fv37Q12vWrFF5ebm2b9+u+fPnq6OjQw8++KDWrl2ryy9/5zmLhx56SDNnztSWLVv0iU+4/70RADC2ndZzQB0dHZKk0tJSSdL27duVSqW0cOHCgcyMGTM0adIkbd584icvk8mkOjs7B10AAGPfKTegTCajO+64Q5dccolmzXrnA61aW1sVjUZVXFw8KFtRUaHWk7w6o7GxUUVFRQOXmpqaU10SAGAUOeUG1NDQoF27dumxxx47rQWsXLlSHR0dA5cDBw6cVj0AwOhwSu8Duu222/T0009r06ZNmjhx4sD3Kysr1dfXp/b29kFnQW1tbaqsrDxhrVgsppjhPQ4AgLHBdAYUBIFuu+02rVu3Ts8//7xqa2sHXT9nzhxlZ2drw4Y/fX59c3Oz9u/fr/r6+qFZMQBgTDCdATU0NGjt2rV68sknVVBQMPC8TlFRkXJzc1VUVKQbb7xRK1asUGlpqQoLC3X77bervr6eV8ABAAYxNaDVq1dLki699NJB33/ooYd0ww03SJK+973vKRwOa9myZUomk1q8eLF+9KMfDcliAQBjRygIAut4tGHV2dmpoqIi7fz1SyrIz3f6P8mebuf6gW3clNIR95lqIeOkueyQ+19As8K2p+tiGfe1vLHhJ6ba+/+w1pQvqO5yzqZLS0y1owVznbOZnPGm2uFxs5yzJUXu65CkcDr+4aE/8/brrzhnIz3us8MkacMf9jpn/+XRdabaxzvc5wAGIff7miTJMEvR/DBnmC/5Dvd8fsx2X64uKnDOzhpfZKo9Z5x77d/uedM5mwoC/e+OLnV0dKiwsPCkOWbBAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8OKWPYzgTOju6lOl3G59RkJfjXDcVso0pCcl93Id78h0ZwyietCErSfFs95lD5YuWmWqr+KgpfvyNJ5yz4aTtE3GD6B+ds1kR2ziWVOKQczZR4j5uSJJyw6WmfMcR99E96b6EqfbUGec4Z+d8fLap9i83Pu+ctU7LCQXu9+WcSMRUu7Cw2JSfMe0s5+yFtbZjPznsvp2hPQdNtbt2veacLcpxH/PT5ziWjDMgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBcjdhZce0e3Uim3eUJ9iaRz3ZIK2xymTCblnA2HjdPgwu79P5Nlm2UVRAwz7IICU+2zLlpuyqezcp2zx976ual2ptcy+ypmqh0J3Pd5EHefBSZJkdJPm/JldXOds0cOv2WqPb6qwjl7yXzbLMVXX9vlnA2H3O/HklRTXuac/fisGabaEyuLTfnCcb3O2ax4i6l2b7N7PtHrvg5JyvnYBc7ZxZ+52jnbk0zoP+5r/NAcZ0AAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9G7Cie/vZ29Sf7nLJHg4xz3UjE1nMLxxc5Z/sD25iSwDK5J+O+jZKUbSgedpt4NCCdU2PK11z0352zWQW2sUCte3/qnA2l2ky1I4bfzxJHXzfVzoqea8qHK8qds2Ul+aba8ZTb/UySpp833VS74cv/wzmbk20bxVMcc7+/RdVjqt3fccCUj3e4j4TqTLqP95KkknPd9/kFn7nIVDt3ymznbKik2jkbj8clRvEAAEYqGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwIsROwsu2dWlSL/brKdJs2Y5121pOWxaR05urnM2q8C2O1OG+W7RcMRUOyvjPgsuHbEMpZNCSpjyirnPd6uc9Vem0tlZ7rVbm5801U7GO5yzWVlHTLU723eb8pEC92OUSnSZamcS3e7rSNlqn1/rfv9JxuOm2j1d7rP9enuOmWpnR6Km/FnnzHfOFlfb5gDmV0xxzqYN9wdJShjG7wUZ96GRSccsZ0AAAC9MDaixsVFz585VQUGBysvLddVVV6m5uXlQ5tJLL1UoFBp0ueWWW4Z00QCA0c/UgJqamtTQ0KAtW7bo2WefVSqV0qJFi94Zvf1nbrrpJrW0tAxc7rvvviFdNABg9DM9abF+/fpBX69Zs0bl5eXavn275s//099A8/LyVFlZOTQrBACMSaf1HFBHxztP0paWlg76/iOPPKKysjLNmjVLK1euVE/PyT8MKplMqrOzc9AFADD2nfKr4DKZjO644w5dcsklmvVnr0L7whe+oMmTJ6u6ulo7d+7U1772NTU3N+tnP/vZCes0Njbq7rvvPtVlAABGqVNuQA0NDdq1a5defPHFQd+/+eabB/59wQUXqKqqSgsWLNDevXs1derU99VZuXKlVqxYMfB1Z2enampsH/kMABh9TqkB3XbbbXr66ae1adMmTZw48QOz8+bNkyTt2bPnhA0oFospFoudyjIAAKOYqQEFQaDbb79d69at08aNG1VbW/uh/2fHjh2SpKqqqlNaIABgbDI1oIaGBq1du1ZPPvmkCgoK1NraKkkqKipSbm6u9u7dq7Vr1+qzn/2sxo8fr507d+rOO+/U/PnzVVdXNywbAAAYnUwNaPXq1ZLeebPpn3vooYd0ww03KBqN6rnnntP999+veDyumpoaLVu2TN/4xjeGbMEAgLHB/Ce4D1JTU6OmpqbTWtBArYvmKT8/3ykbMjyHVBSyPd904MBB5+zZU84y1c7OdZ83ZZnDJElByH122Icd1/cKBbbZcUHG/dX+QeA+O0ySymZe55wdV1Bhqr3/lcecs109thlp0VLb3LNwf7tztj9+1FQ76HWvHU7atjPdb3hbRb/tdlhUOtk5Wzhlrql2btk5pnxWvvtTDCHju1+SfWnnbDrpnn1nLX3O2axs93mU2dlurYVZcAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL07584CGW29GCjtOlYimUs51C6LZpnV0J/uds2/t2W+qfdaM9388xUlFbL8rWCb3BCHb+I5Mxn0khyRFLDezwFY7mXEf3VNYM//DQ39mYsR9LX/846um2uE+29iZcKTXOZtJud9mJSkacxt5JUk5RaUfHvozkdwC99oF4021s2IlhoW4b6MkJdO2+0Qi7T7SJmzISlJ2yP22km17eFPGcH8Lh90fg1yznAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvBixs+AmVoxXQYHbHKkglXCu+8artpldyWTcOTt50jmm2gpCztGysgmm0v0p93lToeyMqXbIMBNKkkKBZUCVbRZcOEg6Z5Mh2zyw8TOvcM6WTf6EqXai/bAp3x9y34ehrBxT7Wie+7w2ZUVNtQPD8Qxs4/HU3+8+8y6dMd7GjWsJa5xzNhKyPexa1pIxbmda7vmIYTZiV5fbjEbOgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXozYUTyVNeNVWFjolO3u6naue07+x03rKC4pdc6GjP08E1jGYBh/VzCM+enu7rWVlvsIFEkKuS9F/SnbDJTiYsOIIstCJPX3u+dD49xuq++KVE0x5S0DVkKybadljycS7iOeJCkadR8hZL2Np9Np52zIeOxDpr0iRbLct7P9eJepdiwn5pzNyTWOsrK0gLD7Puzs7HT8+QAAeEADAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4MWJnwVkcO+Y2d0iSNv96h6n2xXMvdM62tR021c4yzI9KJm0zuCyz4Fpb3PefJGVl2+Zk1dZWO2ffOnjUVDs7luecPf62bTvzcsc5Z0Nh2z6RbMfTMiatv982q2/mTPe5dIcOtZlqRyLut8Oq6nJT7VQq5Zw93Ga8XWW7z1+TpCDjvp1dXbZZcBfOnemczc3LN9UO0u5TBkNh25w5F5wBAQC8MDWg1atXq66uToWFhSosLFR9fb1+8YtfDFyfSCTU0NCg8ePHKz8/X8uWLVNbm+03JgDAR4OpAU2cOFH33nuvtm/frm3btunyyy/XlVdeqVdffVWSdOedd+qpp57S448/rqamJh06dEjXXHPNsCwcADC6mZ4DuuKKKwZ9/U//9E9avXq1tmzZookTJ+rBBx/U2rVrdfnll0uSHnroIc2cOVNbtmzRJz7xiaFbNQBg1Dvl54DS6bQee+wxxeNx1dfXa/v27UqlUlq4cOFAZsaMGZo0aZI2b9580jrJZFKdnZ2DLgCAsc/cgF555RXl5+crFovplltu0bp163TeeeeptbVV0WhUxcXFg/IVFRVqbW09ab3GxkYVFRUNXGpqaswbAQAYfcwNaPr06dqxY4e2bt2qW2+9VcuXL9drr712ygtYuXKlOjo6Bi4HDhw45VoAgNHD/D6gaDSqadOmSZLmzJmj3/zmN/r+97+va6+9Vn19fWpvbx90FtTW1qbKysqT1ovFYorFbK+5BwCMfqf9PqBMJqNkMqk5c+YoOztbGzZsGLiuublZ+/fvV319/en+GADAGGM6A1q5cqWWLl2qSZMmqaurS2vXrtXGjRv1zDPPqKioSDfeeKNWrFih0tJSFRYW6vbbb1d9fT2vgAMAvI+pAR0+fFhf/OIX1dLSoqKiItXV1emZZ57RZz7zGUnS9773PYXDYS1btkzJZFKLFy/Wj370o2FZ+J8bN859ZMq0qbWm2rGY+7ic3NwcU+1w2L12JmMb9ZJMJJ2z5eWlptqRrLQpXzq+2DmblWX7c2xHl/t2th1+21Q7HXXfzlDgPtJEkgoL3UcISVIs6j4GJRyy/WHD8ifw8gnjTbXjPXHnbCRiG/XSbRppY7v/5OS43zclqbvbfbRSSUmxcS3ux8f6OBEO+x2GY2pADz744Aden5OTo1WrVmnVqlWntSgAwNjHLDgAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAX5mnYwy0I3hklYflguq4u92x3vNu0nq6uXPfa3bba4bD77k8kEqballE8ClKm2tZRPF2GkSnd3b2m2vG4+3b29rqPhZGkcMh9rEkobBvFE4n0m/L9qeEbxdPV5T5CqifeY6od73HPx8zjb9zvb3Hj/T4UCpny8bj7KJ5UyradlsfCVL/tId1yWwmF3ffJu2t+9/H8ZEZcA3r3wYoPpgOA0a2rq0tFRUUnvT4UfFiLOsMymYwOHTqkgoKCQb+FdHZ2qqamRgcOHFBhYaHHFQ4vtnPs+Chso8R2jjVDsZ1BEKirq0vV1dUfOPB0xJ0BhcNhTZw48aTXFxYWjumD/y62c+z4KGyjxHaONae7nR905vMuXoQAAPCCBgQA8GLUNKBYLKZvfetbpg/PGo3YzrHjo7CNEts51pzJ7RxxL0IAAHw0jJozIADA2EIDAgB4QQMCAHhBAwIAeDFqGtCqVat09tlnKycnR/PmzdNLL73ke0lD6tvf/rZCodCgy4wZM3wv67Rs2rRJV1xxhaqrqxUKhfTEE08Muj4IAt11112qqqpSbm6uFi5cqN27d/tZ7Gn4sO284YYb3ndslyxZ4mexp6ixsVFz585VQUGBysvLddVVV6m5uXlQJpFIqKGhQePHj1d+fr6WLVumtrY2Tys+NS7beemll77veN5yyy2eVnxqVq9erbq6uoE3m9bX1+sXv/jFwPVn6liOigb04x//WCtWrNC3vvUt/fa3v9Xs2bO1ePFiHT582PfShtT555+vlpaWgcuLL77oe0mnJR6Pa/bs2Vq1atUJr7/vvvv0gx/8QA888IC2bt2qcePGafHixebBq7592HZK0pIlSwYd20cfffQMrvD0NTU1qaGhQVu2bNGzzz6rVCqlRYsWKR7/04DXO++8U0899ZQef/xxNTU16dChQ7rmmms8rtrOZTsl6aabbhp0PO+77z5PKz41EydO1L333qvt27dr27Ztuvzyy3XllVfq1VdflXQGj2UwClx88cVBQ0PDwNfpdDqorq4OGhsbPa5qaH3rW98KZs+e7XsZw0ZSsG7duoGvM5lMUFlZGXznO98Z+F57e3sQi8WCRx991MMKh8Z7tzMIgmD58uXBlVde6WU9w+Xw4cOBpKCpqSkIgneOXXZ2dvD4448PZH7/+98HkoLNmzf7WuZpe+92BkEQfPrTnw7+5m/+xt+ihklJSUnwr//6r2f0WI74M6C+vj5t375dCxcuHPheOBzWwoULtXnzZo8rG3q7d+9WdXW1pkyZouuvv1779+/3vaRhs2/fPrW2tg46rkVFRZo3b96YO66StHHjRpWXl2v69Om69dZbdezYMd9LOi0dHR2SpNLSUknS9u3blUqlBh3PGTNmaNKkSaP6eL53O9/1yCOPqKysTLNmzdLKlSvVY/jYiZEmnU7rscceUzweV319/Rk9liNuGOl7HT16VOl0WhUVFYO+X1FRoddff93TqobevHnztGbNGk2fPl0tLS26++679alPfUq7du1SQUGB7+UNudbWVkk64XF997qxYsmSJbrmmmtUW1urvXv36u///u+1dOlSbd68WZGI++f8jBSZTEZ33HGHLrnkEs2aNUvSO8czGo2quLh4UHY0H88TbackfeELX9DkyZNVXV2tnTt36mtf+5qam5v1s5/9zONq7V555RXV19crkUgoPz9f69at03nnnacdO3acsWM54hvQR8XSpUsH/l1XV6d58+Zp8uTJ+slPfqIbb7zR48pwuq677rqBf19wwQWqq6vT1KlTtXHjRi1YsMDjyk5NQ0ODdu3aNeqfo/wwJ9vOm2++eeDfF1xwgaqqqrRgwQLt3btXU6dOPdPLPGXTp0/Xjh071NHRoZ/+9Kdavny5mpqazugaRvyf4MrKyhSJRN73Coy2tjZVVlZ6WtXwKy4u1rnnnqs9e/b4XsqwePfYfdSOqyRNmTJFZWVlo/LY3nbbbXr66af1wgsvDPrYlMrKSvX19am9vX1QfrQez5Nt54nMmzdPkkbd8YxGo5o2bZrmzJmjxsZGzZ49W9///vfP6LEc8Q0oGo1qzpw52rBhw8D3MpmMNmzYoPr6eo8rG17d3d3au3evqqqqfC9lWNTW1qqysnLQce3s7NTWrVvH9HGVpIMHD+rYsWOj6tgGQaDbbrtN69at0/PPP6/a2tpB18+ZM0fZ2dmDjmdzc7P2798/qo7nh23niezYsUOSRtXxPJFMJqNkMnlmj+WQvqRhmDz22GNBLBYL1qxZE7z22mvBzTffHBQXFwetra2+lzZk/vZv/zbYuHFjsG/fvuBXv/pVsHDhwqCsrCw4fPiw76Wdsq6uruDll18OXn755UBS8N3vfjd4+eWXgzfffDMIgiC49957g+Li4uDJJ58Mdu7cGVx55ZVBbW1t0Nvb63nlNh+0nV1dXcFXvvKVYPPmzcG+ffuC5557LrjwwguDc845J0gkEr6X7uzWW28NioqKgo0bNwYtLS0Dl56enoHMLbfcEkyaNCl4/vnng23btgX19fVBfX29x1Xbfdh27tmzJ7jnnnuCbdu2Bfv27QuefPLJYMqUKcH8+fM9r9zm61//etDU1BTs27cv2LlzZ/D1r389CIVCwS9/+csgCM7csRwVDSgIguCHP/xhMGnSpCAajQYXX3xxsGXLFt9LGlLXXnttUFVVFUSj0eCss84Krr322mDPnj2+l3VaXnjhhUDS+y7Lly8PguCdl2J/85vfDCoqKoJYLBYsWLAgaG5u9rvoU/BB29nT0xMsWrQomDBhQpCdnR1Mnjw5uOmmm0bdL08n2j5JwUMPPTSQ6e3tDb785S8HJSUlQV5eXnD11VcHLS0t/hZ9Cj5sO/fv3x/Mnz8/KC0tDWKxWDBt2rTg7/7u74KOjg6/Czf667/+62Dy5MlBNBoNJkyYECxYsGCg+QTBmTuWfBwDAMCLEf8cEABgbKIBAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALz4P4JaN4R3/+c8AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "86\n",
            "telephone\n",
            "5\n",
            "household_electrical_devices\n"
          ]
        }
      ],
      "source": [
        "num = 5\n",
        "\n",
        "img = x_train[num]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(y_train_union[num][0])\n",
        "print(labels_fine[y_train_union[num][0]])\n",
        "print(y_train_union[num][1])\n",
        "print(labels_coarse[y_train_union[num][1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8qM-1f3wmc7"
      },
      "outputs": [],
      "source": [
        "x_train_own, x_val_own, y_train_own, y_val_own = train_test_split(x_train, y_train_union, test_size=0.2, stratify=y_train_union)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qYLLwVZPID89",
        "outputId": "119e66b4-2151-4e6d-dbb6-ee59c85e8036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of x_train_own: (40000, 32, 32, 3)\n",
            "Shape of x_val_own: (10000, 32, 32, 3)\n",
            "Shape of y_train_own: (40000, 2)\n",
            "Shape of y_val_own: (10000, 2)\n",
            "Original Proportions:\n",
            "Class [0 4]: 0.01\n",
            "Class [1 1]: 0.01\n",
            "Class [ 2 14]: 0.01\n",
            "Class [3 8]: 0.01\n",
            "Class [4 0]: 0.01\n",
            "Class [5 6]: 0.01\n",
            "Class [6 7]: 0.01\n",
            "Class [7 7]: 0.01\n",
            "Class [ 8 18]: 0.01\n",
            "Class [9 3]: 0.01\n",
            "Class [10  3]: 0.01\n",
            "Class [11 14]: 0.01\n",
            "Class [12  9]: 0.01\n",
            "Class [13 18]: 0.01\n",
            "Class [14  7]: 0.01\n",
            "Class [15 11]: 0.01\n",
            "Class [16  3]: 0.01\n",
            "Class [17  9]: 0.01\n",
            "Class [18  7]: 0.01\n",
            "Class [19 11]: 0.01\n",
            "Class [20  6]: 0.01\n",
            "Class [21 11]: 0.01\n",
            "Class [22  5]: 0.01\n",
            "Class [23 10]: 0.01\n",
            "Class [24  7]: 0.01\n",
            "Class [25  6]: 0.01\n",
            "Class [26 13]: 0.01\n",
            "Class [27 15]: 0.01\n",
            "Class [28  3]: 0.01\n",
            "Class [29 15]: 0.01\n",
            "Class [30  0]: 0.01\n",
            "Class [31 11]: 0.01\n",
            "Class [32  1]: 0.01\n",
            "Class [33 10]: 0.01\n",
            "Class [34 12]: 0.01\n",
            "Class [35 14]: 0.01\n",
            "Class [36 16]: 0.01\n",
            "Class [37  9]: 0.01\n",
            "Class [38 11]: 0.01\n",
            "Class [39  5]: 0.01\n",
            "Class [40  5]: 0.01\n",
            "Class [41 19]: 0.01\n",
            "Class [42  8]: 0.01\n",
            "Class [43  8]: 0.01\n",
            "Class [44 15]: 0.01\n",
            "Class [45 13]: 0.01\n",
            "Class [46 14]: 0.01\n",
            "Class [47 17]: 0.01\n",
            "Class [48 18]: 0.01\n",
            "Class [49 10]: 0.01\n",
            "Class [50 16]: 0.01\n",
            "Class [51  4]: 0.01\n",
            "Class [52 17]: 0.01\n",
            "Class [53  4]: 0.01\n",
            "Class [54  2]: 0.01\n",
            "Class [55  0]: 0.01\n",
            "Class [56 17]: 0.01\n",
            "Class [57  4]: 0.01\n",
            "Class [58 18]: 0.01\n",
            "Class [59 17]: 0.01\n",
            "Class [60 10]: 0.01\n",
            "Class [61  3]: 0.01\n",
            "Class [62  2]: 0.01\n",
            "Class [63 12]: 0.01\n",
            "Class [64 12]: 0.01\n",
            "Class [65 16]: 0.01\n",
            "Class [66 12]: 0.01\n",
            "Class [67  1]: 0.01\n",
            "Class [68  9]: 0.01\n",
            "Class [69 19]: 0.01\n",
            "Class [70  2]: 0.01\n",
            "Class [71 10]: 0.01\n",
            "Class [72  0]: 0.01\n",
            "Class [73  1]: 0.01\n",
            "Class [74 16]: 0.01\n",
            "Class [75 12]: 0.01\n",
            "Class [76  9]: 0.01\n",
            "Class [77 13]: 0.01\n",
            "Class [78 15]: 0.01\n",
            "Class [79 13]: 0.01\n",
            "Class [80 16]: 0.01\n",
            "Class [81 19]: 0.01\n",
            "Class [82  2]: 0.01\n",
            "Class [83  4]: 0.01\n",
            "Class [84  6]: 0.01\n",
            "Class [85 19]: 0.01\n",
            "Class [86  5]: 0.01\n",
            "Class [87  5]: 0.01\n",
            "Class [88  8]: 0.01\n",
            "Class [89 19]: 0.01\n",
            "Class [90 18]: 0.01\n",
            "Class [91  1]: 0.01\n",
            "Class [92  2]: 0.01\n",
            "Class [93 15]: 0.01\n",
            "Class [94  6]: 0.01\n",
            "Class [95  0]: 0.01\n",
            "Class [96 17]: 0.01\n",
            "Class [97  8]: 0.01\n",
            "Class [98 14]: 0.01\n",
            "Class [99 13]: 0.01\n",
            "\n",
            "Train Proportions:\n",
            "Class [0 4]: 0.01\n",
            "Class [1 1]: 0.01\n",
            "Class [ 2 14]: 0.01\n",
            "Class [3 8]: 0.01\n",
            "Class [4 0]: 0.01\n",
            "Class [5 6]: 0.01\n",
            "Class [6 7]: 0.01\n",
            "Class [7 7]: 0.01\n",
            "Class [ 8 18]: 0.01\n",
            "Class [9 3]: 0.01\n",
            "Class [10  3]: 0.01\n",
            "Class [11 14]: 0.01\n",
            "Class [12  9]: 0.01\n",
            "Class [13 18]: 0.01\n",
            "Class [14  7]: 0.01\n",
            "Class [15 11]: 0.01\n",
            "Class [16  3]: 0.01\n",
            "Class [17  9]: 0.01\n",
            "Class [18  7]: 0.01\n",
            "Class [19 11]: 0.01\n",
            "Class [20  6]: 0.01\n",
            "Class [21 11]: 0.01\n",
            "Class [22  5]: 0.01\n",
            "Class [23 10]: 0.01\n",
            "Class [24  7]: 0.01\n",
            "Class [25  6]: 0.01\n",
            "Class [26 13]: 0.01\n",
            "Class [27 15]: 0.01\n",
            "Class [28  3]: 0.01\n",
            "Class [29 15]: 0.01\n",
            "Class [30  0]: 0.01\n",
            "Class [31 11]: 0.01\n",
            "Class [32  1]: 0.01\n",
            "Class [33 10]: 0.01\n",
            "Class [34 12]: 0.01\n",
            "Class [35 14]: 0.01\n",
            "Class [36 16]: 0.01\n",
            "Class [37  9]: 0.01\n",
            "Class [38 11]: 0.01\n",
            "Class [39  5]: 0.01\n",
            "Class [40  5]: 0.01\n",
            "Class [41 19]: 0.01\n",
            "Class [42  8]: 0.01\n",
            "Class [43  8]: 0.01\n",
            "Class [44 15]: 0.01\n",
            "Class [45 13]: 0.01\n",
            "Class [46 14]: 0.01\n",
            "Class [47 17]: 0.01\n",
            "Class [48 18]: 0.01\n",
            "Class [49 10]: 0.01\n",
            "Class [50 16]: 0.01\n",
            "Class [51  4]: 0.01\n",
            "Class [52 17]: 0.01\n",
            "Class [53  4]: 0.01\n",
            "Class [54  2]: 0.01\n",
            "Class [55  0]: 0.01\n",
            "Class [56 17]: 0.01\n",
            "Class [57  4]: 0.01\n",
            "Class [58 18]: 0.01\n",
            "Class [59 17]: 0.01\n",
            "Class [60 10]: 0.01\n",
            "Class [61  3]: 0.01\n",
            "Class [62  2]: 0.01\n",
            "Class [63 12]: 0.01\n",
            "Class [64 12]: 0.01\n",
            "Class [65 16]: 0.01\n",
            "Class [66 12]: 0.01\n",
            "Class [67  1]: 0.01\n",
            "Class [68  9]: 0.01\n",
            "Class [69 19]: 0.01\n",
            "Class [70  2]: 0.01\n",
            "Class [71 10]: 0.01\n",
            "Class [72  0]: 0.01\n",
            "Class [73  1]: 0.01\n",
            "Class [74 16]: 0.01\n",
            "Class [75 12]: 0.01\n",
            "Class [76  9]: 0.01\n",
            "Class [77 13]: 0.01\n",
            "Class [78 15]: 0.01\n",
            "Class [79 13]: 0.01\n",
            "Class [80 16]: 0.01\n",
            "Class [81 19]: 0.01\n",
            "Class [82  2]: 0.01\n",
            "Class [83  4]: 0.01\n",
            "Class [84  6]: 0.01\n",
            "Class [85 19]: 0.01\n",
            "Class [86  5]: 0.01\n",
            "Class [87  5]: 0.01\n",
            "Class [88  8]: 0.01\n",
            "Class [89 19]: 0.01\n",
            "Class [90 18]: 0.01\n",
            "Class [91  1]: 0.01\n",
            "Class [92  2]: 0.01\n",
            "Class [93 15]: 0.01\n",
            "Class [94  6]: 0.01\n",
            "Class [95  0]: 0.01\n",
            "Class [96 17]: 0.01\n",
            "Class [97  8]: 0.01\n",
            "Class [98 14]: 0.01\n",
            "Class [99 13]: 0.01\n",
            "\n",
            "Validation Proportions:\n",
            "Class [0 4]: 0.01\n",
            "Class [1 1]: 0.01\n",
            "Class [ 2 14]: 0.01\n",
            "Class [3 8]: 0.01\n",
            "Class [4 0]: 0.01\n",
            "Class [5 6]: 0.01\n",
            "Class [6 7]: 0.01\n",
            "Class [7 7]: 0.01\n",
            "Class [ 8 18]: 0.01\n",
            "Class [9 3]: 0.01\n",
            "Class [10  3]: 0.01\n",
            "Class [11 14]: 0.01\n",
            "Class [12  9]: 0.01\n",
            "Class [13 18]: 0.01\n",
            "Class [14  7]: 0.01\n",
            "Class [15 11]: 0.01\n",
            "Class [16  3]: 0.01\n",
            "Class [17  9]: 0.01\n",
            "Class [18  7]: 0.01\n",
            "Class [19 11]: 0.01\n",
            "Class [20  6]: 0.01\n",
            "Class [21 11]: 0.01\n",
            "Class [22  5]: 0.01\n",
            "Class [23 10]: 0.01\n",
            "Class [24  7]: 0.01\n",
            "Class [25  6]: 0.01\n",
            "Class [26 13]: 0.01\n",
            "Class [27 15]: 0.01\n",
            "Class [28  3]: 0.01\n",
            "Class [29 15]: 0.01\n",
            "Class [30  0]: 0.01\n",
            "Class [31 11]: 0.01\n",
            "Class [32  1]: 0.01\n",
            "Class [33 10]: 0.01\n",
            "Class [34 12]: 0.01\n",
            "Class [35 14]: 0.01\n",
            "Class [36 16]: 0.01\n",
            "Class [37  9]: 0.01\n",
            "Class [38 11]: 0.01\n",
            "Class [39  5]: 0.01\n",
            "Class [40  5]: 0.01\n",
            "Class [41 19]: 0.01\n",
            "Class [42  8]: 0.01\n",
            "Class [43  8]: 0.01\n",
            "Class [44 15]: 0.01\n",
            "Class [45 13]: 0.01\n",
            "Class [46 14]: 0.01\n",
            "Class [47 17]: 0.01\n",
            "Class [48 18]: 0.01\n",
            "Class [49 10]: 0.01\n",
            "Class [50 16]: 0.01\n",
            "Class [51  4]: 0.01\n",
            "Class [52 17]: 0.01\n",
            "Class [53  4]: 0.01\n",
            "Class [54  2]: 0.01\n",
            "Class [55  0]: 0.01\n",
            "Class [56 17]: 0.01\n",
            "Class [57  4]: 0.01\n",
            "Class [58 18]: 0.01\n",
            "Class [59 17]: 0.01\n",
            "Class [60 10]: 0.01\n",
            "Class [61  3]: 0.01\n",
            "Class [62  2]: 0.01\n",
            "Class [63 12]: 0.01\n",
            "Class [64 12]: 0.01\n",
            "Class [65 16]: 0.01\n",
            "Class [66 12]: 0.01\n",
            "Class [67  1]: 0.01\n",
            "Class [68  9]: 0.01\n",
            "Class [69 19]: 0.01\n",
            "Class [70  2]: 0.01\n",
            "Class [71 10]: 0.01\n",
            "Class [72  0]: 0.01\n",
            "Class [73  1]: 0.01\n",
            "Class [74 16]: 0.01\n",
            "Class [75 12]: 0.01\n",
            "Class [76  9]: 0.01\n",
            "Class [77 13]: 0.01\n",
            "Class [78 15]: 0.01\n",
            "Class [79 13]: 0.01\n",
            "Class [80 16]: 0.01\n",
            "Class [81 19]: 0.01\n",
            "Class [82  2]: 0.01\n",
            "Class [83  4]: 0.01\n",
            "Class [84  6]: 0.01\n",
            "Class [85 19]: 0.01\n",
            "Class [86  5]: 0.01\n",
            "Class [87  5]: 0.01\n",
            "Class [88  8]: 0.01\n",
            "Class [89 19]: 0.01\n",
            "Class [90 18]: 0.01\n",
            "Class [91  1]: 0.01\n",
            "Class [92  2]: 0.01\n",
            "Class [93 15]: 0.01\n",
            "Class [94  6]: 0.01\n",
            "Class [95  0]: 0.01\n",
            "Class [96 17]: 0.01\n",
            "Class [97  8]: 0.01\n",
            "Class [98 14]: 0.01\n",
            "Class [99 13]: 0.01\n"
          ]
        }
      ],
      "source": [
        "# prompt: I want to check correct stratification of data (stratification means same proportion of classes in train and validation data)\n",
        "\n",
        "print(f'Shape of x_train_own: {x_train_own.shape}')\n",
        "print(f'Shape of x_val_own: {x_val_own.shape}')\n",
        "print(f'Shape of y_train_own: {y_train_own.shape}')\n",
        "print(f'Shape of y_val_own: {y_val_own.shape}')\n",
        "\n",
        "# Check class proportions in the original training data\n",
        "unique_classes, class_counts = np.unique(y_train_union, axis=0, return_counts=True)\n",
        "total_samples = len(y_train_union)\n",
        "original_proportions = class_counts / total_samples\n",
        "\n",
        "# Check class proportions in the training split\n",
        "unique_train_classes, train_class_counts = np.unique(y_train_own, axis=0, return_counts=True)\n",
        "train_total_samples = len(y_train_own)\n",
        "train_proportions = train_class_counts / train_total_samples\n",
        "\n",
        "\n",
        "# Check class proportions in the validation split\n",
        "unique_val_classes, val_class_counts = np.unique(y_val_own, axis=0, return_counts=True)\n",
        "val_total_samples = len(y_val_own)\n",
        "val_proportions = val_class_counts / val_total_samples\n",
        "\n",
        "print(\"Original Proportions:\")\n",
        "for i in range(len(unique_classes)):\n",
        "    print(f\"Class {unique_classes[i]}: {original_proportions[i]}\")\n",
        "\n",
        "print(\"\\nTrain Proportions:\")\n",
        "for i in range(len(unique_train_classes)):\n",
        "  print(f\"Class {unique_train_classes[i]}: {train_proportions[i]}\")\n",
        "\n",
        "\n",
        "print(\"\\nValidation Proportions:\")\n",
        "for i in range(len(unique_val_classes)):\n",
        "  print(f\"Class {unique_val_classes[i]}: {val_proportions[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W0Lx8j13NQI",
        "outputId": "7a85dac8-6909-43b9-a7cc-304a4117e741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de x_train_own: (40000, 32, 32, 3)\n",
            "Dimensiones de y_train_own: (40000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(f'Dimensiones de x_train_own: {x_train_own.shape}')\n",
        "print(f'Dimensiones de y_train_own: {y_train_own.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "csdDuOdy56ik",
        "outputId": "9d2be8ce-349a-40af-e595-babf118663d8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwaklEQVR4nO3de3Bc5Znv+193q7t1b1mWdbMk4wvYGF9IHHB0CI6DPb7MKQ4X7ylIUjUmQ0HByNSAJ5PEUwkEZqbEkH0SkpRjzjnD4MmuGBJmx3DgJGbAYDkkNokdvI25KLYR2MaSfEN3qdXqXuePjJUR2PA+tuRXEt9PVVdZ0uNH7+q1ev26W91Ph4IgCAQAwAUW9r0AAMAnEwEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwIss3wv4oEwmo6NHj6qgoEChUMj3cgAARkEQqLOzU5WVlQqHz/44Z9QF0NGjR1VdXe17GQCA83T48GFVVVWd9ecjFkDr16/Xd77zHbW0tGj+/Pn64Q9/qCuvvPJj/19BQYEkaetL25WXn+/0u7q6upzXlV9Y5FwrSZGw+1U0kM6YegcZ9ylIaWPv7HjcuTb/P69zV1lZtsOmo6PTufb//O/fNPV+9n8+4VwbBLZH1P0p9/2Tsu0ehcK2teRmx5xrKysSpt6FhXnOtZnUgKl3KtXvXBuk+0y9Lcdhywn3Y1CSuntt2xmEIs61N/y3vzT1bn7vDefabPebvSTp7+/7F+faxISJzrVdnZ26cv7Fg+fzsxmRAPrpT3+qtWvX6pFHHtHChQv18MMPa/ny5WpsbFRpaelH/t/TT7vl5ecrP9/txGgZZufa87RIxBBAA6MogAxHYkFBoam3NYAMm6lYzP1EK0m2Z2ltJ/1QyH3h1meLrU8vW+ojEdufdrMM9emMrXfGUB8Y949lO8PGwDc//W+otx7j0aj77S0aNbU2nQ+t5wnp46/HEXkRwne/+13ddttt+spXvqLZs2frkUceUW5urv71X/91JH4dAGAMGvYA6u/v1+7du7V06dI//ZJwWEuXLtWOHTs+VJ9MJtXR0THkAgAY/4Y9gE6cOKF0Oq2ysrIh3y8rK1NLS8uH6uvr65VIJAYvvAABAD4ZvL8PaN26dWpvbx+8HD582PeSAAAXwLC/CKGkpESRSEStra1Dvt/a2qry8vIP1cfjccUNr9gCAIwPw/4IKBaLacGCBdq6devg9zKZjLZu3ara2trh/nUAgDFqRF6GvXbtWq1evVqf+cxndOWVV+rhhx9Wd3e3vvKVr4zErwMAjEEjEkA33XSTjh8/rnvvvVctLS26/PLLtWXLlg+9MAEA8Mk1YpMQ1qxZozVr1pzz/y+cMMn5jU8FRe7v0I0Y3rEsSQMD7u+ITiaTpt7pdNq5NhO410pSW/v7zrXvHnrb1DsILG/9lXp6epxr32k6YOpt2D0yLlvRmOHNiMZJCFHjm0VLS7Kda0MhW+9kv+UN0bYrsT/pvoMSuba/BRdNKHJfh22wgXp7j5vq8xMlzrXllbZX+r7xWoNz7YzpU029Y9nux1UmcD/IXWu9vwoOAPDJRAABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwYsVE852sgldJAqt+pNhw25Kjxo96jUffPb4/FbKNELKNh0umUqXdHVrtz7YkTzabeLR/4qI2Ps7/xdefad/Y3mnpnDCNwQpbjRFIs6n6wfHpyvql3JGw7EA+c6nOu7epxr5WkgcB9PFXEeJ910WUVzrUTSopMvY+edN/OiUVuY71Oa2/rMtVXTK5xrk2lbSO7LLfPuXPmmXrHstzPbxHDydO1lkdAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADAi1E7Cy6TSSuTSTvVBoH7QLCMZXiYUcg4aM4ywy4SiZp6F0+Y5FybKCw29e7t7TXVn2h5z7k22ddt6h0YrvLelNvxdNqMqgnOtV/5P2pNvdvb3zfVf//pV51rOwZsx3jcMJduxeVVpt7/bfmVzrX/seeQqXfLySPOte0dtuPq/U7bMf6Fy+Y616bTbjMuT+swHCsFBXmm3tGo+3klbDhOXGt5BAQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4MWpH8fT0dDuPqonFYs59LbWSFAq5j5/IGEYCSVJ6YMC5diCdMvUOhyPOtaGIe+0f/4Ot/Giz+8iUvt4+U++CHPdDONwXmHpfMe9S59pM4WRT7+KI7ViZX+M+LunNA8dMvRdeWuRce9sN/5up9/Eg4VzbcupNU++ceNy5tl2dpt5Z8WxT/ZULP+dcm5ufa+odz3bfzmjMtu4sw/nQMvIs5Hj+4REQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwYtTOguvvT6m/v9+ptqenx7lvdnaOaR3ZhjlMsahtzlwk7H71nzh13NS7vd199lVJSampd1enba7WW43uM74KbFehynOjzrX9BbZ9P3VatXPtS79tNPVe+akSU/2CyYXOtcG775l6f+7iSc61heW2mXe/3dviXNvb12XqXVzsPlOtp9f9OJGkwom27Zw773Ln2l27fmXqHQrcZ0YWJiaYemcZzkFpwzzKsOPASB4BAQC8GPYA+va3v61QKDTkMmvWrOH+NQCAMW5EnoK77LLL9MILL/zpl2SN2mf6AACejEgyZGVlqby8fCRaAwDGiRH5G9D+/ftVWVmpadOm6ctf/rIOHTp01tpkMqmOjo4hFwDA+DfsAbRw4UJt3LhRW7Zs0YYNG9TU1KSrr75anWd55VR9fb0SicTgpbra/ZVHAICxa9gDaOXKlfqLv/gLzZs3T8uXL9cvfvELtbW16Wc/+9kZ69etW6f29vbBy+HDh4d7SQCAUWjEXx1QVFSkSy65RAcOHDjjz+PxuOKGz3YHAIwPI/4+oK6uLh08eFAVFRUj/asAAGPIsAfQV7/6VTU0NOidd97Rb37zG91www2KRCL64he/ONy/CgAwhg37U3BHjhzRF7/4RZ08eVKTJk3S5z73Oe3cuVOTJrmP+5Ckgvx85RcUONWm02nnvkHGtAwl+9zHT3R2dJt6hyMR93X0uq9Dkt584zX33smkqXd3R5upvqjrHefaz1e5j1eRpP1H3Nd+UaVtTEk87DZORJJOtNv2faBKU31p3H07q0ttN+tUX69zbVu3+21NklpPur+qNRIJTL0LCt2fug8ds43i+dRnak31pZPcx1m987b7aCpJys/Nd66dNm22qbfhFKSBlPvJM8i41Q57AD3xxBPD3RIAMA4xCw4A4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwYsQ/juFchcIRhcJug4pMKRqxZW4kGnOuzch9dpgk9fa6z+CS43VxWnmZ+6yxd95529T70J6XTPVTQ8edawtyTK2VjrvPJquZaJs1VprvXl9TbJth19Jku85zetqca6eU5Zl6n3zvmHNtc+Prpt6hpPsMw3DYNq8tFLifvvqSttv9pbM/Zarv6u5yrv3Dm//L1LtycpVzbVX1DFPv/r5+92LTIE23Wh4BAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF6M2lE8PT3dCofd8nFgYMC5bybjPrpFkqKGUTxZWbZRIvkF+c61fcmkqXfN1Onuxak+U+8uuY/WkaSJhpE2eRNs12FFabFzbay4wNS7OHTSvTbVaup9tNl2nV9cVuJcG013mnp397mPkTnRuMfUuzh/onNtV5dhNJWkngH30Velk0pNvadcdLGp/q23XnOuPX78XVPvT3/qs861WVHbLKuTJ93HMEUi7nHR1el2DPIICADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeDFqZ8E1vrVPubm5TrWhkHuO5uW6z1+TpIklk5xrc3Jsc5gCuc9ICxln2LWdPOFc+/aLj5t653Y0meonTow710Yy7nP9JCkI3K/Dtpajpt5tx91nwZVkuc8MlKT8SbZjJd3Z7lx75Ij7bDdJykm4r+VUW4+pd4lhPuJFtpumnnv9oHPtfMM8NUmqqp5mqt/6wk+da0OZflPvGTM+5d47bDsO33//lKHaffZed5fbMcgjIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4MWonQV3YP+bys7OdqoNh903o6ys1LSO3t4259qMqbOUTrnPPQtFIqbex9/4rXPtqb1bTb0rsvtM9SG5z6fq6EiaekcN13pu3HZ/Kz7gPvcsNGC7TiJ9ttl+7xvax7Jtx0pW2H3GVywvz9Q7PeC+fyZn2/ZPzFB+0Yx5pt5ZcfcZdpL02t5dzrU5OQlT7wmTKp1rX93jfruXpOPH3nOuveiimc61PT1utx0eAQEAvDAH0Pbt23XttdeqsrJSoVBITz311JCfB0Gge++9VxUVFcrJydHSpUu1f//+4VovAGCcMAdQd3e35s+fr/Xr15/x5w899JB+8IMf6JFHHtErr7yivLw8LV++XH19tqcoAADjm/lvQCtXrtTKlSvP+LMgCPTwww/rm9/8pq677jpJ0o9//GOVlZXpqaee0s0333x+qwUAjBvD+jegpqYmtbS0aOnSpYPfSyQSWrhwoXbs2HHG/5NMJtXR0THkAgAY/4Y1gFpaWiRJZWVlQ75fVlY2+LMPqq+vVyKRGLxUV1cP55IAAKOU91fBrVu3Tu3t7YOXw4cP+14SAOACGNYAKi8vlyS1trYO+X5ra+vgzz4oHo+rsLBwyAUAMP4NawBNnTpV5eXl2rr1T29s7Ojo0CuvvKLa2trh/FUAgDHO/Cq4rq4uHThwYPDrpqYm7dmzR8XFxaqpqdHdd9+tf/zHf9TFF1+sqVOn6lvf+pYqKyt1/fXXD+e6AQBjnDmAdu3apS984QuDX69du1aStHr1am3cuFFf+9rX1N3drdtvv11tbW363Oc+py1btjiP1TktSAfKpAOn2pxs983o7ek0rSMk93E5QeC23tOyou4jalLdtnUf3/sr59pYv+2Vh1m5tgfO/Z3u/XuTtuswlshxrq2qyDX17utyf+9aW5ftOkmG3dctSad6up1rW9ttQ6GajrpvZ3GB++1BkmZPcK9tT9nWHQq7n1PmXn6FqXdfr/v1LUmHmv7gXHvpJfNNvadf7D5GqLXFfbSOJIVU4VxbXOy+M7Pjbuc2cwAtXrz4I0+0oVBIDzzwgB544AFrawDAJ4j3V8EBAD6ZCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBfmUTwXSiZIKxO4zZ3Ky3Wf8XXq1HHTOiIR96soEo6YeocjIefa9/btNvVuP/CGc+2kmG3+Wtx4tyUWcb9ecuK2tUTC7tfhQDJl6j2QdJ97Fs9LmHr3DtiuxHDafS1Ti2y9I6G0c+2B9/tNvXd1uPeumeg+G1GSLi9zv92//Yc9pt5vvbnLVN/dddK5NlFUbOo9qeTMH2VzJhdPn2nqbRtf6b4vOx3nP/IICADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPBi1I7iCZRRoIxTbSQr6tw3N6/QtI6W5veca7v7+ky91dfrXNq1+2VT63hPt3NtlnG2TkTuY2EkKcswLiecto3i6e90v877jaOSooYRT6ls2yievJTtOvzMFe4jVvIrbeNYerrcj5Xf7fy9qff2fUeda1s7bWN+ZkxyG/ciSdlHbKOsdjYdM9UPJN3X/r/2/M7U+zfbtzjXfn7J/27qnZ2T7Vwblvvt2L0nAAAeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAF6N2FlxFWZVycnIcq91zNB53n+8lSTmG2XE9p06Yep/6vft8t3DLIVPvAcP8tXTK1FpBxjYTqj/lNtNPkrq73WslKWQYHdcbS5t6F1VOda6t+tSfm3pHswtM9fGiic612ZPnmHoHIffbz9HwJlNvNf3UubQ9bds/HRH322bopPtMOkkKdbvPaZSkzID7qfTw22+bej+7+SfOtRWTa0y958xf4Fw7MOB+oujvTzrV8QgIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8GLUjuLpT/UrnBVxqk2n3EdEpJPdpnUkW44413b89iVT70zzO+7Flpkzkiz3LTK2CSgaSNlG8cSzDGvP2LYzryDfuTZRahvDlKia7lw78bKrTb0zBZNN9QOG6yUUtd2sk11tzrUTZ37G1PvqVXHn2kRhnqn37Msuc67d/4eDpt4v/uR/mupz3DdTqaDD1PvA/n3Otdu2/sLUe8Yl7mObsg0bGc6KutU5dwQAYBgRQAAAL8wBtH37dl177bWqrKxUKBTSU089NeTnt9xyi0Kh0JDLihUrhmu9AIBxwhxA3d3dmj9/vtavX3/WmhUrVqi5uXnw8vjjj5/XIgEA44/5RQgrV67UypUrP7ImHo+rvLz8nBcFABj/RuRvQNu2bVNpaalmzpypO++8UydPnjxrbTKZVEdHx5ALAGD8G/YAWrFihX784x9r69at+ud//mc1NDRo5cqVSp/l0w7r6+uVSCQGL9XV1cO9JADAKDTs7wO6+eabB/89d+5czZs3T9OnT9e2bdu0ZMmSD9WvW7dOa9euHfy6o6ODEAKAT4ARfxn2tGnTVFJSogMHDpzx5/F4XIWFhUMuAIDxb8QD6MiRIzp58qQqKipG+lcBAMYQ81NwXV1dQx7NNDU1ac+ePSouLlZxcbHuv/9+rVq1SuXl5Tp48KC+9rWvacaMGVq+fPmwLhwAMLaZA2jXrl36whe+MPj16b/frF69Whs2bNDevXv1b//2b2pra1NlZaWWLVumf/iHf1A8bhiWJKn3+GEFjv/n1B9+59x34MR7pnV0NR93rg26bK/gi4bdZ6oNZGzz14LAfXZYv3G2W1d3xlSfJff+4ZDtQXm/4UF8rOZTpt4TFlznXlxQaurd2d1rqg+F3G+qhYkiU++Y48xFSZpc+r6pd+SyS5xruwdMrdWfcZs3JkmTa6aaei9efKWp/oUtzzrXnjzVaeqtsPtt+RfPPmlqPRC47/tF1yxzru3pcZu5aQ6gxYsXf+TJ7bnnnrO2BAB8AjELDgDgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPBi2D8PaLgc/83/q3iWWz4Gbe7z3WJyn6skSZE+97lnQdiW5xHDCLaIsXcs7L7ukG0UnFJn/mzBs+rut9VbdL7f5Vz7xq9fNfVO5lY615bVTjD1DueVmerTGfcrvaWlxdQ7np3jXNsXts10/P9e3OZc2/reYVPvorxc59qOXtvsvZb2Y6b6oy0nnGt7jbMUM4F7/Ym2o6be/2PjBufaX/3qBefas30A6QfxCAgA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwYtSO4ol1NyvmOKumcnKhc9+sjG0uzLFIn3PtiXbbiA3HaRWSpOws27ycwmz3+xaxLNt4olDYtpaQ4W5OPGJqraihd09Hq6n3u/tfd64NTbvC1DtRVWyql9yv867OdlPnnJj7aWCnYRyLJL249RfOtcGAbcZTOOq+7nDMdmAl+2235ffb3c8rgWFfSlJR8UTn2jkXzzT1vmTWLOfaaDTmXNvf36+9r3787YdHQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwItROwtuUkGW8/yz4nz3OU+hTNS0jt6upHNte5dtxlNqwL02GrHNayvMc19Ldtw29yrbOAsu4jjTT5KMrRXJcr8PFS5K2HpXXOJce6Lbdl+ur/WEqT6VSjnXTiorNfXu73nfufa1V39r6t3e0eVcmxywzWvLzXc/WMoKck29uzt7TPVV1dXOtTVTp5t6z54737n2srmfNvWeUOw+kzBkOAX19PTofzz2rx9bxyMgAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwItRO4onO5JRjuMIl1Sv+7icvl73kSaS1NvrXus4OWhQfty9Nmy8qxAxzM3Iz7Y1jxqPGsuAlXDIdiUmQ+7dBwonmnr3ZxU618aN+z6QbbRSNO5+sMSzbDvo0JG3nWtPHG819S4omeJcO/C+bTxRosB9rNaEkkpT72h2v6l+0iT3kTZZMdvIoWPNjc61kZD7uVCSiidOcq4tq6hxru11PHHyCAgA4IUpgOrr63XFFVeooKBApaWluv7669XYODSd+/r6VFdXp4kTJyo/P1+rVq1Sa6vtXhMAYPwzBVBDQ4Pq6uq0c+dOPf/880qlUlq2bJm6u7sHa+655x4988wzevLJJ9XQ0KCjR4/qxhtvHPaFAwDGNtOTxVu2bBny9caNG1VaWqrdu3dr0aJFam9v16OPPqpNmzbpmmuukSQ99thjuvTSS7Vz50599rOfHb6VAwDGtPP6G1B7e7skqfg/P1Ni9+7dSqVSWrp06WDNrFmzVFNTox07dpyxRzKZVEdHx5ALAGD8O+cAymQyuvvuu3XVVVdpzpw5kqSWlhbFYjEVFRUNqS0rK1NLS8sZ+9TX1yuRSAxeqg0f7AQAGLvOOYDq6uq0b98+PfHEE+e1gHXr1qm9vX3wcvjw4fPqBwAYG87pfUBr1qzRs88+q+3bt6uqqmrw++Xl5erv71dbW9uQR0Gtra0qLy8/Y694PK644T0OAIDxwfQIKAgCrVmzRps3b9aLL76oqVOnDvn5ggULFI1GtXXr1sHvNTY26tChQ6qtrR2eFQMAxgXTI6C6ujpt2rRJTz/9tAoKCgb/rpNIJJSTk6NEIqFbb71Va9euVXFxsQoLC3XXXXeptraWV8ABAIYwBdCGDRskSYsXLx7y/ccee0y33HKLJOl73/uewuGwVq1apWQyqeXLl+tHP/rRsCwWADB+mAIoCD5+flV2drbWr1+v9evXn/OiJGmgN6WU43C1zi73+W6pAdvQrpBhNllBjqm1goz7PLCMrbU6e93Xne0+UkuSFC+0vXYlE7ivPhq1zcnKznef15Y/41JT744JFc61eTl5pt4TihKm+lhOrnNtTpZtztxbb+1zru3qt+2fuZdf7lz7+t5fm3rHYu7HYTzb9nfmiOMcytPa2878Kt8z6fkvb9x3ERhuP50dp0y9L5o227l24iT3eXoDAwNOdcyCAwB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALw4p49juBC6ejIacByH0dnvPjYjZhxTUpDj3jsrah3z457/6bRt3YbpHcoM2HpHZKuPRd0Ps2iObS5Qn2EETlZisqn3JTNnOdeGcotMvWN5Bab6eNj9Om8+sMfU+9W9e51r33m3ydT78LGjzrXxqO3+cF5usXNtd8f7pt5Z0ZipPp7rvj/z8otMvfML3Mc2zb38KlPvS2cvcK7NKXAfe+U6bohHQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwItROwsulZTCEbfafsMsuIJs47ypuKHYcXbdaYbxXsqkTa0Vibg3Dxvvh2SM9ZG45TCzXYfZcfcdlG0bM6cgk3SuzcqyXSfRkG2HHt/7onPtL5/6d1Pvt/bvd64NyXggDrhfh5Fs97l+ktTX2+Ncmx2znerKyspM9bPmuM9gm1RWZepdUOg+825C8SRT7+xc9+s8Zrituc655BEQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4MWoHcVTkBdStuNom+y4+/iWwoKYaR2xbPfasHFMSSjIONf2D9juK+RG3XunjeNvIsaRQ11p97WnU+7rlqTCVMq9OLDtnyDlPkYmHAyYencffctU/6vnNjvXvrjrNVPvZNpwGjDeZS0tr3aunTXn06bezUffc649efyIqXdX10lTfVhdzrUVlVNMvUsra9yLbTdNKeN+e4sbRvFk0m63NR4BAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAAL0btLLj8bCnHcXU9Sfd5RqGQbdaYQu7DlcLGOUwpw2iygYxtjlnKMJosOydi6h2J2upTQeBcmxU3DN+T1B+f4Fwbyio29Zbc5wZmZwwz6SS927jXVL/11beda7vDeabeuTH3/dObth3k8xdc7Vy7bMVfmHqHw+73n48dbzH17unpMNUXT3A/DnMLCky9A7mfs7JCxttyliECDLMrXWt5BAQA8MIUQPX19briiitUUFCg0tJSXX/99WpsbBxSs3jxYoVCoSGXO+64Y1gXDQAY+0wB1NDQoLq6Ou3cuVPPP/+8UqmUli1bpu7u7iF1t912m5qbmwcvDz300LAuGgAw9pn+BrRly5YhX2/cuFGlpaXavXu3Fi1aNPj93NxclZeXD88KAQDj0nn9Dai9vV2SVFw89I+7P/nJT1RSUqI5c+Zo3bp16unpOWuPZDKpjo6OIRcAwPh3zq+Cy2Qyuvvuu3XVVVdpzpw5g9//0pe+pClTpqiyslJ79+7V17/+dTU2NurnP//5GfvU19fr/vvvP9dlAADGqHMOoLq6Ou3bt08vv/zykO/ffvvtg/+eO3euKioqtGTJEh08eFDTp0//UJ9169Zp7dq1g193dHSoutr9Y3wBAGPTOQXQmjVr9Oyzz2r79u2qqqr6yNqFCxdKkg4cOHDGAIrH46bPGgcAjA+mAAqCQHfddZc2b96sbdu2aerUqR/7f/bs2SNJqqioOKcFAgDGJ1MA1dXVadOmTXr66adVUFCglpY/vrs4kUgoJydHBw8e1KZNm/Tnf/7nmjhxovbu3at77rlHixYt0rx580ZkAwAAY5MpgDZs2CDpj282/a8ee+wx3XLLLYrFYnrhhRf08MMPq7u7W9XV1Vq1apW++c1vDtuCAQDjg/kpuI9SXV2thoaG81rQabGYFHNcXTJwfzV5f9owJE1SlqE8K8f2qvZolvtcrfx41NQ74z7eSzm21koaZnBJkmLus69yyqaYWveUfdq5Np1jfBo45T5XK5G2zeo7+O4RU/0fjnU51xYU5Jp6h8LuM76mT7c9kzHz0gXOtRnjvMNEYZFzbWGh+6w2SeroajfVWwZB5ubaZsGFZBwyaWE4T2QMMx0/LitOYxYcAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4MU5fx7QSIuEQsoKuY2gsEypSQ4YZk9IyqQtYzBsIzOyou4Lj7jOJfpPQcZ9hlAqXmjqHam+3FSfU3mpc215zQxT7/cz7mNNTrZ3m3pPKJnoXHv42FFT71+8vNdU35dy358J4+SW7Lx859olf3aDqffc+Vc412YC25isUJblNmG7rx3PzjHVW0TCtttyJOK+9pDjOXOQ4XSYzriPbEo7zgLjERAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPBi1M6Ck9zHFGVnu88/anvfNguuvde9PhRzn5UkSTkR93VH+lKm3qH8hHNt1uzlpt4TZi421UcKipxr29O2/RM2zKeacfFkU+9jp0451/5fj2409d65t9FUX5jnflMdGOgx9U4UVTnX1lw0y9Q7P999Vl9qoN/UeyCddq8dcK+VpKxo3FSvjHt/y5xGSYpkuc+lCxxnsP3pPxjOb4a2rrU8AgIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8GLWjeLpSkutUlpPt7uMk3j1lG1UxYBgNkzGM1pGk4rT7eJ1YXp6pd+KSJc61WVM+a+qdieeb6nu6up1rO9rbTb0TCfeRQweb3jb1/r//n0eda3fs2GHqHXYeNPVHsWjEuTYnbrtfWVpe6VxbVFxi6h3Jcl9LKBw19c5Ku5++UmHbKJ4Bw21TkumufChi2z8hwxCc1IBt3amk+/ijSNT9+k47jkniERAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPBi1M6C2/teoJhjPB58332uVn6BbV5bb797/bFDGVPv2aV9zrWT8spMvfMTU5xrI8b5UW2nWk31WZGYc+2AcS0v/epl59rnn3/B1PsPf2h0rg0C23EVCtnqsyLux3hW1NY7O7fAuba3L2nq3dvnPmssFjPOgstyn48XcS+VJKUGbNdhOhhwrg2Fbff7g8Cw77Nsp/Rw2Lad7utwu8J5BAQA8MIUQBs2bNC8efNUWFiowsJC1dbW6pe//OXgz/v6+lRXV6eJEycqPz9fq1atUmur7d4yAOCTwRRAVVVVevDBB7V7927t2rVL11xzja677jq9/vrrkqR77rlHzzzzjJ588kk1NDTo6NGjuvHGG0dk4QCAsc30hOG111475Ot/+qd/0oYNG7Rz505VVVXp0Ucf1aZNm3TNNddIkh577DFdeuml2rlzpz77WdtnzgAAxrdz/htQOp3WE088oe7ubtXW1mr37t1KpVJaunTpYM2sWbNUU1PzkR/WlUwm1dHRMeQCABj/zAH02muvKT8/X/F4XHfccYc2b96s2bNnq6WlRbFYTEVFRUPqy8rK1NLSctZ+9fX1SiQSg5fq6mrzRgAAxh5zAM2cOVN79uzRK6+8ojvvvFOrV6/WG2+8cc4LWLdundrb2wcvhw8fPudeAICxw/w+oFgsphkzZkiSFixYoN/97nf6/ve/r5tuukn9/f1qa2sb8iiotbVV5eXlZ+0Xj8cVj8ftKwcAjGnn/T6gTCajZDKpBQsWKBqNauvWrYM/a2xs1KFDh1RbW3u+vwYAMM6YHgGtW7dOK1euVE1NjTo7O7Vp0yZt27ZNzz33nBKJhG699VatXbtWxcXFKiws1F133aXa2lpeAQcA+BBTAB07dkx/+Zd/qebmZiUSCc2bN0/PPfec/uzP/kyS9L3vfU/hcFirVq1SMpnU8uXL9aMf/eicFnbkVEhRx3ElpwbcR1VkR2zPOvZG0u61hnVIUk/gvpbe3m5T766T7m8ALp1gG/PT1tVpqn/tzbecaxt+/Yqp95uNB51ru7t6Tb0jljElIdu+j9qmzijL8FxFJmObO3PqlPv+3Pv7XabeF02b4VxbWnb2p+rPJD/ffYRQNGZ7mj8raqsPZwznFcNoHUkaGHAf8yPjZJ1wxP3AChuahx1nH5nOxo8++uhH/jw7O1vr16/X+vXrLW0BAJ9AzIIDAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhhnoY90oL/HFMxYBhXkTbUpjLGMRiWemPv/rR7fd9AxtS7N9nvXNvTaxtR09vbZ6pPGtaSTruPPpL+dLyMhJHtbavPGI6ttOG4kqRUyn3US1+fbd/39vQ413Z328ZNhQyjYaKxlKm3VSZjOG6NOz8IDLf9ERzFY7m+u7u7JH38bSgUjOSt7BwcOXKED6UDgHHg8OHDqqqqOuvPR10AZTIZHT16VAUFBQr9l2GkHR0dqq6u1uHDh1VYWOhxhSOL7Rw/PgnbKLGd481wbGcQBOrs7FRlZaXC4bM/yhp1T8GFw+GPTMzCwsJxvfNPYzvHj0/CNkps53hzvtuZSCQ+toYXIQAAvCCAAABejJkAisfjuu+++xSP2z4oaqxhO8ePT8I2SmzneHMht3PUvQgBAPDJMGYeAQEAxhcCCADgBQEEAPCCAAIAeDFmAmj9+vW66KKLlJ2drYULF+q3v/2t7yUNq29/+9sKhUJDLrNmzfK9rPOyfft2XXvttaqsrFQoFNJTTz015OdBEOjee+9VRUWFcnJytHTpUu3fv9/PYs/Dx23nLbfc8qF9u2LFCj+LPUf19fW64oorVFBQoNLSUl1//fVqbGwcUtPX16e6ujpNnDhR+fn5WrVqlVpbWz2t+Ny4bOfixYs/tD/vuOMOTys+Nxs2bNC8efMG32xaW1urX/7yl4M/v1D7ckwE0E9/+lOtXbtW9913n37/+99r/vz5Wr58uY4dO+Z7acPqsssuU3Nz8+Dl5Zdf9r2k89Ld3a358+dr/fr1Z/z5Qw89pB/84Ad65JFH9MorrygvL0/Lly83D7z07eO2U5JWrFgxZN8+/vjjF3CF56+hoUF1dXXauXOnnn/+eaVSKS1btmzIANF77rlHzzzzjJ588kk1NDTo6NGjuvHGGz2u2s5lOyXptttuG7I/H3roIU8rPjdVVVV68MEHtXv3bu3atUvXXHONrrvuOr3++uuSLuC+DMaAK6+8Mqirqxv8Op1OB5WVlUF9fb3HVQ2v++67L5g/f77vZYwYScHmzZsHv85kMkF5eXnwne98Z/B7bW1tQTweDx5//HEPKxweH9zOIAiC1atXB9ddd52X9YyUY8eOBZKChoaGIAj+uO+i0Wjw5JNPDta8+eabgaRgx44dvpZ53j64nUEQBJ///OeDv/mbv/G3qBEyYcKE4F/+5V8u6L4c9Y+A+vv7tXv3bi1dunTwe+FwWEuXLtWOHTs8rmz47d+/X5WVlZo2bZq+/OUv69ChQ76XNGKamprU0tIyZL8mEgktXLhw3O1XSdq2bZtKS0s1c+ZM3XnnnTp58qTvJZ2X9vZ2SVJxcbEkaffu3UqlUkP256xZs1RTUzOm9+cHt/O0n/zkJyopKdGcOXO0bt069Rg+dmK0SafTeuKJJ9Td3a3a2toLui9H3TDSDzpx4oTS6bTKysqGfL+srExvvfWWp1UNv4ULF2rjxo2aOXOmmpubdf/99+vqq6/Wvn37VFBQ4Ht5w66lpUWSzrhfT/9svFixYoVuvPFGTZ06VQcPHtTf//3fa+XKldqxY4cikYjv5ZllMhndfffduuqqqzRnzhxJf9yfsVhMRUVFQ2rH8v4803ZK0pe+9CVNmTJFlZWV2rt3r77+9a+rsbFRP//5zz2u1u61115TbW2t+vr6lJ+fr82bN2v27Nnas2fPBduXoz6APilWrlw5+O958+Zp4cKFmjJlin72s5/p1ltv9bgynK+bb7558N9z587VvHnzNH36dG3btk1LlizxuLJzU1dXp3379o35v1F+nLNt5+233z7477lz56qiokJLlizRwYMHNX369Au9zHM2c+ZM7dmzR+3t7fr3f/93rV69Wg0NDRd0DaP+KbiSkhJFIpEPvQKjtbVV5eXlnlY18oqKinTJJZfowIEDvpcyIk7vu0/afpWkadOmqaSkZEzu2zVr1ujZZ5/VSy+9NORjU8rLy9Xf36+2trYh9WN1f55tO89k4cKFkjTm9mcsFtOMGTO0YMEC1dfXa/78+fr+979/QfflqA+gWCymBQsWaOvWrYPfy2Qy2rp1q2praz2ubGR1dXXp4MGDqqio8L2UETF16lSVl5cP2a8dHR165ZVXxvV+lf74qb8nT54cU/s2CAKtWbNGmzdv1osvvqipU6cO+fmCBQsUjUaH7M/GxkYdOnRoTO3Pj9vOM9mzZ48kjan9eSaZTEbJZPLC7sthfUnDCHniiSeCeDwebNy4MXjjjTeC22+/PSgqKgpaWlp8L23Y/O3f/m2wbdu2oKmpKfj1r38dLF26NCgpKQmOHTvme2nnrLOzM3j11VeDV199NZAUfPe73w1effXV4N133w2CIAgefPDBoKioKHj66aeDvXv3Btddd10wderUoLe31/PKbT5qOzs7O4OvfvWrwY4dO4KmpqbghRdeCD796U8HF198cdDX1+d76c7uvPPOIJFIBNu2bQuam5sHLz09PYM1d9xxR1BTUxO8+OKLwa5du4La2tqgtrbW46rtPm47Dxw4EDzwwAPBrl27gqampuDpp58Opk2bFixatMjzym2+8Y1vBA0NDUFTU1Owd+/e4Bvf+EYQCoWC//iP/wiC4MLtyzERQEEQBD/84Q+DmpqaIBaLBVdeeWWwc+dO30saVjfddFNQUVERxGKxYPLkycFNN90UHDhwwPeyzstLL70USPrQZfXq1UEQ/PGl2N/61reCsrKyIB6PB0uWLAkaGxv9LvocfNR29vT0BMuWLQsmTZoURKPRYMqUKcFtt9025u48nWn7JAWPPfbYYE1vb2/w13/918GECROC3Nzc4IYbbgiam5v9LfocfNx2Hjp0KFi0aFFQXFwcxOPxYMaMGcHf/d3fBe3t7X4XbvRXf/VXwZQpU4JYLBZMmjQpWLJkyWD4BMGF25d8HAMAwItR/zcgAMD4RAABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAv/n/DP6CfiBomtAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34\n",
            "fox\n",
            "12\n",
            "medium_mammals\n"
          ]
        }
      ],
      "source": [
        "num2 = 5\n",
        "\n",
        "img_selected = x_train_own[num2]\n",
        "plt.imshow(img_selected)\n",
        "plt.show()\n",
        "\n",
        "print(y_train_own[num2][0])\n",
        "print(labels_fine[y_train_own[num2][0]])\n",
        "print(y_train_own[num2][1])\n",
        "print(labels_coarse[y_train_own[num2][1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Ua6ihbLrQSh-",
        "outputId": "84e8aa28-fefb-438f-9746-cf366475af1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ keras_tensor_40CLONE      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flattened_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ keras_tensor_40CLONE[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_512 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │ flattened_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_256 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_512[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense_256[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ fine_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │ dense_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ coarse_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │ dense_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ keras_tensor_40CLONE      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flattened_input (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ keras_tensor_40CLONE[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_512 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │      \u001b[38;5;34m1,573,376\u001b[0m │ flattened_input[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_256 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dense_512[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_128 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dense_256[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_128[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ fine_output (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │          \u001b[38;5;34m6,500\u001b[0m │ dense_64[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ coarse_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │          \u001b[38;5;34m1,300\u001b[0m │ dense_64[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,753,656</span> (6.69 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,753,656\u001b[0m (6.69 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,753,656</span> (6.69 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,753,656\u001b[0m (6.69 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#INTENTO CON MAS CAPAS\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Number of fine-grain (100) and coarse-grain (20) classes\n",
        "fine_classes = 100\n",
        "coarse_classes = 20\n",
        "\n",
        "\n",
        "# Aquí usaríamos x_train como data_entrenamiento\n",
        "\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = layers.Input(shape=(32, 32, 3), name=\"matrix_input\")  # CIFAR-100 images\n",
        "\n",
        "# normalization\n",
        "normalization_layer = layers.Normalization(axis=-1, name=\"normalization_layer\")\n",
        "normalization_layer.adapt(x_train)\n",
        "input_layer = normalization_layer(input_layer)\n",
        "flatten_layer = layers.Flatten(name=\"flattened_input\")(input_layer)\n",
        "# Hidden layers\n",
        "dense_512 = layers.Dense(512, activation='relu', name=\"dense_512\")(flatten_layer)\n",
        "dense_256 = layers.Dense(256, activation='relu', name=\"dense_256\")(dense_512)\n",
        "dense_128 = layers.Dense(128, activation='relu', name=\"dense_128\")(dense_256)\n",
        "dense_64 = layers.Dense(64, activation='relu', name=\"dense_64\")(dense_128)\n",
        "\n",
        "# Fine-grain prediction branch (100 classes)\n",
        "fine_output = layers.Dense(fine_classes,\n",
        "                           activation='softmax',\n",
        "                           name='fine_output')(dense_64)\n",
        "\n",
        "# Coarse-grain prediction branch (20 classes)\n",
        "coarse_output = layers.Dense(coarse_classes,\n",
        "                             activation='softmax',\n",
        "                             name='coarse_output')(dense_64)\n",
        "\n",
        "# Define the model with two outputs\n",
        "model = models.Model(inputs=input_layer, outputs=[fine_output, coarse_output])\n",
        "\n",
        "# Compile the model with separate loss functions for each output\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={'fine_output': 'sparse_categorical_crossentropy', 'coarse_output': 'sparse_categorical_crossentropy'},\n",
        "    metrics={'fine_output': 'accuracy', 'coarse_output': 'accuracy'}\n",
        ")\n",
        "\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "qh6SzooGDmDF",
        "outputId": "d14887be-59fe-4f59-ea30-c28bd04e8b16"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ matrix_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ normalization_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │ matrix_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flattened_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ normalization_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_512 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │ flattened_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_512[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_256 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_256[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ fine_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │ dense_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ coarse_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │ dense_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ matrix_input (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ normalization_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m7\u001b[0m │ matrix_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mNormalization\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flattened_input (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ normalization_layer[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_512 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │      \u001b[38;5;34m1,573,376\u001b[0m │ flattened_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_512[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_256 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_256[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_128 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ fine_output (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │          \u001b[38;5;34m6,500\u001b[0m │ dense_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ coarse_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │          \u001b[38;5;34m1,300\u001b[0m │ dense_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,753,663</span> (6.69 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,753,663\u001b[0m (6.69 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,753,656</span> (6.69 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,753,656\u001b[0m (6.69 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> (32.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7\u001b[0m (32.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#INTENTO CON DROPOUT,\n",
        "# USE ESTE AL FINAL, convine mas capas y dropout. ACA ESTA LA POSTA\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Número de clases\n",
        "fine_classes = 100\n",
        "coarse_classes = 20\n",
        "\n",
        "# Entrada y normalización\n",
        "input_layer = layers.Input(shape=(32, 32, 3), name=\"matrix_input\")\n",
        "normalization_layer = layers.Normalization(axis=-1, name=\"normalization_layer\")\n",
        "normalization_layer.adapt(x_train)  # Ajusta según los datos de entrenamiento\n",
        "\n",
        "# Estructura de la red\n",
        "x = normalization_layer(input_layer)\n",
        "flatten_layer = layers.Flatten(name=\"flattened_input\")(x)\n",
        "\n",
        "# Capas ocultas con mayor capacidad y Dropout\n",
        "dense_512 = layers.Dense(512, activation='relu', name=\"dense_512\")(flatten_layer)\n",
        "dropout_512 = layers.Dropout(0.2)(dense_512)\n",
        "dense_256 = layers.Dense(256, activation='relu', name=\"dense_256\")(dropout_512)\n",
        "dropout_256 = layers.Dropout(0.2)(dense_256)\n",
        "dense_128 = layers.Dense(128, activation='relu', name=\"dense_128\")(dropout_256)\n",
        "dense_64 = layers.Dense(64, activation='relu', name=\"dense_64\")(dense_128)\n",
        "\n",
        "\n",
        "# Fine-grain prediction branch (100 classes)\n",
        "fine_output = layers.Dense(fine_classes,\n",
        "                           activation='softmax',\n",
        "                           name='fine_output')(dense_64)\n",
        "\n",
        "# Coarse-grain prediction branch (20 classes)\n",
        "coarse_output = layers.Dense(coarse_classes,\n",
        "                             activation='softmax',\n",
        "                             name='coarse_output')(dense_64)\n",
        "\n",
        "\n",
        "# Define el modelo con dos salidas\n",
        "model = models.Model(inputs=input_layer, outputs=[fine_output, coarse_output])\n",
        "\n",
        "# Compile the model with separate loss functions for each output\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={'fine_output': 'sparse_categorical_crossentropy', 'coarse_output': 'sparse_categorical_crossentropy'},\n",
        "    metrics={'fine_output': 'accuracy', 'coarse_output': 'accuracy'}\n",
        ")\n",
        "\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CSY8g94VS9kT"
      },
      "outputs": [],
      "source": [
        "#COMENTAMOS ESTE GRAFICO GIGANTE DE IVO\n",
        "#from tensorflow.keras.utils import plot_model\n",
        "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_bnmy0cWSTB",
        "outputId": "87289e49-57b8-4ef2-ea68-8cf43f84e74c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(40000, 32, 32, 3)\n",
            "(40000, 2)\n",
            "[42 95 19 ... 26 64 47]\n"
          ]
        }
      ],
      "source": [
        "print(x_train_own.shape)\n",
        "print(y_train_own.shape)\n",
        "\n",
        "lista = y_train_own[:,0]\n",
        "print(lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sinBvVxlnJ2-",
        "outputId": "8d52a0c8-46dd-439b-84f2-83d23282ae20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train_own shape: (40000, 32, 32, 3)\n",
            "y_train_own shape: (40000, 2)\n",
            "x_val_own shape: (10000, 32, 32, 3)\n",
            "y_val_own shape: (10000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(f\"x_train_own shape: {x_train_own.shape}\")\n",
        "print(f\"y_train_own shape: {y_train_own.shape}\")\n",
        "print(f\"x_val_own shape: {x_val_own.shape}\")\n",
        "print(f\"y_val_own shape: {y_val_own.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usLt8dSjB_ik"
      },
      "outputs": [],
      "source": [
        "#AGREGUE ACA UN PAR QUE ESTABAN EN EL OTRO\n",
        "rlrop = ReduceLROnPlateau(\n",
        "    monitor = \"val_accuracy\",\n",
        "    factor = 0.5,\n",
        "    patience = 3,\n",
        "    verbose = 1,\n",
        "    min_lr = 1e-5\n",
        ")\n",
        "\n",
        "es = EarlyStopping(\n",
        "    monitor = \"val_accuracy\",\n",
        "    patience = 5,\n",
        "    verbose = 1,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "mc = ModelCheckpoint(\n",
        "    \"best_weights.weights.h5\",\n",
        "    monitor = \"val_accuracy\",\n",
        "    verbose = 1,\n",
        "    save_best_only = True,\n",
        "    save_weights_only = True,\n",
        "\n",
        ")\n",
        "\n",
        "tb = TensorBoard(\n",
        "    log_dir = \"logs\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-mAn9JGqTLgX",
        "outputId": "eada8aa0-8a37-4f37-90a1-91b87b071473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - coarse_output_accuracy: 0.1407 - fine_output_accuracy: 0.0362 - loss: 7.2404{'coarse_output_accuracy': 0.1707250028848648, 'fine_output_accuracy': 0.05597500130534172, 'loss': 6.901590824127197, 'val_coarse_output_accuracy': 0.22439999878406525, 'val_fine_output_accuracy': 0.08659999817609787, 'val_loss': 6.417306423187256}\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 27ms/step - coarse_output_accuracy: 0.1408 - fine_output_accuracy: 0.0363 - loss: 7.2396 - val_coarse_output_accuracy: 0.2244 - val_fine_output_accuracy: 0.0866 - val_loss: 6.4173\n",
            "Epoch 2/10\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - coarse_output_accuracy: 0.2295 - fine_output_accuracy: 0.0976 - loss: 6.3945{'coarse_output_accuracy': 0.23444999754428864, 'fine_output_accuracy': 0.10102500021457672, 'loss': 6.349236965179443, 'val_coarse_output_accuracy': 0.2563000023365021, 'val_fine_output_accuracy': 0.11249999701976776, 'val_loss': 6.1888508796691895}\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 28ms/step - coarse_output_accuracy: 0.2295 - fine_output_accuracy: 0.0976 - loss: 6.3945 - val_coarse_output_accuracy: 0.2563 - val_fine_output_accuracy: 0.1125 - val_loss: 6.1889\n",
            "Epoch 3/10\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - coarse_output_accuracy: 0.2621 - fine_output_accuracy: 0.1170 - loss: 6.1495{'coarse_output_accuracy': 0.2619749903678894, 'fine_output_accuracy': 0.1198749989271164, 'loss': 6.145015239715576, 'val_coarse_output_accuracy': 0.2712000012397766, 'val_fine_output_accuracy': 0.1340000033378601, 'val_loss': 6.016561985015869}\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 35ms/step - coarse_output_accuracy: 0.2621 - fine_output_accuracy: 0.1170 - loss: 6.1495 - val_coarse_output_accuracy: 0.2712 - val_fine_output_accuracy: 0.1340 - val_loss: 6.0166\n",
            "Epoch 4/10\n",
            "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - coarse_output_accuracy: 0.2795 - fine_output_accuracy: 0.1391 - loss: 5.9898{'coarse_output_accuracy': 0.27799999713897705, 'fine_output_accuracy': 0.13552500307559967, 'loss': 6.009105205535889, 'val_coarse_output_accuracy': 0.28839999437332153, 'val_fine_output_accuracy': 0.14800000190734863, 'val_loss': 5.937166690826416}\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - coarse_output_accuracy: 0.2795 - fine_output_accuracy: 0.1391 - loss: 5.9898 - val_coarse_output_accuracy: 0.2884 - val_fine_output_accuracy: 0.1480 - val_loss: 5.9372\n",
            "Epoch 5/10\n",
            "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - coarse_output_accuracy: 0.2900 - fine_output_accuracy: 0.1404 - loss: 5.8855{'coarse_output_accuracy': 0.29010000824928284, 'fine_output_accuracy': 0.14315000176429749, 'loss': 5.8924736976623535, 'val_coarse_output_accuracy': 0.29100000858306885, 'val_fine_output_accuracy': 0.1542000025510788, 'val_loss': 5.860006332397461}\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - coarse_output_accuracy: 0.2900 - fine_output_accuracy: 0.1404 - loss: 5.8855 - val_coarse_output_accuracy: 0.2910 - val_fine_output_accuracy: 0.1542 - val_loss: 5.8600\n",
            "Epoch 6/10\n",
            "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - coarse_output_accuracy: 0.3064 - fine_output_accuracy: 0.1609 - loss: 5.7592{'coarse_output_accuracy': 0.30114999413490295, 'fine_output_accuracy': 0.15657499432563782, 'loss': 5.790212154388428, 'val_coarse_output_accuracy': 0.30090001225471497, 'val_fine_output_accuracy': 0.16009999811649323, 'val_loss': 5.805875778198242}\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - coarse_output_accuracy: 0.3064 - fine_output_accuracy: 0.1609 - loss: 5.7593 - val_coarse_output_accuracy: 0.3009 - val_fine_output_accuracy: 0.1601 - val_loss: 5.8059\n",
            "Epoch 7/10\n",
            "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - coarse_output_accuracy: 0.3148 - fine_output_accuracy: 0.1667 - loss: 5.6847{'coarse_output_accuracy': 0.3100000023841858, 'fine_output_accuracy': 0.16329999268054962, 'loss': 5.703409671783447, 'val_coarse_output_accuracy': 0.3095000088214874, 'val_fine_output_accuracy': 0.16680000722408295, 'val_loss': 5.7395100593566895}\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - coarse_output_accuracy: 0.3148 - fine_output_accuracy: 0.1667 - loss: 5.6848 - val_coarse_output_accuracy: 0.3095 - val_fine_output_accuracy: 0.1668 - val_loss: 5.7395\n",
            "Epoch 8/10\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - coarse_output_accuracy: 0.3246 - fine_output_accuracy: 0.1701 - loss: 5.6148{'coarse_output_accuracy': 0.32124999165534973, 'fine_output_accuracy': 0.1701750010251999, 'loss': 5.6379475593566895, 'val_coarse_output_accuracy': 0.3188000023365021, 'val_fine_output_accuracy': 0.1770000010728836, 'val_loss': 5.692567825317383}\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - coarse_output_accuracy: 0.3246 - fine_output_accuracy: 0.1701 - loss: 5.6148 - val_coarse_output_accuracy: 0.3188 - val_fine_output_accuracy: 0.1770 - val_loss: 5.6926\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - coarse_output_accuracy: 0.3355 - fine_output_accuracy: 0.1813 - loss: 5.5252{'coarse_output_accuracy': 0.33147498965263367, 'fine_output_accuracy': 0.17857499420642853, 'loss': 5.561302661895752, 'val_coarse_output_accuracy': 0.3221000134944916, 'val_fine_output_accuracy': 0.18080000579357147, 'val_loss': 5.671888828277588}\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - coarse_output_accuracy: 0.3355 - fine_output_accuracy: 0.1813 - loss: 5.5253 - val_coarse_output_accuracy: 0.3221 - val_fine_output_accuracy: 0.1808 - val_loss: 5.6719\n",
            "Epoch 10/10\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - coarse_output_accuracy: 0.3423 - fine_output_accuracy: 0.1850 - loss: 5.4500{'coarse_output_accuracy': 0.3416999876499176, 'fine_output_accuracy': 0.1829500049352646, 'loss': 5.482916355133057, 'val_coarse_output_accuracy': 0.320499986410141, 'val_fine_output_accuracy': 0.17810000479221344, 'val_loss': 5.70489501953125}\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 27ms/step - coarse_output_accuracy: 0.3423 - fine_output_accuracy: 0.1850 - loss: 5.4500 - val_coarse_output_accuracy: 0.3205 - val_fine_output_accuracy: 0.1781 - val_loss: 5.7049\n"
          ]
        }
      ],
      "source": [
        "#x_train_own, x_val_own, y_train_own, y_val_own = train_test_split(x_train, y_train_union, test_size=0.2, stratify=y_train_union)\n",
        "# SIN LOS OTROS CALLBACKS CON MENOS BATCH\n",
        "history = model.fit(\n",
        "    x = x_train_own,\n",
        "    y = {'fine_output': lista, 'coarse_output': y_train_own[:,1]},\n",
        "    epochs = 10,\n",
        "    batch_size = 32,\n",
        "    validation_data = (x_val_own, {'fine_output': y_val_own[:,0], 'coarse_output': y_val_own[:,1]}),\n",
        "    # Add the following line:\n",
        "    callbacks=[tf.keras.callbacks.LambdaCallback(on_epoch_end=lambda epoch, logs: print(logs if logs is not None else \"No logs available\"))]\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwbd3pqvD7vy",
        "outputId": "24318d93-06e7-4879-e06c-d5adb4378d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - coarse_output_accuracy: 0.1308 - fine_output_accuracy: 0.0387 - loss: 7.2793{'coarse_output_accuracy': 0.1639000028371811, 'fine_output_accuracy': 0.05635000020265579, 'loss': 6.986175060272217, 'val_coarse_output_accuracy': 0.22830000519752502, 'val_fine_output_accuracy': 0.09679999947547913, 'val_loss': 6.454349994659424}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 38ms/step - coarse_output_accuracy: 0.1309 - fine_output_accuracy: 0.0388 - loss: 7.2784 - val_coarse_output_accuracy: 0.2283 - val_fine_output_accuracy: 0.0968 - val_loss: 6.4543 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m  5/625\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - coarse_output_accuracy: 0.1829 - fine_output_accuracy: 0.1010 - loss: 6.4168"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/callback_list.py:96: UserWarning: Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: coarse_output_accuracy,fine_output_accuracy,loss,val_coarse_output_accuracy,val_fine_output_accuracy,val_loss,learning_rate.\n",
            "  callback.on_epoch_end(epoch, logs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_accuracy available, skipping.\n",
            "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - coarse_output_accuracy: 0.2237 - fine_output_accuracy: 0.0935 - loss: 6.4397{'coarse_output_accuracy': 0.23330000042915344, 'fine_output_accuracy': 0.1002499982714653, 'loss': 6.38668966293335, 'val_coarse_output_accuracy': 0.260699987411499, 'val_fine_output_accuracy': 0.12210000306367874, 'val_loss': 6.150067329406738}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - coarse_output_accuracy: 0.2237 - fine_output_accuracy: 0.0935 - loss: 6.4396 - val_coarse_output_accuracy: 0.2607 - val_fine_output_accuracy: 0.1221 - val_loss: 6.1501 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - coarse_output_accuracy: 0.2574 - fine_output_accuracy: 0.1206 - loss: 6.1523{'coarse_output_accuracy': 0.2641499936580658, 'fine_output_accuracy': 0.1242000013589859, 'loss': 6.124065399169922, 'val_coarse_output_accuracy': 0.27799999713897705, 'val_fine_output_accuracy': 0.13750000298023224, 'val_loss': 6.008011341094971}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - coarse_output_accuracy: 0.2574 - fine_output_accuracy: 0.1206 - loss: 6.1522 - val_coarse_output_accuracy: 0.2780 - val_fine_output_accuracy: 0.1375 - val_loss: 6.0080 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - coarse_output_accuracy: 0.2860 - fine_output_accuracy: 0.1378 - loss: 5.9505{'coarse_output_accuracy': 0.28722500801086426, 'fine_output_accuracy': 0.14277499914169312, 'loss': 5.942696571350098, 'val_coarse_output_accuracy': 0.29919999837875366, 'val_fine_output_accuracy': 0.15479999780654907, 'val_loss': 5.835040092468262}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 36ms/step - coarse_output_accuracy: 0.2860 - fine_output_accuracy: 0.1378 - loss: 5.9505 - val_coarse_output_accuracy: 0.2992 - val_fine_output_accuracy: 0.1548 - val_loss: 5.8350 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - coarse_output_accuracy: 0.2994 - fine_output_accuracy: 0.1525 - loss: 5.8163{'coarse_output_accuracy': 0.3013499975204468, 'fine_output_accuracy': 0.15604999661445618, 'loss': 5.810001850128174, 'val_coarse_output_accuracy': 0.31470000743865967, 'val_fine_output_accuracy': 0.17110000550746918, 'val_loss': 5.749093532562256}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - coarse_output_accuracy: 0.2994 - fine_output_accuracy: 0.1525 - loss: 5.8162 - val_coarse_output_accuracy: 0.3147 - val_fine_output_accuracy: 0.1711 - val_loss: 5.7491 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - coarse_output_accuracy: 0.3196 - fine_output_accuracy: 0.1672 - loss: 5.6721{'coarse_output_accuracy': 0.31632500886917114, 'fine_output_accuracy': 0.16532500088214874, 'loss': 5.697872638702393, 'val_coarse_output_accuracy': 0.31310001015663147, 'val_fine_output_accuracy': 0.16590000689029694, 'val_loss': 5.718334674835205}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - coarse_output_accuracy: 0.3196 - fine_output_accuracy: 0.1672 - loss: 5.6721 - val_coarse_output_accuracy: 0.3131 - val_fine_output_accuracy: 0.1659 - val_loss: 5.7183 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - coarse_output_accuracy: 0.3313 - fine_output_accuracy: 0.1746 - loss: 5.5674{'coarse_output_accuracy': 0.3278749883174896, 'fine_output_accuracy': 0.1740500032901764, 'loss': 5.5968241691589355, 'val_coarse_output_accuracy': 0.3237999975681305, 'val_fine_output_accuracy': 0.18150000274181366, 'val_loss': 5.634831428527832}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 48ms/step - coarse_output_accuracy: 0.3313 - fine_output_accuracy: 0.1746 - loss: 5.5674 - val_coarse_output_accuracy: 0.3238 - val_fine_output_accuracy: 0.1815 - val_loss: 5.6348 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - coarse_output_accuracy: 0.3420 - fine_output_accuracy: 0.1861 - loss: 5.4704{'coarse_output_accuracy': 0.34002500772476196, 'fine_output_accuracy': 0.1836249977350235, 'loss': 5.50825309753418, 'val_coarse_output_accuracy': 0.33239999413490295, 'val_fine_output_accuracy': 0.1931000053882599, 'val_loss': 5.590708255767822}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - coarse_output_accuracy: 0.3420 - fine_output_accuracy: 0.1861 - loss: 5.4705 - val_coarse_output_accuracy: 0.3324 - val_fine_output_accuracy: 0.1931 - val_loss: 5.5907 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - coarse_output_accuracy: 0.3514 - fine_output_accuracy: 0.1952 - loss: 5.4264{'coarse_output_accuracy': 0.346574991941452, 'fine_output_accuracy': 0.19177499413490295, 'loss': 5.45395040512085, 'val_coarse_output_accuracy': 0.33550000190734863, 'val_fine_output_accuracy': 0.19099999964237213, 'val_loss': 5.5631513595581055}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - coarse_output_accuracy: 0.3514 - fine_output_accuracy: 0.1952 - loss: 5.4264 - val_coarse_output_accuracy: 0.3355 - val_fine_output_accuracy: 0.1910 - val_loss: 5.5632 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - coarse_output_accuracy: 0.3618 - fine_output_accuracy: 0.2032 - loss: 5.3088{'coarse_output_accuracy': 0.3548249900341034, 'fine_output_accuracy': 0.19802500307559967, 'loss': 5.356417179107666, 'val_coarse_output_accuracy': 0.3402000069618225, 'val_fine_output_accuracy': 0.19609999656677246, 'val_loss': 5.577352523803711}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - coarse_output_accuracy: 0.3618 - fine_output_accuracy: 0.2032 - loss: 5.3089 - val_coarse_output_accuracy: 0.3402 - val_fine_output_accuracy: 0.1961 - val_loss: 5.5774 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - coarse_output_accuracy: 0.3680 - fine_output_accuracy: 0.2077 - loss: 5.2742{'coarse_output_accuracy': 0.36442500352859497, 'fine_output_accuracy': 0.20399999618530273, 'loss': 5.2996439933776855, 'val_coarse_output_accuracy': 0.3379000127315521, 'val_fine_output_accuracy': 0.1996999979019165, 'val_loss': 5.532022476196289}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - coarse_output_accuracy: 0.3680 - fine_output_accuracy: 0.2077 - loss: 5.2742 - val_coarse_output_accuracy: 0.3379 - val_fine_output_accuracy: 0.1997 - val_loss: 5.5320 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - coarse_output_accuracy: 0.3749 - fine_output_accuracy: 0.2120 - loss: 5.1817{'coarse_output_accuracy': 0.3720250129699707, 'fine_output_accuracy': 0.20937499403953552, 'loss': 5.231290817260742, 'val_coarse_output_accuracy': 0.3416999876499176, 'val_fine_output_accuracy': 0.20069999992847443, 'val_loss': 5.530981063842773}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - coarse_output_accuracy: 0.3749 - fine_output_accuracy: 0.2120 - loss: 5.1818 - val_coarse_output_accuracy: 0.3417 - val_fine_output_accuracy: 0.2007 - val_loss: 5.5310 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - coarse_output_accuracy: 0.3851 - fine_output_accuracy: 0.2210 - loss: 5.1218{'coarse_output_accuracy': 0.37687501311302185, 'fine_output_accuracy': 0.21649999916553497, 'loss': 5.183138847351074, 'val_coarse_output_accuracy': 0.33809998631477356, 'val_fine_output_accuracy': 0.193900004029274, 'val_loss': 5.5426130294799805}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 39ms/step - coarse_output_accuracy: 0.3851 - fine_output_accuracy: 0.2210 - loss: 5.1220 - val_coarse_output_accuracy: 0.3381 - val_fine_output_accuracy: 0.1939 - val_loss: 5.5426 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - coarse_output_accuracy: 0.3860 - fine_output_accuracy: 0.2201 - loss: 5.1028{'coarse_output_accuracy': 0.38635000586509705, 'fine_output_accuracy': 0.22030000388622284, 'loss': 5.113360404968262, 'val_coarse_output_accuracy': 0.3472000062465668, 'val_fine_output_accuracy': 0.2094999998807907, 'val_loss': 5.487466335296631}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 34ms/step - coarse_output_accuracy: 0.3860 - fine_output_accuracy: 0.2201 - loss: 5.1028 - val_coarse_output_accuracy: 0.3472 - val_fine_output_accuracy: 0.2095 - val_loss: 5.4875 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - coarse_output_accuracy: 0.3931 - fine_output_accuracy: 0.2286 - loss: 5.0295{'coarse_output_accuracy': 0.39250001311302185, 'fine_output_accuracy': 0.22692500054836273, 'loss': 5.059073448181152, 'val_coarse_output_accuracy': 0.35429999232292175, 'val_fine_output_accuracy': 0.210099995136261, 'val_loss': 5.478176593780518}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - coarse_output_accuracy: 0.3931 - fine_output_accuracy: 0.2286 - loss: 5.0296 - val_coarse_output_accuracy: 0.3543 - val_fine_output_accuracy: 0.2101 - val_loss: 5.4782 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - coarse_output_accuracy: 0.4016 - fine_output_accuracy: 0.2357 - loss: 4.9670{'coarse_output_accuracy': 0.39777499437332153, 'fine_output_accuracy': 0.23145000636577606, 'loss': 5.018877029418945, 'val_coarse_output_accuracy': 0.35010001063346863, 'val_fine_output_accuracy': 0.21119999885559082, 'val_loss': 5.501328945159912}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 34ms/step - coarse_output_accuracy: 0.4016 - fine_output_accuracy: 0.2357 - loss: 4.9672 - val_coarse_output_accuracy: 0.3501 - val_fine_output_accuracy: 0.2112 - val_loss: 5.5013 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - coarse_output_accuracy: 0.4050 - fine_output_accuracy: 0.2377 - loss: 4.9460{'coarse_output_accuracy': 0.4038499891757965, 'fine_output_accuracy': 0.23524999618530273, 'loss': 4.96816349029541, 'val_coarse_output_accuracy': 0.3513999879360199, 'val_fine_output_accuracy': 0.20759999752044678, 'val_loss': 5.487396717071533}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - coarse_output_accuracy: 0.4050 - fine_output_accuracy: 0.2377 - loss: 4.9460 - val_coarse_output_accuracy: 0.3514 - val_fine_output_accuracy: 0.2076 - val_loss: 5.4874 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - coarse_output_accuracy: 0.4145 - fine_output_accuracy: 0.2388 - loss: 4.9168{'coarse_output_accuracy': 0.4112499952316284, 'fine_output_accuracy': 0.2414499968290329, 'loss': 4.924300193786621, 'val_coarse_output_accuracy': 0.35019999742507935, 'val_fine_output_accuracy': 0.21279999613761902, 'val_loss': 5.491016387939453}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 39ms/step - coarse_output_accuracy: 0.4144 - fine_output_accuracy: 0.2388 - loss: 4.9168 - val_coarse_output_accuracy: 0.3502 - val_fine_output_accuracy: 0.2128 - val_loss: 5.4910 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - coarse_output_accuracy: 0.4161 - fine_output_accuracy: 0.2471 - loss: 4.8542{'coarse_output_accuracy': 0.4155749976634979, 'fine_output_accuracy': 0.2455500066280365, 'loss': 4.869810104370117, 'val_coarse_output_accuracy': 0.34869998693466187, 'val_fine_output_accuracy': 0.21050000190734863, 'val_loss': 5.51479434967041}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 34ms/step - coarse_output_accuracy: 0.4161 - fine_output_accuracy: 0.2471 - loss: 4.8543 - val_coarse_output_accuracy: 0.3487 - val_fine_output_accuracy: 0.2105 - val_loss: 5.5148 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - coarse_output_accuracy: 0.4264 - fine_output_accuracy: 0.2494 - loss: 4.7976{'coarse_output_accuracy': 0.4231500029563904, 'fine_output_accuracy': 0.24735000729560852, 'loss': 4.821014404296875, 'val_coarse_output_accuracy': 0.35519999265670776, 'val_fine_output_accuracy': 0.21080000698566437, 'val_loss': 5.474265098571777}\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - coarse_output_accuracy: 0.4264 - fine_output_accuracy: 0.2493 - loss: 4.7976 - val_coarse_output_accuracy: 0.3552 - val_fine_output_accuracy: 0.2108 - val_loss: 5.4743 - learning_rate: 0.0010\n"
          ]
        }
      ],
      "source": [
        "#x_train_own, x_val_own, y_train_own, y_val_own = train_test_split(x_train, y_train_union, test_size=0.2, stratify=y_train_union)\n",
        "# ESTE ES CON EARLY STOP Y ReduceLROnPlateau. SAQUE EL EARLY STOP Y ME DIO MUCHO MEJOR\n",
        "history = model.fit(\n",
        "    x = x_train_own,\n",
        "    y = {'fine_output': lista, 'coarse_output': y_train_own[:,1]},\n",
        "    epochs = 20,\n",
        "    batch_size = 64,\n",
        "    validation_data = (x_val_own, {'fine_output': y_val_own[:,0], 'coarse_output': y_val_own[:,1]}),\n",
        "    # Add the following line:\n",
        "    callbacks=[tf.keras.callbacks.LambdaCallback(on_epoch_end=lambda epoch, logs: print(logs if logs is not None else \"No logs available\")), rlrop,\n",
        "    mc]\n",
        "\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_rn_01",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
