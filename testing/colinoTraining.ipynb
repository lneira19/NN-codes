{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":84511,"databundleVersionId":9468663,"sourceType":"competition"},{"sourceId":9731527,"sourceType":"datasetVersion","datasetId":5955397}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Librerías generales\n\nimport numpy as np\nimport os\nimport pickle\nimport matplotlib.pyplot as plt","metadata":{"id":"utceBhWGgYlM","executionInfo":{"status":"ok","timestamp":1729991889260,"user_tz":180,"elapsed":2,"user":{"displayName":"LUCAS ORBE","userId":"03038966733029419882"}},"execution":{"iopub.status.busy":"2024-10-29T01:00:26.480100Z","iopub.execute_input":"2024-10-29T01:00:26.480535Z","iopub.status.idle":"2024-10-29T01:00:26.492256Z","shell.execute_reply.started":"2024-10-29T01:00:26.480490Z","shell.execute_reply":"2024-10-29T01:00:26.491340Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Lectura de datos","metadata":{"id":"7Pz7thRjgYlN"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pickle\n\n# Define la carpeta de datos (ajusta esto según el nombre que reciban los datos en Kaggle)\ndata_folder_name = '../input/dataselected'  \n\n# Definir una función para obtener los nombres de archivos en una carpeta\ndef getFileNames(folder_name):\n    file_names = os.listdir(folder_name)\n    return file_names\n\nprint(getFileNames(data_folder_name))\n\n# Lectura de archivos '.npy'\nx_test = np.load(f'{data_folder_name}/x_sub_val.npy')\nx_train = np.load(f'{data_folder_name}/x_sub_train_aug.npy')\n\ny_train_coarse = np.load(f'{data_folder_name}/y_sub_train_aug_1.npy')\ny_train_fine = np.load(f'{data_folder_name}/y_sub_train_aug_0.npy')\n\ny_test_coarse = np.load(f'{data_folder_name}/y_sub_val_1.npy')\ny_test_fine = np.load(f'{data_folder_name}/y_sub_val_0.npy')\n\n# Lectura de archivos '.pck'\nwith open('/kaggle/input/dl-itba-cifar-100-2024-q-1/coarse_label_names.pck', \"rb\") as f:\n    coarse_label_names = pickle.load(f)\n\nwith open('/kaggle/input/dl-itba-cifar-100-2024-q-1/fine_label_names.pck', \"rb\") as f:\n    fine_label_names = pickle.load(f)\n\n# Información de las dimensiones de los datos\nprint('Dimensiones de los datos:')\nprint(x_test.shape)\nprint(x_train.shape)\nprint(y_train_coarse.shape)\nprint(y_train_fine.shape)\n\nprint('Cantidad de clases:')\nprint(np.shape(coarse_label_names))\nprint(np.shape(fine_label_names))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a5iVfJM3gYlO","executionInfo":{"status":"ok","timestamp":1729991890061,"user_tz":180,"elapsed":2,"user":{"displayName":"LUCAS ORBE","userId":"03038966733029419882"}},"outputId":"6b0a579c-1893-41fe-e13d-f0edab11b5f8","execution":{"iopub.status.busy":"2024-10-29T01:00:27.873874Z","iopub.execute_input":"2024-10-29T01:00:27.874236Z","iopub.status.idle":"2024-10-29T01:00:52.485010Z","shell.execute_reply.started":"2024-10-29T01:00:27.874198Z","shell.execute_reply":"2024-10-29T01:00:52.483993Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"['x_sub_val.npy', 'y_sub_train_aug_0.npy', 'y_sub_train_aug_1.npy', 'y_sub_val_1.npy', 'x_sub_train_aug.npy', 'y_sub_val_0.npy']\nDimensiones de los datos:\n(10000, 32, 32, 3)\n(1040000, 32, 32, 3)\n(1040000,)\n(1040000,)\nCantidad de clases:\n(20,)\n(100,)\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.layers import Input, Dense, Dropout, Flatten, LayerNormalization,BatchNormalization, Conv2D, MaxPooling2D\nfrom keras.models import Model\nfrom keras.regularizers import l2","metadata":{"execution":{"iopub.status.busy":"2024-10-29T01:00:52.486921Z","iopub.execute_input":"2024-10-29T01:00:52.487543Z","iopub.status.idle":"2024-10-29T01:01:04.148406Z","shell.execute_reply.started":"2024-10-29T01:00:52.487495Z","shell.execute_reply":"2024-10-29T01:01:04.147652Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### MODELO 1","metadata":{}},{"cell_type":"code","source":"#OTRA ESTRUCTURA \n# Entrada y normalización\ninput_layer = Input(shape=(32, 32, 3), name=\"matrix_input\")\n\n# Estructura de la red\nx = BatchNormalization(axis=-1, name=\"normalization_layer\")(input_layer)\nflatten_layer = Flatten(name=\"flattened_input\")(x)\n\n# Ajustes de las capas ocultas y Dropout\ndense_1024 = Dense(1024, activation='relu', name=\"dense_1024\")(flatten_layer)\ndropout_1024 = Dropout(0.3)(dense_1024)\ndense_512 = Dense(512, activation='relu', name=\"dense_512\")(dropout_1024)\ndropout_512 = Dropout(0.2)(dense_512)\ndense_256 = Dense(256, activation='relu', name=\"dense_256\")(dropout_512)\ndropout_256 = Dropout(0.2)(dense_256)\ndense_128 = Dense(128, activation='relu', name=\"dense_128\")(dense_256)\ndense_64 = Dense(64, activation='relu', name=\"dense_64\")(dense_128)\n\n# Salidas\nfine_output = Dense(100, activation='softmax', name='fine_output')(dense_64)\n\n\n# Coarse-grain prediction branch (20 classes)\ncoarse_output = Dense(20,\n                             activation='softmax',\n                             name='coarse_output')(dropout_512)\n\n# Defino el modelo con dos salidas\nmyModel = Model(\n    inputs                  = input_layer,\n    #outputs                 = [fine_output, coarse_output]\n    outputs                 = [fine_output]\n)\n\"\"\"myModel2 = Model(\n    inputs                  = input_layer,\n    outputs                 = [coarse_output]\n)\"\"\"\n\n# Print model summary\nmyModel.summary()\n\n#myModel2.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T00:36:20.376091Z","iopub.execute_input":"2024-10-29T00:36:20.376361Z","iopub.status.idle":"2024-10-29T00:36:21.308492Z","shell.execute_reply.started":"2024-10-29T00:36:20.376331Z","shell.execute_reply":"2024-10-29T00:36:21.307639Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ matrix_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ normalization_layer             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │            \u001b[38;5;34m12\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flattened_input (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1024 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m3,146,752\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_512 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_256 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_128 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m6,500\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ matrix_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ normalization_layer             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flattened_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1024 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,146,752</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_512 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_256 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,850,544\u001b[0m (14.69 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,544</span> (14.69 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,850,538\u001b[0m (14.69 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,538</span> (14.69 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Shuffle de los datos\nindexes_train   = np.arange(len(x_train))\nindexes_test    = np.arange(len(x_test))\n\nnp.random.shuffle(indexes_train)\nnp.random.shuffle(indexes_test)\n\n# Shuffle de datos de train\n\nx_train_dup         = x_train[indexes_train]\ny_train_coarse_dup  = y_train_coarse[indexes_train]\ny_train_fine_dup    = y_train_fine[indexes_train]\n\n# Shuffle de datos de test\nx_test_dup         = x_test[indexes_test]\ny_test_coarse_dup  = y_test_coarse[indexes_test]\ny_test_fine_dup    = y_test_fine[indexes_test]","metadata":{"execution":{"iopub.status.busy":"2024-10-29T00:36:21.309679Z","iopub.execute_input":"2024-10-29T00:36:21.309998Z","iopub.status.idle":"2024-10-29T00:36:22.389261Z","shell.execute_reply.started":"2024-10-29T00:36:21.309965Z","shell.execute_reply":"2024-10-29T00:36:22.388278Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## CALLBACKS\n","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard, LambdaCallback\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay,LearningRateSchedule\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-10-29T01:01:04.149471Z","iopub.execute_input":"2024-10-29T01:01:04.149988Z","iopub.status.idle":"2024-10-29T01:01:04.229147Z","shell.execute_reply.started":"2024-10-29T01:01:04.149953Z","shell.execute_reply":"2024-10-29T01:01:04.227962Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n\nrlrop = ReduceLROnPlateau(\n    monitor = \"val_accuracy\",\n    factor = 0.5,\n    patience = 5,\n    verbose = 1,\n    min_lr = 1e-6\n)\n\n\nrlrop2 = ReduceLROnPlateau(\n    monitor = \"accuracy\",\n    factor = 0.2,\n    patience = 5,\n    verbose = 1,\n    min_lr = 1e-6\n)\n\nes = EarlyStopping(\n    monitor = \"val_accuracy\",\n    patience = 8,\n    verbose = 1,\n    restore_best_weights = True\n)\n\nes2 = EarlyStopping(\n    monitor = \"accuracy\",\n    patience = 10,\n    verbose = 1,\n    restore_best_weights = True\n)\n\nmc2 = ModelCheckpoint(\n    \"best_weights_v1.weights.h5\",\n    monitor = \"accuracy\",\n    verbose = 1,\n    save_best_only = True,\n    save_weights_only = True,\n\n)\n\n\nmc = ModelCheckpoint(\n    \"best_weights_v2.weights.h5\",\n    monitor = \"val_accuracy\",\n    verbose = 1,\n    save_best_only = True,\n    save_weights_only = True,\n\n)\n\n\n\ntb = TensorBoard(\n    log_dir = \"logs\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T00:36:22.396871Z","iopub.execute_input":"2024-10-29T00:36:22.397290Z","iopub.status.idle":"2024-10-29T00:36:22.407802Z","shell.execute_reply.started":"2024-10-29T00:36:22.397247Z","shell.execute_reply":"2024-10-29T00:36:22.406981Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### MODELO 1 COMPILE Y FIT","metadata":{}},{"cell_type":"code","source":"myModel.compile(\n    optimizer               = Adam(learning_rate=0.0001),\n    #loss                    = {'fine_output': 'sparse_categorical_crossentropy', 'coarse_output': 'sparse_categorical_crossentropy'},\n    loss                    = {'fine_output': 'sparse_categorical_crossentropy'},\n    loss_weights            = None,\n    #metrics                 = {'fine_output': 'categorical_accuracy', 'coarse_output': 'categorical_accuracy'},\n    metrics                 = {'fine_output': 'accuracy'},\n    weighted_metrics        = None,\n    run_eagerly             = False,\n    steps_per_execution     = 1,\n    jit_compile             = \"auto\",\n    auto_scale_loss         = True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T00:36:22.409059Z","iopub.execute_input":"2024-10-29T00:36:22.409618Z","iopub.status.idle":"2024-10-29T00:36:22.426709Z","shell.execute_reply.started":"2024-10-29T00:36:22.409576Z","shell.execute_reply":"2024-10-29T00:36:22.426041Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#FIT PRUEBA\nhistory = myModel.fit(\n    x                       = x_train_dup,\n    y                       = {'fine_output': y_train_fine_dup},\n    batch_size              = 256,\n    epochs                  = 100,\n    verbose                 = \"auto\",\n    callbacks               = [LambdaCallback(on_epoch_end=lambda epoch, logs: print(logs if logs is not None else \"No logs available\")),rlrop,es,mc2,mc],\n    validation_split        = 0.0,\n    validation_data         = (x_test_dup, {'fine_output': y_test_fine_dup}),\n    shuffle                 = True,\n    class_weight            = None,\n    sample_weight           = None,\n    initial_epoch           = 0,\n    steps_per_epoch         = None,\n    validation_steps        = None,\n    validation_batch_size   = None,\n    validation_freq         = 1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T00:37:34.359112Z","iopub.execute_input":"2024-10-29T00:37:34.359482Z","iopub.status.idle":"2024-10-29T00:58:06.593632Z","shell.execute_reply.started":"2024-10-29T00:37:34.359448Z","shell.execute_reply":"2024-10-29T00:58:06.592636Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m4058/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1341 - loss: 3.6698{'accuracy': 0.13496731221675873, 'loss': 3.6645944118499756, 'val_accuracy': 0.17100000381469727, 'val_loss': 3.47049880027771}\n\nEpoch 1: accuracy improved from 0.12530 to 0.13497, saving model to best_weights_v1.weights.h5\n\nEpoch 1: val_accuracy improved from 0.15890 to 0.17100, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1341 - loss: 3.6698 - val_accuracy: 0.1710 - val_loss: 3.4705 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1399 - loss: 3.6314{'accuracy': 0.14048942923545837, 'loss': 3.6281094551086426, 'val_accuracy': 0.17260000109672546, 'val_loss': 3.449355363845825}\n\nEpoch 2: accuracy improved from 0.13497 to 0.14049, saving model to best_weights_v1.weights.h5\n\nEpoch 2: val_accuracy improved from 0.17100 to 0.17260, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1399 - loss: 3.6314 - val_accuracy: 0.1726 - val_loss: 3.4494 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1449 - loss: 3.5997{'accuracy': 0.14544999599456787, 'loss': 3.5964293479919434, 'val_accuracy': 0.17649999260902405, 'val_loss': 3.4228222370147705}\n\nEpoch 3: accuracy improved from 0.14049 to 0.14545, saving model to best_weights_v1.weights.h5\n\nEpoch 3: val_accuracy improved from 0.17260 to 0.17650, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1449 - loss: 3.5996 - val_accuracy: 0.1765 - val_loss: 3.4228 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1503 - loss: 3.5706{'accuracy': 0.15070576965808868, 'loss': 3.5678212642669678, 'val_accuracy': 0.18320000171661377, 'val_loss': 3.427959442138672}\n\nEpoch 4: accuracy improved from 0.14545 to 0.15071, saving model to best_weights_v1.weights.h5\n\nEpoch 4: val_accuracy improved from 0.17650 to 0.18320, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.1503 - loss: 3.5706 - val_accuracy: 0.1832 - val_loss: 3.4280 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m4050/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1534 - loss: 3.5456{'accuracy': 0.15450577437877655, 'loss': 3.541637420654297, 'val_accuracy': 0.1899999976158142, 'val_loss': 3.376471519470215}\n\nEpoch 5: accuracy improved from 0.15071 to 0.15451, saving model to best_weights_v1.weights.h5\n\nEpoch 5: val_accuracy improved from 0.18320 to 0.19000, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.1534 - loss: 3.5456 - val_accuracy: 0.1900 - val_loss: 3.3765 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1583 - loss: 3.5213{'accuracy': 0.1584894210100174, 'loss': 3.519594430923462, 'val_accuracy': 0.1923999935388565, 'val_loss': 3.355785608291626}\n\nEpoch 6: accuracy improved from 0.15451 to 0.15849, saving model to best_weights_v1.weights.h5\n\nEpoch 6: val_accuracy improved from 0.19000 to 0.19240, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1583 - loss: 3.5213 - val_accuracy: 0.1924 - val_loss: 3.3558 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m4057/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1618 - loss: 3.4994{'accuracy': 0.16238461434841156, 'loss': 3.4960246086120605, 'val_accuracy': 0.19550000131130219, 'val_loss': 3.3478405475616455}\n\nEpoch 7: accuracy improved from 0.15849 to 0.16238, saving model to best_weights_v1.weights.h5\n\nEpoch 7: val_accuracy improved from 0.19240 to 0.19550, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1618 - loss: 3.4994 - val_accuracy: 0.1955 - val_loss: 3.3478 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m4058/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1652 - loss: 3.4797{'accuracy': 0.16606827080249786, 'loss': 3.4761600494384766, 'val_accuracy': 0.19750000536441803, 'val_loss': 3.3276307582855225}\n\nEpoch 8: accuracy improved from 0.16238 to 0.16607, saving model to best_weights_v1.weights.h5\n\nEpoch 8: val_accuracy improved from 0.19550 to 0.19750, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1652 - loss: 3.4797 - val_accuracy: 0.1975 - val_loss: 3.3276 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m4059/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1695 - loss: 3.4592{'accuracy': 0.16955769062042236, 'loss': 3.457746982574463, 'val_accuracy': 0.20499999821186066, 'val_loss': 3.3174421787261963}\n\nEpoch 9: accuracy improved from 0.16607 to 0.16956, saving model to best_weights_v1.weights.h5\n\nEpoch 9: val_accuracy improved from 0.19750 to 0.20500, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1695 - loss: 3.4592 - val_accuracy: 0.2050 - val_loss: 3.3174 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m4061/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1720 - loss: 3.4415{'accuracy': 0.17249518632888794, 'loss': 3.441465139389038, 'val_accuracy': 0.20759999752044678, 'val_loss': 3.296340227127075}\n\nEpoch 10: accuracy improved from 0.16956 to 0.17250, saving model to best_weights_v1.weights.h5\n\nEpoch 10: val_accuracy improved from 0.20500 to 0.20760, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1720 - loss: 3.4415 - val_accuracy: 0.2076 - val_loss: 3.2963 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1754 - loss: 3.4253{'accuracy': 0.1756259649991989, 'loss': 3.423907518386841, 'val_accuracy': 0.20600000023841858, 'val_loss': 3.291429281234741}\n\nEpoch 11: accuracy improved from 0.17250 to 0.17563, saving model to best_weights_v1.weights.h5\n\nEpoch 11: val_accuracy did not improve from 0.20760\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1754 - loss: 3.4253 - val_accuracy: 0.2060 - val_loss: 3.2914 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1779 - loss: 3.4085{'accuracy': 0.1778596192598343, 'loss': 3.410656690597534, 'val_accuracy': 0.20749999582767487, 'val_loss': 3.2849621772766113}\n\nEpoch 12: accuracy improved from 0.17563 to 0.17786, saving model to best_weights_v1.weights.h5\n\nEpoch 12: val_accuracy did not improve from 0.20760\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1779 - loss: 3.4085 - val_accuracy: 0.2075 - val_loss: 3.2850 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m4053/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1810 - loss: 3.3921{'accuracy': 0.1805163472890854, 'loss': 3.397209882736206, 'val_accuracy': 0.20880000293254852, 'val_loss': 3.284008502960205}\n\nEpoch 13: accuracy improved from 0.17786 to 0.18052, saving model to best_weights_v1.weights.h5\n\nEpoch 13: val_accuracy improved from 0.20760 to 0.20880, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1810 - loss: 3.3921 - val_accuracy: 0.2088 - val_loss: 3.2840 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1836 - loss: 3.3789{'accuracy': 0.18312884867191315, 'loss': 3.3812685012817383, 'val_accuracy': 0.21130000054836273, 'val_loss': 3.2676594257354736}\n\nEpoch 14: accuracy improved from 0.18052 to 0.18313, saving model to best_weights_v1.weights.h5\n\nEpoch 14: val_accuracy improved from 0.20880 to 0.21130, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1836 - loss: 3.3789 - val_accuracy: 0.2113 - val_loss: 3.2677 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m4051/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1858 - loss: 3.3674{'accuracy': 0.1853211522102356, 'loss': 3.37115478515625, 'val_accuracy': 0.21389999985694885, 'val_loss': 3.2609121799468994}\n\nEpoch 15: accuracy improved from 0.18313 to 0.18532, saving model to best_weights_v1.weights.h5\n\nEpoch 15: val_accuracy improved from 0.21130 to 0.21390, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1858 - loss: 3.3675 - val_accuracy: 0.2139 - val_loss: 3.2609 - learning_rate: 0.0010\nEpoch 16/100\n\u001b[1m4051/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1876 - loss: 3.3558{'accuracy': 0.1872115433216095, 'loss': 3.36037278175354, 'val_accuracy': 0.2175000011920929, 'val_loss': 3.2521936893463135}\n\nEpoch 16: accuracy improved from 0.18532 to 0.18721, saving model to best_weights_v1.weights.h5\n\nEpoch 16: val_accuracy improved from 0.21390 to 0.21750, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1876 - loss: 3.3558 - val_accuracy: 0.2175 - val_loss: 3.2522 - learning_rate: 0.0010\nEpoch 17/100\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1900 - loss: 3.3461{'accuracy': 0.18934327363967896, 'loss': 3.3494510650634766, 'val_accuracy': 0.21639999747276306, 'val_loss': 3.2535746097564697}\n\nEpoch 17: accuracy improved from 0.18721 to 0.18934, saving model to best_weights_v1.weights.h5\n\nEpoch 17: val_accuracy did not improve from 0.21750\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1900 - loss: 3.3461 - val_accuracy: 0.2164 - val_loss: 3.2536 - learning_rate: 0.0010\nEpoch 18/100\n\u001b[1m4061/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1917 - loss: 3.3376{'accuracy': 0.19136731326580048, 'loss': 3.3381950855255127, 'val_accuracy': 0.2223999947309494, 'val_loss': 3.2528696060180664}\n\nEpoch 18: accuracy improved from 0.18934 to 0.19137, saving model to best_weights_v1.weights.h5\n\nEpoch 18: val_accuracy improved from 0.21750 to 0.22240, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1917 - loss: 3.3376 - val_accuracy: 0.2224 - val_loss: 3.2529 - learning_rate: 0.0010\nEpoch 19/100\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1934 - loss: 3.3272{'accuracy': 0.1935865432024002, 'loss': 3.3274669647216797, 'val_accuracy': 0.22509999573230743, 'val_loss': 3.2383933067321777}\n\nEpoch 19: accuracy improved from 0.19137 to 0.19359, saving model to best_weights_v1.weights.h5\n\nEpoch 19: val_accuracy improved from 0.22240 to 0.22510, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1934 - loss: 3.3272 - val_accuracy: 0.2251 - val_loss: 3.2384 - learning_rate: 0.0010\nEpoch 20/100\n\u001b[1m4061/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1956 - loss: 3.3202{'accuracy': 0.19523365795612335, 'loss': 3.320481538772583, 'val_accuracy': 0.22020000219345093, 'val_loss': 3.248291254043579}\n\nEpoch 20: accuracy improved from 0.19359 to 0.19523, saving model to best_weights_v1.weights.h5\n\nEpoch 20: val_accuracy did not improve from 0.22510\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1956 - loss: 3.3202 - val_accuracy: 0.2202 - val_loss: 3.2483 - learning_rate: 0.0010\nEpoch 21/100\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1971 - loss: 3.3075{'accuracy': 0.19650480151176453, 'loss': 3.3090097904205322, 'val_accuracy': 0.22390000522136688, 'val_loss': 3.2250797748565674}\n\nEpoch 21: accuracy improved from 0.19523 to 0.19650, saving model to best_weights_v1.weights.h5\n\nEpoch 21: val_accuracy did not improve from 0.22510\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1971 - loss: 3.3075 - val_accuracy: 0.2239 - val_loss: 3.2251 - learning_rate: 0.0010\nEpoch 22/100\n\u001b[1m4050/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1982 - loss: 3.3001{'accuracy': 0.1982942372560501, 'loss': 3.3009724617004395, 'val_accuracy': 0.2273000031709671, 'val_loss': 3.219052791595459}\n\nEpoch 22: accuracy improved from 0.19650 to 0.19829, saving model to best_weights_v1.weights.h5\n\nEpoch 22: val_accuracy improved from 0.22510 to 0.22730, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.1982 - loss: 3.3002 - val_accuracy: 0.2273 - val_loss: 3.2191 - learning_rate: 0.0010\nEpoch 23/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2002 - loss: 3.2918{'accuracy': 0.20028942823410034, 'loss': 3.2916083335876465, 'val_accuracy': 0.22930000722408295, 'val_loss': 3.2197515964508057}\n\nEpoch 23: accuracy improved from 0.19829 to 0.20029, saving model to best_weights_v1.weights.h5\n\nEpoch 23: val_accuracy improved from 0.22730 to 0.22930, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2002 - loss: 3.2918 - val_accuracy: 0.2293 - val_loss: 3.2198 - learning_rate: 0.0010\nEpoch 24/100\n\u001b[1m4061/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2023 - loss: 3.2829{'accuracy': 0.20207788050174713, 'loss': 3.282965898513794, 'val_accuracy': 0.2321999967098236, 'val_loss': 3.2233340740203857}\n\nEpoch 24: accuracy improved from 0.20029 to 0.20208, saving model to best_weights_v1.weights.h5\n\nEpoch 24: val_accuracy improved from 0.22930 to 0.23220, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2023 - loss: 3.2829 - val_accuracy: 0.2322 - val_loss: 3.2233 - learning_rate: 0.0010\nEpoch 25/100\n\u001b[1m4057/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2034 - loss: 3.2724{'accuracy': 0.20336730778217316, 'loss': 3.274528980255127, 'val_accuracy': 0.22990000247955322, 'val_loss': 3.2018208503723145}\n\nEpoch 25: accuracy improved from 0.20208 to 0.20337, saving model to best_weights_v1.weights.h5\n\nEpoch 25: val_accuracy did not improve from 0.23220\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2034 - loss: 3.2724 - val_accuracy: 0.2299 - val_loss: 3.2018 - learning_rate: 0.0010\nEpoch 26/100\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2059 - loss: 3.2638{'accuracy': 0.20524904131889343, 'loss': 3.2659404277801514, 'val_accuracy': 0.23180000483989716, 'val_loss': 3.202505111694336}\n\nEpoch 26: accuracy improved from 0.20337 to 0.20525, saving model to best_weights_v1.weights.h5\n\nEpoch 26: val_accuracy did not improve from 0.23220\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2059 - loss: 3.2638 - val_accuracy: 0.2318 - val_loss: 3.2025 - learning_rate: 0.0010\nEpoch 27/100\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2065 - loss: 3.2577{'accuracy': 0.20640961825847626, 'loss': 3.2594454288482666, 'val_accuracy': 0.22830000519752502, 'val_loss': 3.2184879779815674}\n\nEpoch 27: accuracy improved from 0.20525 to 0.20641, saving model to best_weights_v1.weights.h5\n\nEpoch 27: val_accuracy did not improve from 0.23220\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2065 - loss: 3.2577 - val_accuracy: 0.2283 - val_loss: 3.2185 - learning_rate: 0.0010\nEpoch 28/100\n\u001b[1m4050/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2082 - loss: 3.2507{'accuracy': 0.20809230208396912, 'loss': 3.2516167163848877, 'val_accuracy': 0.23170000314712524, 'val_loss': 3.1907646656036377}\n\nEpoch 28: accuracy improved from 0.20641 to 0.20809, saving model to best_weights_v1.weights.h5\n\nEpoch 28: val_accuracy did not improve from 0.23220\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2082 - loss: 3.2507 - val_accuracy: 0.2317 - val_loss: 3.1908 - learning_rate: 0.0010\nEpoch 29/100\n\u001b[1m4054/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2101 - loss: 3.2384{'accuracy': 0.20890288054943085, 'loss': 3.24411940574646, 'val_accuracy': 0.23090000450611115, 'val_loss': 3.206097364425659}\n\nEpoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 29: accuracy improved from 0.20809 to 0.20890, saving model to best_weights_v1.weights.h5\n\nEpoch 29: val_accuracy did not improve from 0.23220\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2101 - loss: 3.2384 - val_accuracy: 0.2309 - val_loss: 3.2061 - learning_rate: 0.0010\nEpoch 30/100\n\u001b[1m4051/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2216 - loss: 3.1771{'accuracy': 0.22300000488758087, 'loss': 3.169290065765381, 'val_accuracy': 0.2387000024318695, 'val_loss': 3.1756961345672607}\n\nEpoch 30: accuracy improved from 0.20890 to 0.22300, saving model to best_weights_v1.weights.h5\n\nEpoch 30: val_accuracy improved from 0.23220 to 0.23870, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2216 - loss: 3.1771 - val_accuracy: 0.2387 - val_loss: 3.1757 - learning_rate: 5.0000e-04\nEpoch 31/100\n\u001b[1m4059/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2260 - loss: 3.1506{'accuracy': 0.22624807059764862, 'loss': 3.1505823135375977, 'val_accuracy': 0.2409999966621399, 'val_loss': 3.17008900642395}\n\nEpoch 31: accuracy improved from 0.22300 to 0.22625, saving model to best_weights_v1.weights.h5\n\nEpoch 31: val_accuracy improved from 0.23870 to 0.24100, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2260 - loss: 3.1506 - val_accuracy: 0.2410 - val_loss: 3.1701 - learning_rate: 5.0000e-04\nEpoch 32/100\n\u001b[1m4054/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2285 - loss: 3.1360{'accuracy': 0.2278096079826355, 'loss': 3.139880895614624, 'val_accuracy': 0.2402999997138977, 'val_loss': 3.1836330890655518}\n\nEpoch 32: accuracy improved from 0.22625 to 0.22781, saving model to best_weights_v1.weights.h5\n\nEpoch 32: val_accuracy did not improve from 0.24100\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2285 - loss: 3.1360 - val_accuracy: 0.2403 - val_loss: 3.1836 - learning_rate: 5.0000e-04\nEpoch 33/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2295 - loss: 3.1353{'accuracy': 0.22959904372692108, 'loss': 3.1341207027435303, 'val_accuracy': 0.24050000309944153, 'val_loss': 3.1765475273132324}\n\nEpoch 33: accuracy improved from 0.22781 to 0.22960, saving model to best_weights_v1.weights.h5\n\nEpoch 33: val_accuracy did not improve from 0.24100\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2295 - loss: 3.1353 - val_accuracy: 0.2405 - val_loss: 3.1765 - learning_rate: 5.0000e-04\nEpoch 34/100\n\u001b[1m4053/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2315 - loss: 3.1226{'accuracy': 0.231170192360878, 'loss': 3.1248939037323, 'val_accuracy': 0.24699999392032623, 'val_loss': 3.1606342792510986}\n\nEpoch 34: accuracy improved from 0.22960 to 0.23117, saving model to best_weights_v1.weights.h5\n\nEpoch 34: val_accuracy improved from 0.24100 to 0.24700, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2315 - loss: 3.1226 - val_accuracy: 0.2470 - val_loss: 3.1606 - learning_rate: 5.0000e-04\nEpoch 35/100\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2330 - loss: 3.1140{'accuracy': 0.2320673018693924, 'loss': 3.1184470653533936, 'val_accuracy': 0.24570000171661377, 'val_loss': 3.1678152084350586}\n\nEpoch 35: accuracy improved from 0.23117 to 0.23207, saving model to best_weights_v1.weights.h5\n\nEpoch 35: val_accuracy did not improve from 0.24700\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2330 - loss: 3.1140 - val_accuracy: 0.2457 - val_loss: 3.1678 - learning_rate: 5.0000e-04\nEpoch 36/100\n\u001b[1m4061/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2340 - loss: 3.1085{'accuracy': 0.23347210884094238, 'loss': 3.112199068069458, 'val_accuracy': 0.24480000138282776, 'val_loss': 3.1742618083953857}\n\nEpoch 36: accuracy improved from 0.23207 to 0.23347, saving model to best_weights_v1.weights.h5\n\nEpoch 36: val_accuracy did not improve from 0.24700\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2340 - loss: 3.1085 - val_accuracy: 0.2448 - val_loss: 3.1743 - learning_rate: 5.0000e-04\nEpoch 37/100\n\u001b[1m4050/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2342 - loss: 3.1044{'accuracy': 0.23467692732810974, 'loss': 3.1052725315093994, 'val_accuracy': 0.24690000712871552, 'val_loss': 3.161468744277954}\n\nEpoch 37: accuracy improved from 0.23347 to 0.23468, saving model to best_weights_v1.weights.h5\n\nEpoch 37: val_accuracy did not improve from 0.24700\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2342 - loss: 3.1044 - val_accuracy: 0.2469 - val_loss: 3.1615 - learning_rate: 5.0000e-04\nEpoch 38/100\n\u001b[1m4056/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2364 - loss: 3.0969{'accuracy': 0.23582307994365692, 'loss': 3.1000123023986816, 'val_accuracy': 0.24609999358654022, 'val_loss': 3.1682004928588867}\n\nEpoch 38: accuracy improved from 0.23468 to 0.23582, saving model to best_weights_v1.weights.h5\n\nEpoch 38: val_accuracy did not improve from 0.24700\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2364 - loss: 3.0969 - val_accuracy: 0.2461 - val_loss: 3.1682 - learning_rate: 5.0000e-04\nEpoch 39/100\n\u001b[1m4050/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2375 - loss: 3.0915{'accuracy': 0.23698845505714417, 'loss': 3.0935306549072266, 'val_accuracy': 0.24609999358654022, 'val_loss': 3.164116621017456}\n\nEpoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 39: accuracy improved from 0.23582 to 0.23699, saving model to best_weights_v1.weights.h5\n\nEpoch 39: val_accuracy did not improve from 0.24700\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2375 - loss: 3.0915 - val_accuracy: 0.2461 - val_loss: 3.1641 - learning_rate: 5.0000e-04\nEpoch 40/100\n\u001b[1m4054/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2447 - loss: 3.0538{'accuracy': 0.24515481293201447, 'loss': 3.0502095222473145, 'val_accuracy': 0.24969999492168427, 'val_loss': 3.17036509513855}\n\nEpoch 40: accuracy improved from 0.23699 to 0.24515, saving model to best_weights_v1.weights.h5\n\nEpoch 40: val_accuracy improved from 0.24700 to 0.24970, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2447 - loss: 3.0538 - val_accuracy: 0.2497 - val_loss: 3.1704 - learning_rate: 2.5000e-04\nEpoch 41/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2478 - loss: 3.0366{'accuracy': 0.24767307937145233, 'loss': 3.0397238731384277, 'val_accuracy': 0.24719999730587006, 'val_loss': 3.1606268882751465}\n\nEpoch 41: accuracy improved from 0.24515 to 0.24767, saving model to best_weights_v1.weights.h5\n\nEpoch 41: val_accuracy did not improve from 0.24970\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2478 - loss: 3.0366 - val_accuracy: 0.2472 - val_loss: 3.1606 - learning_rate: 2.5000e-04\nEpoch 42/100\n\u001b[1m4059/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2473 - loss: 3.0363{'accuracy': 0.24749808013439178, 'loss': 3.0349135398864746, 'val_accuracy': 0.2515999972820282, 'val_loss': 3.1569507122039795}\n\nEpoch 42: accuracy did not improve from 0.24767\n\nEpoch 42: val_accuracy improved from 0.24970 to 0.25160, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2473 - loss: 3.0363 - val_accuracy: 0.2516 - val_loss: 3.1570 - learning_rate: 2.5000e-04\nEpoch 43/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2501 - loss: 3.0254{'accuracy': 0.2491961568593979, 'loss': 3.028715133666992, 'val_accuracy': 0.25029999017715454, 'val_loss': 3.1637589931488037}\n\nEpoch 43: accuracy improved from 0.24767 to 0.24920, saving model to best_weights_v1.weights.h5\n\nEpoch 43: val_accuracy did not improve from 0.25160\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2501 - loss: 3.0254 - val_accuracy: 0.2503 - val_loss: 3.1638 - learning_rate: 2.5000e-04\nEpoch 44/100\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2499 - loss: 3.0280{'accuracy': 0.2499365359544754, 'loss': 3.0263190269470215, 'val_accuracy': 0.24959999322891235, 'val_loss': 3.16630482673645}\n\nEpoch 44: accuracy improved from 0.24920 to 0.24994, saving model to best_weights_v1.weights.h5\n\nEpoch 44: val_accuracy did not improve from 0.25160\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2499 - loss: 3.0280 - val_accuracy: 0.2496 - val_loss: 3.1663 - learning_rate: 2.5000e-04\nEpoch 45/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2511 - loss: 3.0218{'accuracy': 0.2503874897956848, 'loss': 3.0220305919647217, 'val_accuracy': 0.24729999899864197, 'val_loss': 3.165576696395874}\n\nEpoch 45: accuracy improved from 0.24994 to 0.25039, saving model to best_weights_v1.weights.h5\n\nEpoch 45: val_accuracy did not improve from 0.25160\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.2511 - loss: 3.0218 - val_accuracy: 0.2473 - val_loss: 3.1656 - learning_rate: 2.5000e-04\nEpoch 46/100\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2519 - loss: 3.0157{'accuracy': 0.2508567273616791, 'loss': 3.018240213394165, 'val_accuracy': 0.25119999051094055, 'val_loss': 3.1625587940216064}\n\nEpoch 46: accuracy improved from 0.25039 to 0.25086, saving model to best_weights_v1.weights.h5\n\nEpoch 46: val_accuracy did not improve from 0.25160\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2519 - loss: 3.0157 - val_accuracy: 0.2512 - val_loss: 3.1626 - learning_rate: 2.5000e-04\nEpoch 47/100\n\u001b[1m4061/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2525 - loss: 3.0115{'accuracy': 0.2521173059940338, 'loss': 3.014742374420166, 'val_accuracy': 0.24979999661445618, 'val_loss': 3.175062656402588}\n\nEpoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 47: accuracy improved from 0.25086 to 0.25212, saving model to best_weights_v1.weights.h5\n\nEpoch 47: val_accuracy did not improve from 0.25160\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2525 - loss: 3.0115 - val_accuracy: 0.2498 - val_loss: 3.1751 - learning_rate: 2.5000e-04\nEpoch 48/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2560 - loss: 2.9881{'accuracy': 0.25632980465888977, 'loss': 2.9900288581848145, 'val_accuracy': 0.251800000667572, 'val_loss': 3.161724090576172}\n\nEpoch 48: accuracy improved from 0.25212 to 0.25633, saving model to best_weights_v1.weights.h5\n\nEpoch 48: val_accuracy improved from 0.25160 to 0.25180, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2560 - loss: 2.9881 - val_accuracy: 0.2518 - val_loss: 3.1617 - learning_rate: 1.2500e-04\nEpoch 49/100\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2582 - loss: 2.9830{'accuracy': 0.2572759687900543, 'loss': 2.985668182373047, 'val_accuracy': 0.2524999976158142, 'val_loss': 3.155142068862915}\n\nEpoch 49: accuracy improved from 0.25633 to 0.25728, saving model to best_weights_v1.weights.h5\n\nEpoch 49: val_accuracy improved from 0.25180 to 0.25250, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2582 - loss: 2.9830 - val_accuracy: 0.2525 - val_loss: 3.1551 - learning_rate: 1.2500e-04\nEpoch 50/100\n\u001b[1m4059/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2584 - loss: 2.9795{'accuracy': 0.25757405161857605, 'loss': 2.98146915435791, 'val_accuracy': 0.25220000743865967, 'val_loss': 3.1545703411102295}\n\nEpoch 50: accuracy improved from 0.25728 to 0.25757, saving model to best_weights_v1.weights.h5\n\nEpoch 50: val_accuracy did not improve from 0.25250\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2584 - loss: 2.9795 - val_accuracy: 0.2522 - val_loss: 3.1546 - learning_rate: 1.2500e-04\nEpoch 51/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2587 - loss: 2.9777{'accuracy': 0.25824326276779175, 'loss': 2.9796946048736572, 'val_accuracy': 0.2531000077724457, 'val_loss': 3.157888174057007}\n\nEpoch 51: accuracy improved from 0.25757 to 0.25824, saving model to best_weights_v1.weights.h5\n\nEpoch 51: val_accuracy improved from 0.25250 to 0.25310, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2587 - loss: 2.9777 - val_accuracy: 0.2531 - val_loss: 3.1579 - learning_rate: 1.2500e-04\nEpoch 52/100\n\u001b[1m4053/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2599 - loss: 2.9744{'accuracy': 0.25942787528038025, 'loss': 2.9766056537628174, 'val_accuracy': 0.2551000118255615, 'val_loss': 3.150369644165039}\n\nEpoch 52: accuracy improved from 0.25824 to 0.25943, saving model to best_weights_v1.weights.h5\n\nEpoch 52: val_accuracy improved from 0.25310 to 0.25510, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2599 - loss: 2.9744 - val_accuracy: 0.2551 - val_loss: 3.1504 - learning_rate: 1.2500e-04\nEpoch 53/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2613 - loss: 2.9711{'accuracy': 0.2605682611465454, 'loss': 2.9740169048309326, 'val_accuracy': 0.2540999948978424, 'val_loss': 3.153345823287964}\n\nEpoch 53: accuracy improved from 0.25943 to 0.26057, saving model to best_weights_v1.weights.h5\n\nEpoch 53: val_accuracy did not improve from 0.25510\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2613 - loss: 2.9711 - val_accuracy: 0.2541 - val_loss: 3.1533 - learning_rate: 1.2500e-04\nEpoch 54/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2608 - loss: 2.9659{'accuracy': 0.2605942189693451, 'loss': 2.9707329273223877, 'val_accuracy': 0.2524999976158142, 'val_loss': 3.158050775527954}\n\nEpoch 54: accuracy improved from 0.26057 to 0.26059, saving model to best_weights_v1.weights.h5\n\nEpoch 54: val_accuracy did not improve from 0.25510\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2608 - loss: 2.9660 - val_accuracy: 0.2525 - val_loss: 3.1581 - learning_rate: 1.2500e-04\nEpoch 55/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2603 - loss: 2.9704{'accuracy': 0.2602711617946625, 'loss': 2.9692955017089844, 'val_accuracy': 0.2535000145435333, 'val_loss': 3.151279926300049}\n\nEpoch 55: accuracy did not improve from 0.26059\n\nEpoch 55: val_accuracy did not improve from 0.25510\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2603 - loss: 2.9704 - val_accuracy: 0.2535 - val_loss: 3.1513 - learning_rate: 1.2500e-04\nEpoch 56/100\n\u001b[1m4057/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2618 - loss: 2.9622{'accuracy': 0.26116248965263367, 'loss': 2.966280460357666, 'val_accuracy': 0.25360000133514404, 'val_loss': 3.1605629920959473}\n\nEpoch 56: accuracy improved from 0.26059 to 0.26116, saving model to best_weights_v1.weights.h5\n\nEpoch 56: val_accuracy did not improve from 0.25510\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2618 - loss: 2.9622 - val_accuracy: 0.2536 - val_loss: 3.1606 - learning_rate: 1.2500e-04\nEpoch 57/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2620 - loss: 2.9656{'accuracy': 0.2616932690143585, 'loss': 2.9662861824035645, 'val_accuracy': 0.257099986076355, 'val_loss': 3.157909631729126}\n\nEpoch 57: accuracy improved from 0.26116 to 0.26169, saving model to best_weights_v1.weights.h5\n\nEpoch 57: val_accuracy improved from 0.25510 to 0.25710, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2620 - loss: 2.9656 - val_accuracy: 0.2571 - val_loss: 3.1579 - learning_rate: 1.2500e-04\nEpoch 58/100\n\u001b[1m4050/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2624 - loss: 2.9618{'accuracy': 0.2618855834007263, 'loss': 2.9632227420806885, 'val_accuracy': 0.2556999921798706, 'val_loss': 3.1615684032440186}\n\nEpoch 58: accuracy improved from 0.26169 to 0.26189, saving model to best_weights_v1.weights.h5\n\nEpoch 58: val_accuracy did not improve from 0.25710\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2624 - loss: 2.9618 - val_accuracy: 0.2557 - val_loss: 3.1616 - learning_rate: 1.2500e-04\nEpoch 59/100\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2619 - loss: 2.9633{'accuracy': 0.2618826925754547, 'loss': 2.961721658706665, 'val_accuracy': 0.2572999894618988, 'val_loss': 3.157684087753296}\n\nEpoch 59: accuracy did not improve from 0.26189\n\nEpoch 59: val_accuracy improved from 0.25710 to 0.25730, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2619 - loss: 2.9633 - val_accuracy: 0.2573 - val_loss: 3.1577 - learning_rate: 1.2500e-04\nEpoch 60/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2631 - loss: 2.9579{'accuracy': 0.26279327273368835, 'loss': 2.9592559337615967, 'val_accuracy': 0.2531000077724457, 'val_loss': 3.157620668411255}\n\nEpoch 60: accuracy improved from 0.26189 to 0.26279, saving model to best_weights_v1.weights.h5\n\nEpoch 60: val_accuracy did not improve from 0.25730\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2631 - loss: 2.9579 - val_accuracy: 0.2531 - val_loss: 3.1576 - learning_rate: 1.2500e-04\nEpoch 61/100\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2644 - loss: 2.9524{'accuracy': 0.2636788487434387, 'loss': 2.9565188884735107, 'val_accuracy': 0.2542000114917755, 'val_loss': 3.153542995452881}\n\nEpoch 61: accuracy improved from 0.26279 to 0.26368, saving model to best_weights_v1.weights.h5\n\nEpoch 61: val_accuracy did not improve from 0.25730\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2644 - loss: 2.9524 - val_accuracy: 0.2542 - val_loss: 3.1535 - learning_rate: 1.2500e-04\nEpoch 62/100\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2633 - loss: 2.9539{'accuracy': 0.26316922903060913, 'loss': 2.954676866531372, 'val_accuracy': 0.2549999952316284, 'val_loss': 3.157078266143799}\n\nEpoch 62: accuracy did not improve from 0.26368\n\nEpoch 62: val_accuracy did not improve from 0.25730\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2633 - loss: 2.9539 - val_accuracy: 0.2550 - val_loss: 3.1571 - learning_rate: 1.2500e-04\nEpoch 63/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2643 - loss: 2.9504{'accuracy': 0.26366057991981506, 'loss': 2.952897310256958, 'val_accuracy': 0.25459998846054077, 'val_loss': 3.152904748916626}\n\nEpoch 63: accuracy did not improve from 0.26368\n\nEpoch 63: val_accuracy did not improve from 0.25730\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2642 - loss: 2.9505 - val_accuracy: 0.2546 - val_loss: 3.1529 - learning_rate: 1.2500e-04\nEpoch 64/100\n\u001b[1m4051/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2640 - loss: 2.9490{'accuracy': 0.2640827000141144, 'loss': 2.9505529403686523, 'val_accuracy': 0.25699999928474426, 'val_loss': 3.1579620838165283}\n\nEpoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 64: accuracy improved from 0.26368 to 0.26408, saving model to best_weights_v1.weights.h5\n\nEpoch 64: val_accuracy did not improve from 0.25730\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2640 - loss: 2.9490 - val_accuracy: 0.2570 - val_loss: 3.1580 - learning_rate: 1.2500e-04\nEpoch 65/100\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2666 - loss: 2.9409{'accuracy': 0.2664615511894226, 'loss': 2.939272880554199, 'val_accuracy': 0.2547000050544739, 'val_loss': 3.1566357612609863}\n\nEpoch 65: accuracy improved from 0.26408 to 0.26646, saving model to best_weights_v1.weights.h5\n\nEpoch 65: val_accuracy did not improve from 0.25730\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2666 - loss: 2.9409 - val_accuracy: 0.2547 - val_loss: 3.1566 - learning_rate: 6.2500e-05\nEpoch 66/100\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2673 - loss: 2.9342{'accuracy': 0.267300009727478, 'loss': 2.935089111328125, 'val_accuracy': 0.25760000944137573, 'val_loss': 3.1524417400360107}\n\nEpoch 66: accuracy improved from 0.26646 to 0.26730, saving model to best_weights_v1.weights.h5\n\nEpoch 66: val_accuracy improved from 0.25730 to 0.25760, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.2673 - loss: 2.9342 - val_accuracy: 0.2576 - val_loss: 3.1524 - learning_rate: 6.2500e-05\nEpoch 67/100\n\u001b[1m4053/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2679 - loss: 2.9328{'accuracy': 0.2673798203468323, 'loss': 2.934391736984253, 'val_accuracy': 0.25450000166893005, 'val_loss': 3.1570489406585693}\n\nEpoch 67: accuracy improved from 0.26730 to 0.26738, saving model to best_weights_v1.weights.h5\n\nEpoch 67: val_accuracy did not improve from 0.25760\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2679 - loss: 2.9328 - val_accuracy: 0.2545 - val_loss: 3.1570 - learning_rate: 6.2500e-05\nEpoch 68/100\n\u001b[1m4056/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2683 - loss: 2.9308{'accuracy': 0.2678096294403076, 'loss': 2.9326319694519043, 'val_accuracy': 0.2574999928474426, 'val_loss': 3.1546096801757812}\n\nEpoch 68: accuracy improved from 0.26738 to 0.26781, saving model to best_weights_v1.weights.h5\n\nEpoch 68: val_accuracy did not improve from 0.25760\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2683 - loss: 2.9308 - val_accuracy: 0.2575 - val_loss: 3.1546 - learning_rate: 6.2500e-05\nEpoch 69/100\n\u001b[1m4054/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2682 - loss: 2.9303{'accuracy': 0.26804423332214355, 'loss': 2.932161808013916, 'val_accuracy': 0.257099986076355, 'val_loss': 3.1542582511901855}\n\nEpoch 69: accuracy improved from 0.26781 to 0.26804, saving model to best_weights_v1.weights.h5\n\nEpoch 69: val_accuracy did not improve from 0.25760\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2682 - loss: 2.9303 - val_accuracy: 0.2571 - val_loss: 3.1543 - learning_rate: 6.2500e-05\nEpoch 70/100\n\u001b[1m4058/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2683 - loss: 2.9287{'accuracy': 0.2675778865814209, 'loss': 2.929983615875244, 'val_accuracy': 0.2574999928474426, 'val_loss': 3.153198480606079}\n\nEpoch 70: accuracy did not improve from 0.26804\n\nEpoch 70: val_accuracy did not improve from 0.25760\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2683 - loss: 2.9287 - val_accuracy: 0.2575 - val_loss: 3.1532 - learning_rate: 6.2500e-05\nEpoch 71/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2686 - loss: 2.9293{'accuracy': 0.26848462224006653, 'loss': 2.928956985473633, 'val_accuracy': 0.2563999891281128, 'val_loss': 3.1593472957611084}\n\nEpoch 71: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 71: accuracy improved from 0.26804 to 0.26848, saving model to best_weights_v1.weights.h5\n\nEpoch 71: val_accuracy did not improve from 0.25760\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2686 - loss: 2.9293 - val_accuracy: 0.2564 - val_loss: 3.1593 - learning_rate: 6.2500e-05\nEpoch 72/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2696 - loss: 2.9234{'accuracy': 0.2694057822227478, 'loss': 2.923274278640747, 'val_accuracy': 0.26010000705718994, 'val_loss': 3.150390386581421}\n\nEpoch 72: accuracy improved from 0.26848 to 0.26941, saving model to best_weights_v1.weights.h5\n\nEpoch 72: val_accuracy improved from 0.25760 to 0.26010, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.2696 - loss: 2.9234 - val_accuracy: 0.2601 - val_loss: 3.1504 - learning_rate: 3.1250e-05\nEpoch 73/100\n\u001b[1m4057/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2699 - loss: 2.9229{'accuracy': 0.26987308263778687, 'loss': 2.922179698944092, 'val_accuracy': 0.25780001282691956, 'val_loss': 3.1601414680480957}\n\nEpoch 73: accuracy improved from 0.26941 to 0.26987, saving model to best_weights_v1.weights.h5\n\nEpoch 73: val_accuracy did not improve from 0.26010\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2699 - loss: 2.9229 - val_accuracy: 0.2578 - val_loss: 3.1601 - learning_rate: 3.1250e-05\nEpoch 74/100\n\u001b[1m4058/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2701 - loss: 2.9176{'accuracy': 0.2697307765483856, 'loss': 2.9199302196502686, 'val_accuracy': 0.25619998574256897, 'val_loss': 3.1593172550201416}\n\nEpoch 74: accuracy did not improve from 0.26987\n\nEpoch 74: val_accuracy did not improve from 0.26010\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2701 - loss: 2.9176 - val_accuracy: 0.2562 - val_loss: 3.1593 - learning_rate: 3.1250e-05\nEpoch 75/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2709 - loss: 2.9167{'accuracy': 0.2702692449092865, 'loss': 2.919041395187378, 'val_accuracy': 0.2572000026702881, 'val_loss': 3.1548211574554443}\n\nEpoch 75: accuracy improved from 0.26987 to 0.27027, saving model to best_weights_v1.weights.h5\n\nEpoch 75: val_accuracy did not improve from 0.26010\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2709 - loss: 2.9167 - val_accuracy: 0.2572 - val_loss: 3.1548 - learning_rate: 3.1250e-05\nEpoch 76/100\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2706 - loss: 2.9187{'accuracy': 0.270175963640213, 'loss': 2.91886568069458, 'val_accuracy': 0.2578999996185303, 'val_loss': 3.1572020053863525}\n\nEpoch 76: accuracy did not improve from 0.27027\n\nEpoch 76: val_accuracy did not improve from 0.26010\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2706 - loss: 2.9187 - val_accuracy: 0.2579 - val_loss: 3.1572 - learning_rate: 3.1250e-05\nEpoch 77/100\n\u001b[1m4051/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2705 - loss: 2.9187{'accuracy': 0.2706509530544281, 'loss': 2.9193217754364014, 'val_accuracy': 0.2590999901294708, 'val_loss': 3.157972574234009}\n\nEpoch 77: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 77: accuracy improved from 0.27027 to 0.27065, saving model to best_weights_v1.weights.h5\n\nEpoch 77: val_accuracy did not improve from 0.26010\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2705 - loss: 2.9187 - val_accuracy: 0.2591 - val_loss: 3.1580 - learning_rate: 3.1250e-05\nEpoch 78/100\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2705 - loss: 2.9158{'accuracy': 0.2707461416721344, 'loss': 2.9157140254974365, 'val_accuracy': 0.2581000030040741, 'val_loss': 3.1579155921936035}\n\nEpoch 78: accuracy improved from 0.27065 to 0.27075, saving model to best_weights_v1.weights.h5\n\nEpoch 78: val_accuracy did not improve from 0.26010\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2705 - loss: 2.9158 - val_accuracy: 0.2581 - val_loss: 3.1579 - learning_rate: 1.5625e-05\nEpoch 79/100\n\u001b[1m4050/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2710 - loss: 2.9178{'accuracy': 0.27130481600761414, 'loss': 2.9155757427215576, 'val_accuracy': 0.2581999897956848, 'val_loss': 3.15795636177063}\n\nEpoch 79: accuracy improved from 0.27075 to 0.27130, saving model to best_weights_v1.weights.h5\n\nEpoch 79: val_accuracy did not improve from 0.26010\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2710 - loss: 2.9178 - val_accuracy: 0.2582 - val_loss: 3.1580 - learning_rate: 1.5625e-05\nEpoch 80/100\n\u001b[1m4059/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2702 - loss: 2.9167{'accuracy': 0.2713884711265564, 'loss': 2.9145455360412598, 'val_accuracy': 0.25920000672340393, 'val_loss': 3.159588098526001}\n\nEpoch 80: accuracy improved from 0.27130 to 0.27139, saving model to best_weights_v1.weights.h5\n\nEpoch 80: val_accuracy did not improve from 0.26010\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.2702 - loss: 2.9167 - val_accuracy: 0.2592 - val_loss: 3.1596 - learning_rate: 1.5625e-05\nEpoch 80: early stopping\nRestoring model weights from the end of the best epoch: 72.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### MODELO 2","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.regularizers import l2","metadata":{"execution":{"iopub.status.busy":"2024-10-29T01:01:04.231715Z","iopub.execute_input":"2024-10-29T01:01:04.232095Z","iopub.status.idle":"2024-10-29T01:01:04.239762Z","shell.execute_reply.started":"2024-10-29T01:01:04.232052Z","shell.execute_reply":"2024-10-29T01:01:04.238835Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#OTRA ESTRUCTURA\n# Entrada y normalización\ninput_layer = Input(shape=(32, 32, 3), name=\"matrix_input\")\n\n# Estructura de la red\nx = BatchNormalization(axis=-1, name=\"normalization_layer\")(input_layer)\nflatten_layer = Flatten(name=\"flattened_input\")(x)\n\n# Capas densas y Dropout adicionales para mayor capacidad\ndense_2048 = Dense(2048, activation='relu', name=\"dense_2048\")(flatten_layer)\ndropout_2048 = Dropout(0.4)(dense_2048)\n\ndense_1024 = Dense(1024, activation='relu', name=\"dense_1024\")(dropout_2048)\ndropout_1024 = Dropout(0.3)(dense_1024)\n\n# Capas intermedias adicionales\ndense_512_a = Dense(512, activation='relu', name=\"dense_512_a\")(dropout_1024)\ndropout_512_a = Dropout(0.2)(dense_512_a)\n\n\n# Continuación de las capas existentes\ndense_512 = Dense(512, activation='relu', name=\"dense_512\")(dropout_512_a)\ndropout_512 = Dropout(0.2)(dense_512)\n\ndense_256 = Dense(256, activation='relu', name=\"dense_256\")(dropout_512)\ndropout_256 = Dropout(0.2)(dense_256)\n\ndense_128 = Dense(128, activation='relu', name=\"dense_128\")(dropout_256)\n\n# Capas adicionales para mayor profundidad\ndense_128_b = Dense(128, activation='relu', name=\"dense_128_b\")(dense_128)\ndense_100 = Dense(100, activation='relu', name=\"dense_100\")(dense_128_b)\nbatch_norm_100 = BatchNormalization()(dense_100)\n\n# Salida\nfine_output = Dense(100, activation='softmax', name='fine_output')(batch_norm_100)\n\n# Coarse-grain prediction branch (20 classes)\ncoarse_output = Dense(20,\n                             activation='softmax',\n                             name='coarse_output')(dropout_512)\n\n# Defino el modelo con dos salidas\nmyModel2 = Model(\n    inputs                  = input_layer,\n    #outputs                 = [fine_output, coarse_output]\n    outputs                 = [fine_output]\n)\n\"\"\"myModel2 = Model(\n    inputs                  = input_layer,\n    outputs                 = [coarse_output]\n)\"\"\"\n\n# Print model summary\nmyModel2.summary()\n\n#myModel2.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T01:01:04.242630Z","iopub.execute_input":"2024-10-29T01:01:04.242973Z","iopub.status.idle":"2024-10-29T01:01:05.198170Z","shell.execute_reply.started":"2024-10-29T01:01:04.242941Z","shell.execute_reply":"2024-10-29T01:01:05.197326Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ matrix_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ normalization_layer             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │            \u001b[38;5;34m12\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flattened_input (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2048 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m6,293,504\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1024 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_512_a (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_512 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_256 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_128 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_128_b (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_100 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m12,900\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │           \u001b[38;5;34m400\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ matrix_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ normalization_layer             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flattened_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2048 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,293,504</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1024 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_512_a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_512 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_256 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_128_b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,383,284\u001b[0m (35.79 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,383,284</span> (35.79 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,383,078\u001b[0m (35.79 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,383,078</span> (35.79 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m206\u001b[0m (824.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206</span> (824.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"usa callbacks de model 3","metadata":{}},{"cell_type":"code","source":"# Shuffle de los datos\nindexes_train   = np.arange(len(x_train))\nindexes_test    = np.arange(len(x_test))\n\nnp.random.shuffle(indexes_train)\nnp.random.shuffle(indexes_test)\n\n# Shuffle de datos de train\n\nx_train_dup         = x_train[indexes_train]\ny_train_coarse_dup  = y_train_coarse[indexes_train]\ny_train_fine_dup    = y_train_fine[indexes_train]\n\n# Shuffle de datos de test\nx_test_dup         = x_test[indexes_test]\ny_test_coarse_dup  = y_test_coarse[indexes_test]\ny_test_fine_dup    = y_test_fine[indexes_test]","metadata":{"execution":{"iopub.status.busy":"2024-10-29T01:01:33.593040Z","iopub.execute_input":"2024-10-29T01:01:33.593980Z","iopub.status.idle":"2024-10-29T01:01:34.724440Z","shell.execute_reply.started":"2024-10-29T01:01:33.593938Z","shell.execute_reply":"2024-10-29T01:01:34.723610Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"myModel2.compile(\n    optimizer               = Adam(learning_rate=0.0001),\n    #loss                    = {'fine_output': 'sparse_categorical_crossentropy', 'coarse_output': 'sparse_categorical_crossentropy'},\n    loss                    = {'fine_output': 'sparse_categorical_crossentropy'},\n    loss_weights            = None,\n    #metrics                 = {'fine_output': 'categorical_accuracy', 'coarse_output': 'categorical_accuracy'},\n    metrics                 = {'fine_output': 'accuracy'},\n    weighted_metrics        = None,\n    run_eagerly             = False,\n    steps_per_execution     = 1,\n    jit_compile             = \"auto\",\n    auto_scale_loss         = True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T01:01:48.354362Z","iopub.execute_input":"2024-10-29T01:01:48.355018Z","iopub.status.idle":"2024-10-29T01:01:48.366218Z","shell.execute_reply.started":"2024-10-29T01:01:48.354977Z","shell.execute_reply":"2024-10-29T01:01:48.365210Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"history2 = myModel2.fit(\n    x                       = x_train_dup,\n    y                       = {'fine_output': y_train_fine_dup},\n    batch_size              = 512,\n    epochs                  = 100,\n    verbose                 = \"auto\",\n    callbacks               = [LambdaCallback(on_epoch_end=lambda epoch, logs: print(logs if logs is not None else \"No logs available\")),rlrop,es,mc2,mc],\n    validation_split        = 0.0,\n    validation_data         = (x_test_dup, {'fine_output': y_test_fine_dup}),\n    shuffle                 = True,\n    class_weight            = None,\n    sample_weight           = None,\n    initial_epoch           = 0,\n    steps_per_epoch         = None,\n    validation_steps        = None,\n    validation_batch_size   = None,\n    validation_freq         = 1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T01:01:50.825066Z","iopub.execute_input":"2024-10-29T01:01:50.826208Z","iopub.status.idle":"2024-10-29T01:39:46.717482Z","shell.execute_reply.started":"2024-10-29T01:01:50.826151Z","shell.execute_reply":"2024-10-29T01:39:46.716505Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730163721.341705     102 service.cc:145] XLA service 0x79e6080021d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730163721.341756     102 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730163721.341761     102 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  10/2032\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 18ms/step - accuracy: 0.0069 - loss: 4.9349","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1730163731.251394     102 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0337 - loss: 4.4880{'accuracy': 0.05178653821349144, 'loss': 4.297489166259766, 'val_accuracy': 0.10090000182390213, 'val_loss': 3.915030002593994}\n\nEpoch 1: accuracy improved from -inf to 0.05179, saving model to best_weights_v1.weights.h5\n\nEpoch 1: val_accuracy improved from -inf to 0.10090, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 16ms/step - accuracy: 0.0338 - loss: 4.4879 - val_accuracy: 0.1009 - val_loss: 3.9150 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0856 - loss: 4.0216{'accuracy': 0.09159326553344727, 'loss': 3.976897954940796, 'val_accuracy': 0.1370999962091446, 'val_loss': 3.692094087600708}\n\nEpoch 2: accuracy improved from 0.05179 to 0.09159, saving model to best_weights_v1.weights.h5\n\nEpoch 2: val_accuracy improved from 0.10090 to 0.13710, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.0856 - loss: 4.0216 - val_accuracy: 0.1371 - val_loss: 3.6921 - learning_rate: 1.0000e-04\nEpoch 3/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1065 - loss: 3.8720{'accuracy': 0.10968269407749176, 'loss': 3.8487112522125244, 'val_accuracy': 0.15449999272823334, 'val_loss': 3.583721399307251}\n\nEpoch 3: accuracy improved from 0.09159 to 0.10968, saving model to best_weights_v1.weights.h5\n\nEpoch 3: val_accuracy improved from 0.13710 to 0.15450, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1065 - loss: 3.8720 - val_accuracy: 0.1545 - val_loss: 3.5837 - learning_rate: 1.0000e-04\nEpoch 4/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1183 - loss: 3.7896{'accuracy': 0.1207721158862114, 'loss': 3.774487018585205, 'val_accuracy': 0.1648000031709671, 'val_loss': 3.5253000259399414}\n\nEpoch 4: accuracy improved from 0.10968 to 0.12077, saving model to best_weights_v1.weights.h5\n\nEpoch 4: val_accuracy improved from 0.15450 to 0.16480, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1183 - loss: 3.7896 - val_accuracy: 0.1648 - val_loss: 3.5253 - learning_rate: 1.0000e-04\nEpoch 5/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1272 - loss: 3.7313{'accuracy': 0.12902307510375977, 'loss': 3.7190442085266113, 'val_accuracy': 0.17030000686645508, 'val_loss': 3.4711530208587646}\n\nEpoch 5: accuracy improved from 0.12077 to 0.12902, saving model to best_weights_v1.weights.h5\n\nEpoch 5: val_accuracy improved from 0.16480 to 0.17030, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1272 - loss: 3.7313 - val_accuracy: 0.1703 - val_loss: 3.4712 - learning_rate: 1.0000e-04\nEpoch 6/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1347 - loss: 3.6845{'accuracy': 0.13641537725925446, 'loss': 3.674452543258667, 'val_accuracy': 0.17649999260902405, 'val_loss': 3.439399242401123}\n\nEpoch 6: accuracy improved from 0.12902 to 0.13642, saving model to best_weights_v1.weights.h5\n\nEpoch 6: val_accuracy improved from 0.17030 to 0.17650, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1347 - loss: 3.6845 - val_accuracy: 0.1765 - val_loss: 3.4394 - learning_rate: 1.0000e-04\nEpoch 7/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1410 - loss: 3.6424{'accuracy': 0.14255577325820923, 'loss': 3.6346917152404785, 'val_accuracy': 0.18330000340938568, 'val_loss': 3.410153865814209}\n\nEpoch 7: accuracy improved from 0.13642 to 0.14256, saving model to best_weights_v1.weights.h5\n\nEpoch 7: val_accuracy improved from 0.17650 to 0.18330, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1410 - loss: 3.6424 - val_accuracy: 0.1833 - val_loss: 3.4102 - learning_rate: 1.0000e-04\nEpoch 8/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1470 - loss: 3.6061{'accuracy': 0.1481182724237442, 'loss': 3.600750684738159, 'val_accuracy': 0.19169999659061432, 'val_loss': 3.3691186904907227}\n\nEpoch 8: accuracy improved from 0.14256 to 0.14812, saving model to best_weights_v1.weights.h5\n\nEpoch 8: val_accuracy improved from 0.18330 to 0.19170, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1470 - loss: 3.6061 - val_accuracy: 0.1917 - val_loss: 3.3691 - learning_rate: 1.0000e-04\nEpoch 9/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1517 - loss: 3.5741{'accuracy': 0.15268366038799286, 'loss': 3.5698108673095703, 'val_accuracy': 0.19689999520778656, 'val_loss': 3.3441379070281982}\n\nEpoch 9: accuracy improved from 0.14812 to 0.15268, saving model to best_weights_v1.weights.h5\n\nEpoch 9: val_accuracy improved from 0.19170 to 0.19690, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1517 - loss: 3.5741 - val_accuracy: 0.1969 - val_loss: 3.3441 - learning_rate: 1.0000e-04\nEpoch 10/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1560 - loss: 3.5466{'accuracy': 0.15735384821891785, 'loss': 3.540701389312744, 'val_accuracy': 0.19900000095367432, 'val_loss': 3.3173301219940186}\n\nEpoch 10: accuracy improved from 0.15268 to 0.15735, saving model to best_weights_v1.weights.h5\n\nEpoch 10: val_accuracy improved from 0.19690 to 0.19900, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1560 - loss: 3.5466 - val_accuracy: 0.1990 - val_loss: 3.3173 - learning_rate: 1.0000e-04\nEpoch 11/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1613 - loss: 3.5148{'accuracy': 0.1621384620666504, 'loss': 3.5106968879699707, 'val_accuracy': 0.20730000734329224, 'val_loss': 3.290905475616455}\n\nEpoch 11: accuracy improved from 0.15735 to 0.16214, saving model to best_weights_v1.weights.h5\n\nEpoch 11: val_accuracy improved from 0.19900 to 0.20730, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1613 - loss: 3.5148 - val_accuracy: 0.2073 - val_loss: 3.2909 - learning_rate: 1.0000e-04\nEpoch 12/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1660 - loss: 3.4887{'accuracy': 0.16641250252723694, 'loss': 3.485769271850586, 'val_accuracy': 0.21080000698566437, 'val_loss': 3.25890851020813}\n\nEpoch 12: accuracy improved from 0.16214 to 0.16641, saving model to best_weights_v1.weights.h5\n\nEpoch 12: val_accuracy improved from 0.20730 to 0.21080, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1660 - loss: 3.4887 - val_accuracy: 0.2108 - val_loss: 3.2589 - learning_rate: 1.0000e-04\nEpoch 13/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1708 - loss: 3.4624{'accuracy': 0.1709423065185547, 'loss': 3.461013078689575, 'val_accuracy': 0.21770000457763672, 'val_loss': 3.23844051361084}\n\nEpoch 13: accuracy improved from 0.16641 to 0.17094, saving model to best_weights_v1.weights.h5\n\nEpoch 13: val_accuracy improved from 0.21080 to 0.21770, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1708 - loss: 3.4624 - val_accuracy: 0.2177 - val_loss: 3.2384 - learning_rate: 1.0000e-04\nEpoch 14/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1747 - loss: 3.4387{'accuracy': 0.1750144213438034, 'loss': 3.4371960163116455, 'val_accuracy': 0.2159000039100647, 'val_loss': 3.229119062423706}\n\nEpoch 14: accuracy improved from 0.17094 to 0.17501, saving model to best_weights_v1.weights.h5\n\nEpoch 14: val_accuracy did not improve from 0.21770\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1747 - loss: 3.4387 - val_accuracy: 0.2159 - val_loss: 3.2291 - learning_rate: 1.0000e-04\nEpoch 15/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1780 - loss: 3.4183{'accuracy': 0.17883846163749695, 'loss': 3.4135756492614746, 'val_accuracy': 0.2175000011920929, 'val_loss': 3.21016526222229}\n\nEpoch 15: accuracy improved from 0.17501 to 0.17884, saving model to best_weights_v1.weights.h5\n\nEpoch 15: val_accuracy did not improve from 0.21770\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1780 - loss: 3.4183 - val_accuracy: 0.2175 - val_loss: 3.2102 - learning_rate: 1.0000e-04\nEpoch 16/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1811 - loss: 3.3966{'accuracy': 0.1817076951265335, 'loss': 3.3925063610076904, 'val_accuracy': 0.22390000522136688, 'val_loss': 3.199058771133423}\n\nEpoch 16: accuracy improved from 0.17884 to 0.18171, saving model to best_weights_v1.weights.h5\n\nEpoch 16: val_accuracy improved from 0.21770 to 0.22390, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1811 - loss: 3.3966 - val_accuracy: 0.2239 - val_loss: 3.1991 - learning_rate: 1.0000e-04\nEpoch 17/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1844 - loss: 3.3735{'accuracy': 0.1852298080921173, 'loss': 3.371396064758301, 'val_accuracy': 0.2281000018119812, 'val_loss': 3.1823158264160156}\n\nEpoch 17: accuracy improved from 0.18171 to 0.18523, saving model to best_weights_v1.weights.h5\n\nEpoch 17: val_accuracy improved from 0.22390 to 0.22810, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1844 - loss: 3.3735 - val_accuracy: 0.2281 - val_loss: 3.1823 - learning_rate: 1.0000e-04\nEpoch 18/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1883 - loss: 3.3536{'accuracy': 0.18866346776485443, 'loss': 3.351593494415283, 'val_accuracy': 0.23229999840259552, 'val_loss': 3.1636736392974854}\n\nEpoch 18: accuracy improved from 0.18523 to 0.18866, saving model to best_weights_v1.weights.h5\n\nEpoch 18: val_accuracy improved from 0.22810 to 0.23230, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1883 - loss: 3.3536 - val_accuracy: 0.2323 - val_loss: 3.1637 - learning_rate: 1.0000e-04\nEpoch 19/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1923 - loss: 3.3349{'accuracy': 0.19240672886371613, 'loss': 3.332369327545166, 'val_accuracy': 0.23170000314712524, 'val_loss': 3.159613609313965}\n\nEpoch 19: accuracy improved from 0.18866 to 0.19241, saving model to best_weights_v1.weights.h5\n\nEpoch 19: val_accuracy did not improve from 0.23230\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1923 - loss: 3.3349 - val_accuracy: 0.2317 - val_loss: 3.1596 - learning_rate: 1.0000e-04\nEpoch 20/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1949 - loss: 3.3165{'accuracy': 0.19571442902088165, 'loss': 3.3131144046783447, 'val_accuracy': 0.23890000581741333, 'val_loss': 3.127486228942871}\n\nEpoch 20: accuracy improved from 0.19241 to 0.19571, saving model to best_weights_v1.weights.h5\n\nEpoch 20: val_accuracy improved from 0.23230 to 0.23890, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1949 - loss: 3.3165 - val_accuracy: 0.2389 - val_loss: 3.1275 - learning_rate: 1.0000e-04\nEpoch 21/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1981 - loss: 3.2952{'accuracy': 0.198515385389328, 'loss': 3.2944488525390625, 'val_accuracy': 0.24210000038146973, 'val_loss': 3.1140973567962646}\n\nEpoch 21: accuracy improved from 0.19571 to 0.19852, saving model to best_weights_v1.weights.h5\n\nEpoch 21: val_accuracy improved from 0.23890 to 0.24210, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.1981 - loss: 3.2952 - val_accuracy: 0.2421 - val_loss: 3.1141 - learning_rate: 1.0000e-04\nEpoch 22/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2017 - loss: 3.2767{'accuracy': 0.20160096883773804, 'loss': 3.2777349948883057, 'val_accuracy': 0.24560000002384186, 'val_loss': 3.1060280799865723}\n\nEpoch 22: accuracy improved from 0.19852 to 0.20160, saving model to best_weights_v1.weights.h5\n\nEpoch 22: val_accuracy improved from 0.24210 to 0.24560, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2017 - loss: 3.2767 - val_accuracy: 0.2456 - val_loss: 3.1060 - learning_rate: 1.0000e-04\nEpoch 23/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2049 - loss: 3.2594{'accuracy': 0.2049865424633026, 'loss': 3.2593235969543457, 'val_accuracy': 0.2460000067949295, 'val_loss': 3.108527660369873}\n\nEpoch 23: accuracy improved from 0.20160 to 0.20499, saving model to best_weights_v1.weights.h5\n\nEpoch 23: val_accuracy improved from 0.24560 to 0.24600, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2049 - loss: 3.2594 - val_accuracy: 0.2460 - val_loss: 3.1085 - learning_rate: 1.0000e-04\nEpoch 24/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2073 - loss: 3.2461{'accuracy': 0.20743557810783386, 'loss': 3.244508981704712, 'val_accuracy': 0.25060001015663147, 'val_loss': 3.095848321914673}\n\nEpoch 24: accuracy improved from 0.20499 to 0.20744, saving model to best_weights_v1.weights.h5\n\nEpoch 24: val_accuracy improved from 0.24600 to 0.25060, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2073 - loss: 3.2461 - val_accuracy: 0.2506 - val_loss: 3.0958 - learning_rate: 1.0000e-04\nEpoch 25/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2100 - loss: 3.2260{'accuracy': 0.21030481159687042, 'loss': 3.2256522178649902, 'val_accuracy': 0.25119999051094055, 'val_loss': 3.072608709335327}\n\nEpoch 25: accuracy improved from 0.20744 to 0.21030, saving model to best_weights_v1.weights.h5\n\nEpoch 25: val_accuracy improved from 0.25060 to 0.25120, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2100 - loss: 3.2260 - val_accuracy: 0.2512 - val_loss: 3.0726 - learning_rate: 1.0000e-04\nEpoch 26/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2129 - loss: 3.2100{'accuracy': 0.21350961923599243, 'loss': 3.2101070880889893, 'val_accuracy': 0.2529999911785126, 'val_loss': 3.0693678855895996}\n\nEpoch 26: accuracy improved from 0.21030 to 0.21351, saving model to best_weights_v1.weights.h5\n\nEpoch 26: val_accuracy improved from 0.25120 to 0.25300, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2129 - loss: 3.2100 - val_accuracy: 0.2530 - val_loss: 3.0694 - learning_rate: 1.0000e-04\nEpoch 27/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2160 - loss: 3.1944{'accuracy': 0.21604807674884796, 'loss': 3.195725679397583, 'val_accuracy': 0.2547999918460846, 'val_loss': 3.0629453659057617}\n\nEpoch 27: accuracy improved from 0.21351 to 0.21605, saving model to best_weights_v1.weights.h5\n\nEpoch 27: val_accuracy improved from 0.25300 to 0.25480, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2160 - loss: 3.1945 - val_accuracy: 0.2548 - val_loss: 3.0629 - learning_rate: 1.0000e-04\nEpoch 28/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2190 - loss: 3.1809{'accuracy': 0.2194826900959015, 'loss': 3.1792116165161133, 'val_accuracy': 0.25850000977516174, 'val_loss': 3.047699451446533}\n\nEpoch 28: accuracy improved from 0.21605 to 0.21948, saving model to best_weights_v1.weights.h5\n\nEpoch 28: val_accuracy improved from 0.25480 to 0.25850, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2190 - loss: 3.1809 - val_accuracy: 0.2585 - val_loss: 3.0477 - learning_rate: 1.0000e-04\nEpoch 29/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2209 - loss: 3.1640{'accuracy': 0.2212201952934265, 'loss': 3.1648645401000977, 'val_accuracy': 0.262800008058548, 'val_loss': 3.037919044494629}\n\nEpoch 29: accuracy improved from 0.21948 to 0.22122, saving model to best_weights_v1.weights.h5\n\nEpoch 29: val_accuracy improved from 0.25850 to 0.26280, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2209 - loss: 3.1640 - val_accuracy: 0.2628 - val_loss: 3.0379 - learning_rate: 1.0000e-04\nEpoch 30/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2243 - loss: 3.1498{'accuracy': 0.22408558428287506, 'loss': 3.150620698928833, 'val_accuracy': 0.25940001010894775, 'val_loss': 3.047682762145996}\n\nEpoch 30: accuracy improved from 0.22122 to 0.22409, saving model to best_weights_v1.weights.h5\n\nEpoch 30: val_accuracy did not improve from 0.26280\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2243 - loss: 3.1498 - val_accuracy: 0.2594 - val_loss: 3.0477 - learning_rate: 1.0000e-04\nEpoch 31/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2266 - loss: 3.1386{'accuracy': 0.2263692319393158, 'loss': 3.1383185386657715, 'val_accuracy': 0.2648000121116638, 'val_loss': 3.0345242023468018}\n\nEpoch 31: accuracy improved from 0.22409 to 0.22637, saving model to best_weights_v1.weights.h5\n\nEpoch 31: val_accuracy improved from 0.26280 to 0.26480, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2266 - loss: 3.1386 - val_accuracy: 0.2648 - val_loss: 3.0345 - learning_rate: 1.0000e-04\nEpoch 32/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2287 - loss: 3.1278{'accuracy': 0.22944039106369019, 'loss': 3.124143123626709, 'val_accuracy': 0.26809999346733093, 'val_loss': 3.02999210357666}\n\nEpoch 32: accuracy improved from 0.22637 to 0.22944, saving model to best_weights_v1.weights.h5\n\nEpoch 32: val_accuracy improved from 0.26480 to 0.26810, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2287 - loss: 3.1278 - val_accuracy: 0.2681 - val_loss: 3.0300 - learning_rate: 1.0000e-04\nEpoch 33/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2314 - loss: 3.1095{'accuracy': 0.231113463640213, 'loss': 3.1113076210021973, 'val_accuracy': 0.26260000467300415, 'val_loss': 3.0334088802337646}\n\nEpoch 33: accuracy improved from 0.22944 to 0.23111, saving model to best_weights_v1.weights.h5\n\nEpoch 33: val_accuracy did not improve from 0.26810\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2314 - loss: 3.1096 - val_accuracy: 0.2626 - val_loss: 3.0334 - learning_rate: 1.0000e-04\nEpoch 34/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2345 - loss: 3.0942{'accuracy': 0.23407788574695587, 'loss': 3.097144365310669, 'val_accuracy': 0.2662000060081482, 'val_loss': 3.0108702182769775}\n\nEpoch 34: accuracy improved from 0.23111 to 0.23408, saving model to best_weights_v1.weights.h5\n\nEpoch 34: val_accuracy did not improve from 0.26810\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2345 - loss: 3.0942 - val_accuracy: 0.2662 - val_loss: 3.0109 - learning_rate: 1.0000e-04\nEpoch 35/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2367 - loss: 3.0826{'accuracy': 0.23632115125656128, 'loss': 3.084444999694824, 'val_accuracy': 0.26489999890327454, 'val_loss': 3.016840696334839}\n\nEpoch 35: accuracy improved from 0.23408 to 0.23632, saving model to best_weights_v1.weights.h5\n\nEpoch 35: val_accuracy did not improve from 0.26810\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2367 - loss: 3.0826 - val_accuracy: 0.2649 - val_loss: 3.0168 - learning_rate: 1.0000e-04\nEpoch 36/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2383 - loss: 3.0740{'accuracy': 0.23840384185314178, 'loss': 3.0729925632476807, 'val_accuracy': 0.2689000070095062, 'val_loss': 3.0178487300872803}\n\nEpoch 36: accuracy improved from 0.23632 to 0.23840, saving model to best_weights_v1.weights.h5\n\nEpoch 36: val_accuracy improved from 0.26810 to 0.26890, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2383 - loss: 3.0740 - val_accuracy: 0.2689 - val_loss: 3.0178 - learning_rate: 1.0000e-04\nEpoch 37/100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2417 - loss: 3.0594{'accuracy': 0.24141442775726318, 'loss': 3.0599398612976074, 'val_accuracy': 0.2727000117301941, 'val_loss': 3.017293930053711}\n\nEpoch 37: accuracy improved from 0.23840 to 0.24141, saving model to best_weights_v1.weights.h5\n\nEpoch 37: val_accuracy improved from 0.26890 to 0.27270, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2417 - loss: 3.0594 - val_accuracy: 0.2727 - val_loss: 3.0173 - learning_rate: 1.0000e-04\nEpoch 38/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2439 - loss: 3.0468{'accuracy': 0.2432413399219513, 'loss': 3.0498807430267334, 'val_accuracy': 0.27219998836517334, 'val_loss': 2.9969379901885986}\n\nEpoch 38: accuracy improved from 0.24141 to 0.24324, saving model to best_weights_v1.weights.h5\n\nEpoch 38: val_accuracy did not improve from 0.27270\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2439 - loss: 3.0468 - val_accuracy: 0.2722 - val_loss: 2.9969 - learning_rate: 1.0000e-04\nEpoch 39/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2447 - loss: 3.0387{'accuracy': 0.24469999969005585, 'loss': 3.038330078125, 'val_accuracy': 0.27300000190734863, 'val_loss': 2.9947285652160645}\n\nEpoch 39: accuracy improved from 0.24324 to 0.24470, saving model to best_weights_v1.weights.h5\n\nEpoch 39: val_accuracy improved from 0.27270 to 0.27300, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2447 - loss: 3.0387 - val_accuracy: 0.2730 - val_loss: 2.9947 - learning_rate: 1.0000e-04\nEpoch 40/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2464 - loss: 3.0252{'accuracy': 0.24653364717960358, 'loss': 3.026884078979492, 'val_accuracy': 0.2732999920845032, 'val_loss': 3.0103397369384766}\n\nEpoch 40: accuracy improved from 0.24470 to 0.24653, saving model to best_weights_v1.weights.h5\n\nEpoch 40: val_accuracy improved from 0.27300 to 0.27330, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2464 - loss: 3.0252 - val_accuracy: 0.2733 - val_loss: 3.0103 - learning_rate: 1.0000e-04\nEpoch 41/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2496 - loss: 3.0136{'accuracy': 0.24882884323596954, 'loss': 3.016353130340576, 'val_accuracy': 0.273499995470047, 'val_loss': 3.0067975521087646}\n\nEpoch 41: accuracy improved from 0.24653 to 0.24883, saving model to best_weights_v1.weights.h5\n\nEpoch 41: val_accuracy improved from 0.27330 to 0.27350, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2496 - loss: 3.0136 - val_accuracy: 0.2735 - val_loss: 3.0068 - learning_rate: 1.0000e-04\nEpoch 42/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2511 - loss: 3.0073{'accuracy': 0.2510884702205658, 'loss': 3.00605845451355, 'val_accuracy': 0.27399998903274536, 'val_loss': 2.9961588382720947}\n\nEpoch 42: accuracy improved from 0.24883 to 0.25109, saving model to best_weights_v1.weights.h5\n\nEpoch 42: val_accuracy improved from 0.27350 to 0.27400, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2511 - loss: 3.0073 - val_accuracy: 0.2740 - val_loss: 2.9962 - learning_rate: 1.0000e-04\nEpoch 43/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2540 - loss: 2.9925{'accuracy': 0.25331729650497437, 'loss': 2.9945428371429443, 'val_accuracy': 0.2741999924182892, 'val_loss': 2.9971301555633545}\n\nEpoch 43: accuracy improved from 0.25109 to 0.25332, saving model to best_weights_v1.weights.h5\n\nEpoch 43: val_accuracy improved from 0.27400 to 0.27420, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2540 - loss: 2.9925 - val_accuracy: 0.2742 - val_loss: 2.9971 - learning_rate: 1.0000e-04\nEpoch 44/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2553 - loss: 2.9848{'accuracy': 0.25485673546791077, 'loss': 2.9871888160705566, 'val_accuracy': 0.27309998869895935, 'val_loss': 3.0006768703460693}\n\nEpoch 44: accuracy improved from 0.25332 to 0.25486, saving model to best_weights_v1.weights.h5\n\nEpoch 44: val_accuracy did not improve from 0.27420\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2553 - loss: 2.9848 - val_accuracy: 0.2731 - val_loss: 3.0007 - learning_rate: 1.0000e-04\nEpoch 45/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2573 - loss: 2.9778{'accuracy': 0.25703173875808716, 'loss': 2.97709321975708, 'val_accuracy': 0.275299996137619, 'val_loss': 2.9999992847442627}\n\nEpoch 45: accuracy improved from 0.25486 to 0.25703, saving model to best_weights_v1.weights.h5\n\nEpoch 45: val_accuracy improved from 0.27420 to 0.27530, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2573 - loss: 2.9778 - val_accuracy: 0.2753 - val_loss: 3.0000 - learning_rate: 1.0000e-04\nEpoch 46/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2586 - loss: 2.9647{'accuracy': 0.2586855888366699, 'loss': 2.965810775756836, 'val_accuracy': 0.2782000005245209, 'val_loss': 2.9927380084991455}\n\nEpoch 46: accuracy improved from 0.25703 to 0.25869, saving model to best_weights_v1.weights.h5\n\nEpoch 46: val_accuracy improved from 0.27530 to 0.27820, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2586 - loss: 2.9647 - val_accuracy: 0.2782 - val_loss: 2.9927 - learning_rate: 1.0000e-04\nEpoch 47/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2602 - loss: 2.9546{'accuracy': 0.2596451938152313, 'loss': 2.958463668823242, 'val_accuracy': 0.2773999869823456, 'val_loss': 2.9797937870025635}\n\nEpoch 47: accuracy improved from 0.25869 to 0.25965, saving model to best_weights_v1.weights.h5\n\nEpoch 47: val_accuracy did not improve from 0.27820\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2602 - loss: 2.9546 - val_accuracy: 0.2774 - val_loss: 2.9798 - learning_rate: 1.0000e-04\nEpoch 48/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2628 - loss: 2.9445{'accuracy': 0.26234614849090576, 'loss': 2.9469926357269287, 'val_accuracy': 0.2750000059604645, 'val_loss': 2.9793450832366943}\n\nEpoch 48: accuracy improved from 0.25965 to 0.26235, saving model to best_weights_v1.weights.h5\n\nEpoch 48: val_accuracy did not improve from 0.27820\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2628 - loss: 2.9445 - val_accuracy: 0.2750 - val_loss: 2.9793 - learning_rate: 1.0000e-04\nEpoch 49/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2637 - loss: 2.9373{'accuracy': 0.263259619474411, 'loss': 2.940495252609253, 'val_accuracy': 0.27950000762939453, 'val_loss': 2.9791159629821777}\n\nEpoch 49: accuracy improved from 0.26235 to 0.26326, saving model to best_weights_v1.weights.h5\n\nEpoch 49: val_accuracy improved from 0.27820 to 0.27950, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2637 - loss: 2.9373 - val_accuracy: 0.2795 - val_loss: 2.9791 - learning_rate: 1.0000e-04\nEpoch 50/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2666 - loss: 2.9277{'accuracy': 0.26561057567596436, 'loss': 2.929705858230591, 'val_accuracy': 0.28130000829696655, 'val_loss': 2.978668212890625}\n\nEpoch 50: accuracy improved from 0.26326 to 0.26561, saving model to best_weights_v1.weights.h5\n\nEpoch 50: val_accuracy improved from 0.27950 to 0.28130, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2666 - loss: 2.9277 - val_accuracy: 0.2813 - val_loss: 2.9787 - learning_rate: 1.0000e-04\nEpoch 51/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2678 - loss: 2.9188{'accuracy': 0.267347127199173, 'loss': 2.921455144882202, 'val_accuracy': 0.28299999237060547, 'val_loss': 2.9801418781280518}\n\nEpoch 51: accuracy improved from 0.26561 to 0.26735, saving model to best_weights_v1.weights.h5\n\nEpoch 51: val_accuracy improved from 0.28130 to 0.28300, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2678 - loss: 2.9188 - val_accuracy: 0.2830 - val_loss: 2.9801 - learning_rate: 1.0000e-04\nEpoch 52/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2691 - loss: 2.9120{'accuracy': 0.26881441473960876, 'loss': 2.912097930908203, 'val_accuracy': 0.28369998931884766, 'val_loss': 2.9760470390319824}\n\nEpoch 52: accuracy improved from 0.26735 to 0.26881, saving model to best_weights_v1.weights.h5\n\nEpoch 52: val_accuracy improved from 0.28300 to 0.28370, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2691 - loss: 2.9120 - val_accuracy: 0.2837 - val_loss: 2.9760 - learning_rate: 1.0000e-04\nEpoch 53/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2702 - loss: 2.9044{'accuracy': 0.26990193128585815, 'loss': 2.90626859664917, 'val_accuracy': 0.28029999136924744, 'val_loss': 2.9792346954345703}\n\nEpoch 53: accuracy improved from 0.26881 to 0.26990, saving model to best_weights_v1.weights.h5\n\nEpoch 53: val_accuracy did not improve from 0.28370\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2702 - loss: 2.9044 - val_accuracy: 0.2803 - val_loss: 2.9792 - learning_rate: 1.0000e-04\nEpoch 54/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2727 - loss: 2.8946{'accuracy': 0.2717009484767914, 'loss': 2.897538185119629, 'val_accuracy': 0.2809000015258789, 'val_loss': 2.974893093109131}\n\nEpoch 54: accuracy improved from 0.26990 to 0.27170, saving model to best_weights_v1.weights.h5\n\nEpoch 54: val_accuracy did not improve from 0.28370\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2727 - loss: 2.8946 - val_accuracy: 0.2809 - val_loss: 2.9749 - learning_rate: 1.0000e-04\nEpoch 55/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2738 - loss: 2.8863{'accuracy': 0.27312788367271423, 'loss': 2.8897178173065186, 'val_accuracy': 0.2838999927043915, 'val_loss': 2.972501277923584}\n\nEpoch 55: accuracy improved from 0.27170 to 0.27313, saving model to best_weights_v1.weights.h5\n\nEpoch 55: val_accuracy improved from 0.28370 to 0.28390, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2738 - loss: 2.8863 - val_accuracy: 0.2839 - val_loss: 2.9725 - learning_rate: 1.0000e-04\nEpoch 56/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2760 - loss: 2.8756{'accuracy': 0.2745952010154724, 'loss': 2.8825371265411377, 'val_accuracy': 0.28459998965263367, 'val_loss': 2.978084087371826}\n\nEpoch 56: accuracy improved from 0.27313 to 0.27460, saving model to best_weights_v1.weights.h5\n\nEpoch 56: val_accuracy improved from 0.28390 to 0.28460, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2760 - loss: 2.8756 - val_accuracy: 0.2846 - val_loss: 2.9781 - learning_rate: 1.0000e-04\nEpoch 57/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2771 - loss: 2.8704{'accuracy': 0.2763894200325012, 'loss': 2.872418165206909, 'val_accuracy': 0.2847999930381775, 'val_loss': 2.978311061859131}\n\nEpoch 57: accuracy improved from 0.27460 to 0.27639, saving model to best_weights_v1.weights.h5\n\nEpoch 57: val_accuracy improved from 0.28460 to 0.28480, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2771 - loss: 2.8704 - val_accuracy: 0.2848 - val_loss: 2.9783 - learning_rate: 1.0000e-04\nEpoch 58/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2781 - loss: 2.8639{'accuracy': 0.27778366208076477, 'loss': 2.866781234741211, 'val_accuracy': 0.28189998865127563, 'val_loss': 2.9770114421844482}\n\nEpoch 58: accuracy improved from 0.27639 to 0.27778, saving model to best_weights_v1.weights.h5\n\nEpoch 58: val_accuracy did not improve from 0.28480\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2781 - loss: 2.8639 - val_accuracy: 0.2819 - val_loss: 2.9770 - learning_rate: 1.0000e-04\nEpoch 59/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2803 - loss: 2.8553{'accuracy': 0.2796173095703125, 'loss': 2.8601818084716797, 'val_accuracy': 0.28279998898506165, 'val_loss': 2.9681897163391113}\n\nEpoch 59: accuracy improved from 0.27778 to 0.27962, saving model to best_weights_v1.weights.h5\n\nEpoch 59: val_accuracy did not improve from 0.28480\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2803 - loss: 2.8553 - val_accuracy: 0.2828 - val_loss: 2.9682 - learning_rate: 1.0000e-04\nEpoch 60/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2812 - loss: 2.8503{'accuracy': 0.28052404522895813, 'loss': 2.854140520095825, 'val_accuracy': 0.28679999709129333, 'val_loss': 2.9621381759643555}\n\nEpoch 60: accuracy improved from 0.27962 to 0.28052, saving model to best_weights_v1.weights.h5\n\nEpoch 60: val_accuracy improved from 0.28480 to 0.28680, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2812 - loss: 2.8503 - val_accuracy: 0.2868 - val_loss: 2.9621 - learning_rate: 1.0000e-04\nEpoch 61/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2822 - loss: 2.8430{'accuracy': 0.28206729888916016, 'loss': 2.8445746898651123, 'val_accuracy': 0.28769999742507935, 'val_loss': 2.956587791442871}\n\nEpoch 61: accuracy improved from 0.28052 to 0.28207, saving model to best_weights_v1.weights.h5\n\nEpoch 61: val_accuracy improved from 0.28680 to 0.28770, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2822 - loss: 2.8430 - val_accuracy: 0.2877 - val_loss: 2.9566 - learning_rate: 1.0000e-04\nEpoch 62/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2837 - loss: 2.8352{'accuracy': 0.2830807566642761, 'loss': 2.8392174243927, 'val_accuracy': 0.28380000591278076, 'val_loss': 2.9767608642578125}\n\nEpoch 62: accuracy improved from 0.28207 to 0.28308, saving model to best_weights_v1.weights.h5\n\nEpoch 62: val_accuracy did not improve from 0.28770\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2837 - loss: 2.8353 - val_accuracy: 0.2838 - val_loss: 2.9768 - learning_rate: 1.0000e-04\nEpoch 63/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2850 - loss: 2.8315{'accuracy': 0.2846692204475403, 'loss': 2.8327341079711914, 'val_accuracy': 0.28610000014305115, 'val_loss': 2.971193313598633}\n\nEpoch 63: accuracy improved from 0.28308 to 0.28467, saving model to best_weights_v1.weights.h5\n\nEpoch 63: val_accuracy did not improve from 0.28770\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2850 - loss: 2.8315 - val_accuracy: 0.2861 - val_loss: 2.9712 - learning_rate: 1.0000e-04\nEpoch 64/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2876 - loss: 2.8213{'accuracy': 0.2860240340232849, 'loss': 2.825450897216797, 'val_accuracy': 0.2847999930381775, 'val_loss': 2.972242832183838}\n\nEpoch 64: accuracy improved from 0.28467 to 0.28602, saving model to best_weights_v1.weights.h5\n\nEpoch 64: val_accuracy did not improve from 0.28770\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2876 - loss: 2.8214 - val_accuracy: 0.2848 - val_loss: 2.9722 - learning_rate: 1.0000e-04\nEpoch 65/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2877 - loss: 2.8181{'accuracy': 0.28706249594688416, 'loss': 2.820530891418457, 'val_accuracy': 0.2856999933719635, 'val_loss': 2.9632210731506348}\n\nEpoch 65: accuracy improved from 0.28602 to 0.28706, saving model to best_weights_v1.weights.h5\n\nEpoch 65: val_accuracy did not improve from 0.28770\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2877 - loss: 2.8181 - val_accuracy: 0.2857 - val_loss: 2.9632 - learning_rate: 1.0000e-04\nEpoch 66/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2884 - loss: 2.8109{'accuracy': 0.288033664226532, 'loss': 2.814685344696045, 'val_accuracy': 0.288100004196167, 'val_loss': 2.974963903427124}\n\nEpoch 66: accuracy improved from 0.28706 to 0.28803, saving model to best_weights_v1.weights.h5\n\nEpoch 66: val_accuracy improved from 0.28770 to 0.28810, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2884 - loss: 2.8109 - val_accuracy: 0.2881 - val_loss: 2.9750 - learning_rate: 1.0000e-04\nEpoch 67/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2895 - loss: 2.8046{'accuracy': 0.28965288400650024, 'loss': 2.8073508739471436, 'val_accuracy': 0.2904999852180481, 'val_loss': 2.972360849380493}\n\nEpoch 67: accuracy improved from 0.28803 to 0.28965, saving model to best_weights_v1.weights.h5\n\nEpoch 67: val_accuracy improved from 0.28810 to 0.29050, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2895 - loss: 2.8046 - val_accuracy: 0.2905 - val_loss: 2.9724 - learning_rate: 1.0000e-04\nEpoch 68/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2907 - loss: 2.8007{'accuracy': 0.29020193219184875, 'loss': 2.8027424812316895, 'val_accuracy': 0.289900004863739, 'val_loss': 2.971592903137207}\n\nEpoch 68: accuracy improved from 0.28965 to 0.29020, saving model to best_weights_v1.weights.h5\n\nEpoch 68: val_accuracy did not improve from 0.29050\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2907 - loss: 2.8007 - val_accuracy: 0.2899 - val_loss: 2.9716 - learning_rate: 1.0000e-04\nEpoch 69/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2908 - loss: 2.7956{'accuracy': 0.2911759614944458, 'loss': 2.796348810195923, 'val_accuracy': 0.29100000858306885, 'val_loss': 2.952864170074463}\n\nEpoch 69: accuracy improved from 0.29020 to 0.29118, saving model to best_weights_v1.weights.h5\n\nEpoch 69: val_accuracy improved from 0.29050 to 0.29100, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2908 - loss: 2.7956 - val_accuracy: 0.2910 - val_loss: 2.9529 - learning_rate: 1.0000e-04\nEpoch 70/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2935 - loss: 2.7862{'accuracy': 0.2927471101284027, 'loss': 2.789384126663208, 'val_accuracy': 0.28949999809265137, 'val_loss': 2.9600870609283447}\n\nEpoch 70: accuracy improved from 0.29118 to 0.29275, saving model to best_weights_v1.weights.h5\n\nEpoch 70: val_accuracy did not improve from 0.29100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2935 - loss: 2.7862 - val_accuracy: 0.2895 - val_loss: 2.9601 - learning_rate: 1.0000e-04\nEpoch 71/100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2943 - loss: 2.7819{'accuracy': 0.2939355671405792, 'loss': 2.785588502883911, 'val_accuracy': 0.28850001096725464, 'val_loss': 2.9670279026031494}\n\nEpoch 71: accuracy improved from 0.29275 to 0.29394, saving model to best_weights_v1.weights.h5\n\nEpoch 71: val_accuracy did not improve from 0.29100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2943 - loss: 2.7819 - val_accuracy: 0.2885 - val_loss: 2.9670 - learning_rate: 1.0000e-04\nEpoch 72/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2965 - loss: 2.7733{'accuracy': 0.29510384798049927, 'loss': 2.778627395629883, 'val_accuracy': 0.2879999876022339, 'val_loss': 2.9603981971740723}\n\nEpoch 72: accuracy improved from 0.29394 to 0.29510, saving model to best_weights_v1.weights.h5\n\nEpoch 72: val_accuracy did not improve from 0.29100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2965 - loss: 2.7733 - val_accuracy: 0.2880 - val_loss: 2.9604 - learning_rate: 1.0000e-04\nEpoch 73/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2972 - loss: 2.7701{'accuracy': 0.29624807834625244, 'loss': 2.7729361057281494, 'val_accuracy': 0.2888999879360199, 'val_loss': 2.967090129852295}\n\nEpoch 73: accuracy improved from 0.29510 to 0.29625, saving model to best_weights_v1.weights.h5\n\nEpoch 73: val_accuracy did not improve from 0.29100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2972 - loss: 2.7701 - val_accuracy: 0.2889 - val_loss: 2.9671 - learning_rate: 1.0000e-04\nEpoch 74/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2980 - loss: 2.7645{'accuracy': 0.29785865545272827, 'loss': 2.7673709392547607, 'val_accuracy': 0.2888999879360199, 'val_loss': 2.967960834503174}\n\nEpoch 74: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\nEpoch 74: accuracy improved from 0.29625 to 0.29786, saving model to best_weights_v1.weights.h5\n\nEpoch 74: val_accuracy did not improve from 0.29100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2980 - loss: 2.7645 - val_accuracy: 0.2889 - val_loss: 2.9680 - learning_rate: 1.0000e-04\nEpoch 75/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3053 - loss: 2.7274{'accuracy': 0.3060894310474396, 'loss': 2.7233009338378906, 'val_accuracy': 0.29269999265670776, 'val_loss': 2.954465389251709}\n\nEpoch 75: accuracy improved from 0.29786 to 0.30609, saving model to best_weights_v1.weights.h5\n\nEpoch 75: val_accuracy improved from 0.29100 to 0.29270, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3053 - loss: 2.7274 - val_accuracy: 0.2927 - val_loss: 2.9545 - learning_rate: 5.0000e-05\nEpoch 76/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3076 - loss: 2.7135{'accuracy': 0.3081490397453308, 'loss': 2.71195912361145, 'val_accuracy': 0.2930000126361847, 'val_loss': 2.9599738121032715}\n\nEpoch 76: accuracy improved from 0.30609 to 0.30815, saving model to best_weights_v1.weights.h5\n\nEpoch 76: val_accuracy improved from 0.29270 to 0.29300, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3076 - loss: 2.7135 - val_accuracy: 0.2930 - val_loss: 2.9600 - learning_rate: 5.0000e-05\nEpoch 77/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3100 - loss: 2.7049{'accuracy': 0.3097086548805237, 'loss': 2.7058935165405273, 'val_accuracy': 0.29120001196861267, 'val_loss': 2.9531877040863037}\n\nEpoch 77: accuracy improved from 0.30815 to 0.30971, saving model to best_weights_v1.weights.h5\n\nEpoch 77: val_accuracy did not improve from 0.29300\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3100 - loss: 2.7049 - val_accuracy: 0.2912 - val_loss: 2.9532 - learning_rate: 5.0000e-05\nEpoch 78/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3117 - loss: 2.6933{'accuracy': 0.3106144368648529, 'loss': 2.699056386947632, 'val_accuracy': 0.2913999855518341, 'val_loss': 2.9653444290161133}\n\nEpoch 78: accuracy improved from 0.30971 to 0.31061, saving model to best_weights_v1.weights.h5\n\nEpoch 78: val_accuracy did not improve from 0.29300\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3117 - loss: 2.6933 - val_accuracy: 0.2914 - val_loss: 2.9653 - learning_rate: 5.0000e-05\nEpoch 79/100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3128 - loss: 2.6933{'accuracy': 0.3121740520000458, 'loss': 2.6947569847106934, 'val_accuracy': 0.29249998927116394, 'val_loss': 2.9586257934570312}\n\nEpoch 79: accuracy improved from 0.31061 to 0.31217, saving model to best_weights_v1.weights.h5\n\nEpoch 79: val_accuracy did not improve from 0.29300\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3128 - loss: 2.6933 - val_accuracy: 0.2925 - val_loss: 2.9586 - learning_rate: 5.0000e-05\nEpoch 80/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3137 - loss: 2.6882{'accuracy': 0.31331634521484375, 'loss': 2.6894924640655518, 'val_accuracy': 0.2921999990940094, 'val_loss': 2.958350419998169}\n\nEpoch 80: accuracy improved from 0.31217 to 0.31332, saving model to best_weights_v1.weights.h5\n\nEpoch 80: val_accuracy did not improve from 0.29300\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3137 - loss: 2.6882 - val_accuracy: 0.2922 - val_loss: 2.9584 - learning_rate: 5.0000e-05\nEpoch 81/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3137 - loss: 2.6834{'accuracy': 0.3134009540081024, 'loss': 2.68559193611145, 'val_accuracy': 0.29440000653266907, 'val_loss': 2.961862802505493}\n\nEpoch 81: accuracy improved from 0.31332 to 0.31340, saving model to best_weights_v1.weights.h5\n\nEpoch 81: val_accuracy improved from 0.29300 to 0.29440, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3137 - loss: 2.6834 - val_accuracy: 0.2944 - val_loss: 2.9619 - learning_rate: 5.0000e-05\nEpoch 82/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3147 - loss: 2.6790{'accuracy': 0.3138538599014282, 'loss': 2.6838769912719727, 'val_accuracy': 0.29499998688697815, 'val_loss': 2.95401668548584}\n\nEpoch 82: accuracy improved from 0.31340 to 0.31385, saving model to best_weights_v1.weights.h5\n\nEpoch 82: val_accuracy improved from 0.29440 to 0.29500, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3147 - loss: 2.6790 - val_accuracy: 0.2950 - val_loss: 2.9540 - learning_rate: 5.0000e-05\nEpoch 83/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3161 - loss: 2.6729{'accuracy': 0.3149971067905426, 'loss': 2.6767771244049072, 'val_accuracy': 0.29330000281333923, 'val_loss': 2.9612460136413574}\n\nEpoch 83: accuracy improved from 0.31385 to 0.31500, saving model to best_weights_v1.weights.h5\n\nEpoch 83: val_accuracy did not improve from 0.29500\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3161 - loss: 2.6729 - val_accuracy: 0.2933 - val_loss: 2.9612 - learning_rate: 5.0000e-05\nEpoch 84/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3157 - loss: 2.6731{'accuracy': 0.3152846097946167, 'loss': 2.676304817199707, 'val_accuracy': 0.2939999997615814, 'val_loss': 2.955320119857788}\n\nEpoch 84: accuracy improved from 0.31500 to 0.31528, saving model to best_weights_v1.weights.h5\n\nEpoch 84: val_accuracy did not improve from 0.29500\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3157 - loss: 2.6731 - val_accuracy: 0.2940 - val_loss: 2.9553 - learning_rate: 5.0000e-05\nEpoch 85/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3164 - loss: 2.6714{'accuracy': 0.3166932761669159, 'loss': 2.6694045066833496, 'val_accuracy': 0.29649999737739563, 'val_loss': 2.962381362915039}\n\nEpoch 85: accuracy improved from 0.31528 to 0.31669, saving model to best_weights_v1.weights.h5\n\nEpoch 85: val_accuracy improved from 0.29500 to 0.29650, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3164 - loss: 2.6714 - val_accuracy: 0.2965 - val_loss: 2.9624 - learning_rate: 5.0000e-05\nEpoch 86/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3191 - loss: 2.6616{'accuracy': 0.31753942370414734, 'loss': 2.667485237121582, 'val_accuracy': 0.2969000041484833, 'val_loss': 2.964965343475342}\n\nEpoch 86: accuracy improved from 0.31669 to 0.31754, saving model to best_weights_v1.weights.h5\n\nEpoch 86: val_accuracy improved from 0.29650 to 0.29690, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3191 - loss: 2.6616 - val_accuracy: 0.2969 - val_loss: 2.9650 - learning_rate: 5.0000e-05\nEpoch 87/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3182 - loss: 2.6607{'accuracy': 0.3178230822086334, 'loss': 2.6641297340393066, 'val_accuracy': 0.2955000102519989, 'val_loss': 2.969947576522827}\n\nEpoch 87: accuracy improved from 0.31754 to 0.31782, saving model to best_weights_v1.weights.h5\n\nEpoch 87: val_accuracy did not improve from 0.29690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3182 - loss: 2.6607 - val_accuracy: 0.2955 - val_loss: 2.9699 - learning_rate: 5.0000e-05\nEpoch 88/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3185 - loss: 2.6602{'accuracy': 0.31837692856788635, 'loss': 2.662696599960327, 'val_accuracy': 0.2955000102519989, 'val_loss': 2.966169834136963}\n\nEpoch 88: accuracy improved from 0.31782 to 0.31838, saving model to best_weights_v1.weights.h5\n\nEpoch 88: val_accuracy did not improve from 0.29690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3185 - loss: 2.6602 - val_accuracy: 0.2955 - val_loss: 2.9662 - learning_rate: 5.0000e-05\nEpoch 89/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3204 - loss: 2.6513{'accuracy': 0.31942883133888245, 'loss': 2.6561126708984375, 'val_accuracy': 0.2948000133037567, 'val_loss': 2.9638404846191406}\n\nEpoch 89: accuracy improved from 0.31838 to 0.31943, saving model to best_weights_v1.weights.h5\n\nEpoch 89: val_accuracy did not improve from 0.29690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3204 - loss: 2.6513 - val_accuracy: 0.2948 - val_loss: 2.9638 - learning_rate: 5.0000e-05\nEpoch 90/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3204 - loss: 2.6529{'accuracy': 0.3196432590484619, 'loss': 2.655585765838623, 'val_accuracy': 0.2964000105857849, 'val_loss': 2.9617578983306885}\n\nEpoch 90: accuracy improved from 0.31943 to 0.31964, saving model to best_weights_v1.weights.h5\n\nEpoch 90: val_accuracy did not improve from 0.29690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3204 - loss: 2.6529 - val_accuracy: 0.2964 - val_loss: 2.9618 - learning_rate: 5.0000e-05\nEpoch 91/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3208 - loss: 2.6498{'accuracy': 0.32058942317962646, 'loss': 2.652695894241333, 'val_accuracy': 0.29750001430511475, 'val_loss': 2.965195417404175}\n\nEpoch 91: accuracy improved from 0.31964 to 0.32059, saving model to best_weights_v1.weights.h5\n\nEpoch 91: val_accuracy improved from 0.29690 to 0.29750, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3208 - loss: 2.6498 - val_accuracy: 0.2975 - val_loss: 2.9652 - learning_rate: 5.0000e-05\nEpoch 92/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3216 - loss: 2.6445{'accuracy': 0.32078462839126587, 'loss': 2.648327112197876, 'val_accuracy': 0.2944999933242798, 'val_loss': 2.9630837440490723}\n\nEpoch 92: accuracy improved from 0.32059 to 0.32078, saving model to best_weights_v1.weights.h5\n\nEpoch 92: val_accuracy did not improve from 0.29750\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3216 - loss: 2.6445 - val_accuracy: 0.2945 - val_loss: 2.9631 - learning_rate: 5.0000e-05\nEpoch 93/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3229 - loss: 2.6396{'accuracy': 0.32161346077919006, 'loss': 2.6458661556243896, 'val_accuracy': 0.295199990272522, 'val_loss': 2.9713315963745117}\n\nEpoch 93: accuracy improved from 0.32078 to 0.32161, saving model to best_weights_v1.weights.h5\n\nEpoch 93: val_accuracy did not improve from 0.29750\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3229 - loss: 2.6396 - val_accuracy: 0.2952 - val_loss: 2.9713 - learning_rate: 5.0000e-05\nEpoch 94/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3220 - loss: 2.6431{'accuracy': 0.3218500018119812, 'loss': 2.6433768272399902, 'val_accuracy': 0.2939999997615814, 'val_loss': 2.963740587234497}\n\nEpoch 94: accuracy improved from 0.32161 to 0.32185, saving model to best_weights_v1.weights.h5\n\nEpoch 94: val_accuracy did not improve from 0.29750\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3220 - loss: 2.6431 - val_accuracy: 0.2940 - val_loss: 2.9637 - learning_rate: 5.0000e-05\nEpoch 95/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3230 - loss: 2.6371{'accuracy': 0.3226586580276489, 'loss': 2.640641212463379, 'val_accuracy': 0.2921000123023987, 'val_loss': 2.966991901397705}\n\nEpoch 95: accuracy improved from 0.32185 to 0.32266, saving model to best_weights_v1.weights.h5\n\nEpoch 95: val_accuracy did not improve from 0.29750\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3230 - loss: 2.6371 - val_accuracy: 0.2921 - val_loss: 2.9670 - learning_rate: 5.0000e-05\nEpoch 96/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3233 - loss: 2.6374{'accuracy': 0.3236701786518097, 'loss': 2.6359646320343018, 'val_accuracy': 0.2953999936580658, 'val_loss': 2.9584622383117676}\n\nEpoch 96: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\nEpoch 96: accuracy improved from 0.32266 to 0.32367, saving model to best_weights_v1.weights.h5\n\nEpoch 96: val_accuracy did not improve from 0.29750\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3233 - loss: 2.6374 - val_accuracy: 0.2954 - val_loss: 2.9585 - learning_rate: 5.0000e-05\nEpoch 97/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3288 - loss: 2.6107{'accuracy': 0.32855096459388733, 'loss': 2.611677885055542, 'val_accuracy': 0.2971999943256378, 'val_loss': 2.9528250694274902}\n\nEpoch 97: accuracy improved from 0.32367 to 0.32855, saving model to best_weights_v1.weights.h5\n\nEpoch 97: val_accuracy did not improve from 0.29750\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3288 - loss: 2.6107 - val_accuracy: 0.2972 - val_loss: 2.9528 - learning_rate: 2.5000e-05\nEpoch 98/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3290 - loss: 2.6066{'accuracy': 0.32928749918937683, 'loss': 2.6068294048309326, 'val_accuracy': 0.29589998722076416, 'val_loss': 2.9632508754730225}\n\nEpoch 98: accuracy improved from 0.32855 to 0.32929, saving model to best_weights_v1.weights.h5\n\nEpoch 98: val_accuracy did not improve from 0.29750\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3290 - loss: 2.6066 - val_accuracy: 0.2959 - val_loss: 2.9633 - learning_rate: 2.5000e-05\nEpoch 99/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3295 - loss: 2.6060{'accuracy': 0.32999518513679504, 'loss': 2.605250358581543, 'val_accuracy': 0.29660001397132874, 'val_loss': 2.9673633575439453}\n\nEpoch 99: accuracy improved from 0.32929 to 0.33000, saving model to best_weights_v1.weights.h5\n\nEpoch 99: val_accuracy did not improve from 0.29750\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3295 - loss: 2.6060 - val_accuracy: 0.2966 - val_loss: 2.9674 - learning_rate: 2.5000e-05\nEpoch 99: early stopping\nRestoring model weights from the end of the best epoch: 91.\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir logs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history[\"accuracy\"])\nplt.plot(history.history[\"val_accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir logs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = myModel2.predict(x_test).argmax(axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(predictions, columns=[\"Label\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.index.name = \"Id\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MODEL 3","metadata":{}},{"cell_type":"code","source":"rlrop = ReduceLROnPlateau(\n    monitor = \"val_accuracy\",\n    factor = 0.5,\n    patience = 5,\n    verbose = 1,\n    min_lr = 1e-7\n)\n\n\nrlrop2 = ReduceLROnPlateau(\n    monitor = \"accuracy\",\n    factor = 0.2,\n    patience = 5,\n    verbose = 1,\n    min_lr = 1e-6\n)\n\nes = EarlyStopping(\n    monitor = \"val_accuracy\",\n    patience = 8,\n    verbose = 1,\n    restore_best_weights = True\n)\n\nes2 = EarlyStopping(\n    monitor = \"accuracy\",\n    patience = 10,\n    verbose = 1,\n    restore_best_weights = True\n)\n\nmc2 = ModelCheckpoint(\n    \"best_weights_v1.weights.h5\",\n    monitor = \"accuracy\",\n    verbose = 1,\n    save_best_only = True,\n    save_weights_only = True,\n\n)\n\n\nmc = ModelCheckpoint(\n    \"best_weights_v2.weights.h5\",\n    monitor = \"val_accuracy\",\n    verbose = 1,\n    save_best_only = True,\n    save_weights_only = True,\n\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T01:01:06.316257Z","iopub.execute_input":"2024-10-29T01:01:06.316538Z","iopub.status.idle":"2024-10-29T01:01:06.324742Z","shell.execute_reply.started":"2024-10-29T01:01:06.316508Z","shell.execute_reply":"2024-10-29T01:01:06.323704Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"myModel.compile(\n    optimizer               = Adam(learning_rate=0.001),\n    #loss                    = {'fine_output': 'sparse_categorical_crossentropy', 'coarse_output': 'sparse_categorical_crossentropy'},\n    loss                    = {'fine_output': 'sparse_categorical_crossentropy'},\n    loss_weights            = None,\n    #metrics                 = {'fine_output': 'categorical_accuracy', 'coarse_output': 'categorical_accuracy'},\n    metrics                 = {'fine_output': 'accuracy'},\n    weighted_metrics        = None,\n    run_eagerly             = False,\n    steps_per_execution     = 1,\n    jit_compile             = \"auto\",\n    auto_scale_loss         = True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T23:22:38.916056Z","iopub.execute_input":"2024-10-28T23:22:38.916346Z","iopub.status.idle":"2024-10-28T23:22:38.934986Z","shell.execute_reply.started":"2024-10-28T23:22:38.916310Z","shell.execute_reply":"2024-10-28T23:22:38.934309Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"history3 = myModel.fit(\n    x                       = x_train_dup,\n    y                       = {'fine_output': y_train_fine_dup},\n    batch_size              = 512,\n    epochs                  = 100,\n    verbose                 = \"auto\",\n    callbacks               = [LambdaCallback(on_epoch_end=lambda epoch, logs: print(logs if logs is not None else \"No logs available\")),rlrop,es,mc2,mc],\n    validation_split        = 0.0,\n    validation_data         = (x_test_dup, {'fine_output': y_test_fine_dup}),\n    shuffle                 = True,\n    class_weight            = None,\n    sample_weight           = None,\n    initial_epoch           = 0,\n    steps_per_epoch         = None,\n    validation_steps        = None,\n    validation_batch_size   = None,\n    validation_freq         = 1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T23:23:41.474457Z","iopub.execute_input":"2024-10-28T23:23:41.475292Z","iopub.status.idle":"2024-10-28T23:41:02.861803Z","shell.execute_reply.started":"2024-10-28T23:23:41.475251Z","shell.execute_reply":"2024-10-28T23:41:02.861000Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1324 - loss: 3.6825{'accuracy': 0.13385385274887085, 'loss': 3.6747779846191406, 'val_accuracy': 0.16990000009536743, 'val_loss': 3.4628803730010986}\n\nEpoch 1: accuracy improved from 0.12224 to 0.13385, saving model to best_weights_v1.weights.h5\n\nEpoch 1: val_accuracy improved from 0.16080 to 0.16990, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1324 - loss: 3.6824 - val_accuracy: 0.1699 - val_loss: 3.4629 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m2026/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1379 - loss: 3.6436{'accuracy': 0.13913558423519135, 'loss': 3.6375510692596436, 'val_accuracy': 0.17399999499320984, 'val_loss': 3.439652442932129}\n\nEpoch 2: accuracy improved from 0.13385 to 0.13914, saving model to best_weights_v1.weights.h5\n\nEpoch 2: val_accuracy improved from 0.16990 to 0.17400, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1379 - loss: 3.6436 - val_accuracy: 0.1740 - val_loss: 3.4397 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m2024/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1436 - loss: 3.6119{'accuracy': 0.14422115683555603, 'loss': 3.6062653064727783, 'val_accuracy': 0.18219999969005585, 'val_loss': 3.407508611679077}\n\nEpoch 3: accuracy improved from 0.13914 to 0.14422, saving model to best_weights_v1.weights.h5\n\nEpoch 3: val_accuracy improved from 0.17400 to 0.18220, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1436 - loss: 3.6119 - val_accuracy: 0.1822 - val_loss: 3.4075 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1476 - loss: 3.5810{'accuracy': 0.1485355794429779, 'loss': 3.579122304916382, 'val_accuracy': 0.18619999289512634, 'val_loss': 3.3802549839019775}\n\nEpoch 4: accuracy improved from 0.14422 to 0.14854, saving model to best_weights_v1.weights.h5\n\nEpoch 4: val_accuracy improved from 0.18220 to 0.18620, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1477 - loss: 3.5810 - val_accuracy: 0.1862 - val_loss: 3.3803 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m2026/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1522 - loss: 3.5585{'accuracy': 0.15286345779895782, 'loss': 3.555083990097046, 'val_accuracy': 0.186599999666214, 'val_loss': 3.3812499046325684}\n\nEpoch 5: accuracy improved from 0.14854 to 0.15286, saving model to best_weights_v1.weights.h5\n\nEpoch 5: val_accuracy improved from 0.18620 to 0.18660, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1522 - loss: 3.5585 - val_accuracy: 0.1866 - val_loss: 3.3812 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1557 - loss: 3.5358{'accuracy': 0.15675480663776398, 'loss': 3.5336110591888428, 'val_accuracy': 0.19220000505447388, 'val_loss': 3.378115653991699}\n\nEpoch 6: accuracy improved from 0.15286 to 0.15675, saving model to best_weights_v1.weights.h5\n\nEpoch 6: val_accuracy improved from 0.18660 to 0.19220, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1557 - loss: 3.5358 - val_accuracy: 0.1922 - val_loss: 3.3781 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m2024/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1592 - loss: 3.5151{'accuracy': 0.1599336564540863, 'loss': 3.5145187377929688, 'val_accuracy': 0.19550000131130219, 'val_loss': 3.349217176437378}\n\nEpoch 7: accuracy improved from 0.15675 to 0.15993, saving model to best_weights_v1.weights.h5\n\nEpoch 7: val_accuracy improved from 0.19220 to 0.19550, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1592 - loss: 3.5151 - val_accuracy: 0.1955 - val_loss: 3.3492 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1628 - loss: 3.4971{'accuracy': 0.16305096447467804, 'loss': 3.4950859546661377, 'val_accuracy': 0.20479999482631683, 'val_loss': 3.3144214153289795}\n\nEpoch 8: accuracy improved from 0.15993 to 0.16305, saving model to best_weights_v1.weights.h5\n\nEpoch 8: val_accuracy improved from 0.19550 to 0.20480, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1628 - loss: 3.4971 - val_accuracy: 0.2048 - val_loss: 3.3144 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1657 - loss: 3.4807{'accuracy': 0.16615000367164612, 'loss': 3.477774143218994, 'val_accuracy': 0.20149999856948853, 'val_loss': 3.311202049255371}\n\nEpoch 9: accuracy improved from 0.16305 to 0.16615, saving model to best_weights_v1.weights.h5\n\nEpoch 9: val_accuracy did not improve from 0.20480\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1657 - loss: 3.4807 - val_accuracy: 0.2015 - val_loss: 3.3112 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1695 - loss: 3.4591{'accuracy': 0.1692182719707489, 'loss': 3.4596500396728516, 'val_accuracy': 0.20170000195503235, 'val_loss': 3.314440965652466}\n\nEpoch 10: accuracy improved from 0.16615 to 0.16922, saving model to best_weights_v1.weights.h5\n\nEpoch 10: val_accuracy did not improve from 0.20480\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1695 - loss: 3.4591 - val_accuracy: 0.2017 - val_loss: 3.3144 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1704 - loss: 3.4473{'accuracy': 0.17092308402061462, 'loss': 3.4448177814483643, 'val_accuracy': 0.20499999821186066, 'val_loss': 3.281695604324341}\n\nEpoch 11: accuracy improved from 0.16922 to 0.17092, saving model to best_weights_v1.weights.h5\n\nEpoch 11: val_accuracy improved from 0.20480 to 0.20500, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1704 - loss: 3.4473 - val_accuracy: 0.2050 - val_loss: 3.2817 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1745 - loss: 3.4271{'accuracy': 0.17474615573883057, 'loss': 3.4262609481811523, 'val_accuracy': 0.2093999981880188, 'val_loss': 3.280860185623169}\n\nEpoch 12: accuracy improved from 0.17092 to 0.17475, saving model to best_weights_v1.weights.h5\n\nEpoch 12: val_accuracy improved from 0.20500 to 0.20940, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1745 - loss: 3.4271 - val_accuracy: 0.2094 - val_loss: 3.2809 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m2023/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1770 - loss: 3.4127{'accuracy': 0.17749711871147156, 'loss': 3.4118564128875732, 'val_accuracy': 0.21539999544620514, 'val_loss': 3.2760331630706787}\n\nEpoch 13: accuracy improved from 0.17475 to 0.17750, saving model to best_weights_v1.weights.h5\n\nEpoch 13: val_accuracy improved from 0.20940 to 0.21540, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1770 - loss: 3.4127 - val_accuracy: 0.2154 - val_loss: 3.2760 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1794 - loss: 3.3974{'accuracy': 0.17941923439502716, 'loss': 3.3980259895324707, 'val_accuracy': 0.21080000698566437, 'val_loss': 3.2745323181152344}\n\nEpoch 14: accuracy improved from 0.17750 to 0.17942, saving model to best_weights_v1.weights.h5\n\nEpoch 14: val_accuracy did not improve from 0.21540\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1794 - loss: 3.3974 - val_accuracy: 0.2108 - val_loss: 3.2745 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1820 - loss: 3.3835{'accuracy': 0.18186058104038239, 'loss': 3.3846616744995117, 'val_accuracy': 0.2160000056028366, 'val_loss': 3.2558891773223877}\n\nEpoch 15: accuracy improved from 0.17942 to 0.18186, saving model to best_weights_v1.weights.h5\n\nEpoch 15: val_accuracy improved from 0.21540 to 0.21600, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1820 - loss: 3.3835 - val_accuracy: 0.2160 - val_loss: 3.2559 - learning_rate: 0.0010\nEpoch 16/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1841 - loss: 3.3701{'accuracy': 0.1837894171476364, 'loss': 3.372973680496216, 'val_accuracy': 0.21770000457763672, 'val_loss': 3.2453866004943848}\n\nEpoch 16: accuracy improved from 0.18186 to 0.18379, saving model to best_weights_v1.weights.h5\n\nEpoch 16: val_accuracy improved from 0.21600 to 0.21770, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1841 - loss: 3.3701 - val_accuracy: 0.2177 - val_loss: 3.2454 - learning_rate: 0.0010\nEpoch 17/100\n\u001b[1m2024/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1866 - loss: 3.3602{'accuracy': 0.18623076379299164, 'loss': 3.3605830669403076, 'val_accuracy': 0.21690000593662262, 'val_loss': 3.2344837188720703}\n\nEpoch 17: accuracy improved from 0.18379 to 0.18623, saving model to best_weights_v1.weights.h5\n\nEpoch 17: val_accuracy did not improve from 0.21770\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1866 - loss: 3.3602 - val_accuracy: 0.2169 - val_loss: 3.2345 - learning_rate: 0.0010\nEpoch 18/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1878 - loss: 3.3506{'accuracy': 0.18806250393390656, 'loss': 3.3503105640411377, 'val_accuracy': 0.22040000557899475, 'val_loss': 3.236487865447998}\n\nEpoch 18: accuracy improved from 0.18623 to 0.18806, saving model to best_weights_v1.weights.h5\n\nEpoch 18: val_accuracy improved from 0.21770 to 0.22040, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1878 - loss: 3.3506 - val_accuracy: 0.2204 - val_loss: 3.2365 - learning_rate: 0.0010\nEpoch 19/100\n\u001b[1m2026/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1897 - loss: 3.3374{'accuracy': 0.18911923468112946, 'loss': 3.3399322032928467, 'val_accuracy': 0.2222999930381775, 'val_loss': 3.2244021892547607}\n\nEpoch 19: accuracy improved from 0.18806 to 0.18912, saving model to best_weights_v1.weights.h5\n\nEpoch 19: val_accuracy improved from 0.22040 to 0.22230, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1897 - loss: 3.3374 - val_accuracy: 0.2223 - val_loss: 3.2244 - learning_rate: 0.0010\nEpoch 20/100\n\u001b[1m2026/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1918 - loss: 3.3273{'accuracy': 0.1916894167661667, 'loss': 3.3291244506835938, 'val_accuracy': 0.21860000491142273, 'val_loss': 3.2177209854125977}\n\nEpoch 20: accuracy improved from 0.18912 to 0.19169, saving model to best_weights_v1.weights.h5\n\nEpoch 20: val_accuracy did not improve from 0.22230\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1918 - loss: 3.3273 - val_accuracy: 0.2186 - val_loss: 3.2177 - learning_rate: 0.0010\nEpoch 21/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1936 - loss: 3.3195{'accuracy': 0.193520188331604, 'loss': 3.32060170173645, 'val_accuracy': 0.22689999639987946, 'val_loss': 3.2185218334198}\n\nEpoch 21: accuracy improved from 0.19169 to 0.19352, saving model to best_weights_v1.weights.h5\n\nEpoch 21: val_accuracy improved from 0.22230 to 0.22690, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1936 - loss: 3.3195 - val_accuracy: 0.2269 - val_loss: 3.2185 - learning_rate: 0.0010\nEpoch 22/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1951 - loss: 3.3115{'accuracy': 0.19503557682037354, 'loss': 3.3119542598724365, 'val_accuracy': 0.22540000081062317, 'val_loss': 3.2064995765686035}\n\nEpoch 22: accuracy improved from 0.19352 to 0.19504, saving model to best_weights_v1.weights.h5\n\nEpoch 22: val_accuracy did not improve from 0.22690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1951 - loss: 3.3115 - val_accuracy: 0.2254 - val_loss: 3.2065 - learning_rate: 0.0010\nEpoch 23/100\n\u001b[1m2023/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1967 - loss: 3.3023{'accuracy': 0.196144238114357, 'loss': 3.3051295280456543, 'val_accuracy': 0.2240000069141388, 'val_loss': 3.2183456420898438}\n\nEpoch 23: accuracy improved from 0.19504 to 0.19614, saving model to best_weights_v1.weights.h5\n\nEpoch 23: val_accuracy did not improve from 0.22690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1967 - loss: 3.3024 - val_accuracy: 0.2240 - val_loss: 3.2183 - learning_rate: 0.0010\nEpoch 24/100\n\u001b[1m2024/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1983 - loss: 3.2947{'accuracy': 0.1974557638168335, 'loss': 3.296527147293091, 'val_accuracy': 0.22020000219345093, 'val_loss': 3.223273754119873}\n\nEpoch 24: accuracy improved from 0.19614 to 0.19746, saving model to best_weights_v1.weights.h5\n\nEpoch 24: val_accuracy did not improve from 0.22690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1983 - loss: 3.2947 - val_accuracy: 0.2202 - val_loss: 3.2233 - learning_rate: 0.0010\nEpoch 25/100\n\u001b[1m2026/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1987 - loss: 3.2866{'accuracy': 0.1985769271850586, 'loss': 3.2894837856292725, 'val_accuracy': 0.2281000018119812, 'val_loss': 3.2030911445617676}\n\nEpoch 25: accuracy improved from 0.19746 to 0.19858, saving model to best_weights_v1.weights.h5\n\nEpoch 25: val_accuracy improved from 0.22690 to 0.22810, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1987 - loss: 3.2866 - val_accuracy: 0.2281 - val_loss: 3.2031 - learning_rate: 0.0010\nEpoch 26/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2012 - loss: 3.2802{'accuracy': 0.20048461854457855, 'loss': 3.281251907348633, 'val_accuracy': 0.22920000553131104, 'val_loss': 3.2000834941864014}\n\nEpoch 26: accuracy improved from 0.19858 to 0.20048, saving model to best_weights_v1.weights.h5\n\nEpoch 26: val_accuracy improved from 0.22810 to 0.22920, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2012 - loss: 3.2802 - val_accuracy: 0.2292 - val_loss: 3.2001 - learning_rate: 0.0010\nEpoch 27/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2025 - loss: 3.2672{'accuracy': 0.201266348361969, 'loss': 3.2747204303741455, 'val_accuracy': 0.2304999977350235, 'val_loss': 3.175079345703125}\n\nEpoch 27: accuracy improved from 0.20048 to 0.20127, saving model to best_weights_v1.weights.h5\n\nEpoch 27: val_accuracy improved from 0.22920 to 0.23050, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2025 - loss: 3.2672 - val_accuracy: 0.2305 - val_loss: 3.1751 - learning_rate: 0.0010\nEpoch 28/100\n\u001b[1m2025/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2036 - loss: 3.2671{'accuracy': 0.20288750529289246, 'loss': 3.268458127975464, 'val_accuracy': 0.23149999976158142, 'val_loss': 3.1928176879882812}\n\nEpoch 28: accuracy improved from 0.20127 to 0.20289, saving model to best_weights_v1.weights.h5\n\nEpoch 28: val_accuracy improved from 0.23050 to 0.23150, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2036 - loss: 3.2671 - val_accuracy: 0.2315 - val_loss: 3.1928 - learning_rate: 0.0010\nEpoch 29/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2044 - loss: 3.2605{'accuracy': 0.20439808070659637, 'loss': 3.2612767219543457, 'val_accuracy': 0.23160000145435333, 'val_loss': 3.1897852420806885}\n\nEpoch 29: accuracy improved from 0.20289 to 0.20440, saving model to best_weights_v1.weights.h5\n\nEpoch 29: val_accuracy improved from 0.23150 to 0.23160, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2044 - loss: 3.2605 - val_accuracy: 0.2316 - val_loss: 3.1898 - learning_rate: 0.0010\nEpoch 30/100\n\u001b[1m2024/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2047 - loss: 3.2536{'accuracy': 0.20521345734596252, 'loss': 3.2539563179016113, 'val_accuracy': 0.22949999570846558, 'val_loss': 3.183136463165283}\n\nEpoch 30: accuracy improved from 0.20440 to 0.20521, saving model to best_weights_v1.weights.h5\n\nEpoch 30: val_accuracy did not improve from 0.23160\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2047 - loss: 3.2536 - val_accuracy: 0.2295 - val_loss: 3.1831 - learning_rate: 0.0010\nEpoch 31/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2066 - loss: 3.2470{'accuracy': 0.2060692310333252, 'loss': 3.2484235763549805, 'val_accuracy': 0.2345000058412552, 'val_loss': 3.179046869277954}\n\nEpoch 31: accuracy improved from 0.20521 to 0.20607, saving model to best_weights_v1.weights.h5\n\nEpoch 31: val_accuracy improved from 0.23160 to 0.23450, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2066 - loss: 3.2470 - val_accuracy: 0.2345 - val_loss: 3.1790 - learning_rate: 0.0010\nEpoch 32/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2083 - loss: 3.2379{'accuracy': 0.20751634240150452, 'loss': 3.240966320037842, 'val_accuracy': 0.23260000348091125, 'val_loss': 3.177471160888672}\n\nEpoch 32: accuracy improved from 0.20607 to 0.20752, saving model to best_weights_v1.weights.h5\n\nEpoch 32: val_accuracy did not improve from 0.23450\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2083 - loss: 3.2379 - val_accuracy: 0.2326 - val_loss: 3.1775 - learning_rate: 0.0010\nEpoch 33/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2091 - loss: 3.2316{'accuracy': 0.2090528905391693, 'loss': 3.2348687648773193, 'val_accuracy': 0.23589999973773956, 'val_loss': 3.1554393768310547}\n\nEpoch 33: accuracy improved from 0.20752 to 0.20905, saving model to best_weights_v1.weights.h5\n\nEpoch 33: val_accuracy improved from 0.23450 to 0.23590, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2091 - loss: 3.2316 - val_accuracy: 0.2359 - val_loss: 3.1554 - learning_rate: 0.0010\nEpoch 34/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2096 - loss: 3.2263{'accuracy': 0.2093394249677658, 'loss': 3.229520797729492, 'val_accuracy': 0.23589999973773956, 'val_loss': 3.169358491897583}\n\nEpoch 34: accuracy improved from 0.20905 to 0.20934, saving model to best_weights_v1.weights.h5\n\nEpoch 34: val_accuracy did not improve from 0.23590\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2096 - loss: 3.2263 - val_accuracy: 0.2359 - val_loss: 3.1694 - learning_rate: 0.0010\nEpoch 35/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2107 - loss: 3.2242{'accuracy': 0.21059808135032654, 'loss': 3.2251906394958496, 'val_accuracy': 0.23720000684261322, 'val_loss': 3.1649835109710693}\n\nEpoch 35: accuracy improved from 0.20934 to 0.21060, saving model to best_weights_v1.weights.h5\n\nEpoch 35: val_accuracy improved from 0.23590 to 0.23720, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2107 - loss: 3.2242 - val_accuracy: 0.2372 - val_loss: 3.1650 - learning_rate: 0.0010\nEpoch 36/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2115 - loss: 3.2186{'accuracy': 0.21155384182929993, 'loss': 3.218578577041626, 'val_accuracy': 0.23479999601840973, 'val_loss': 3.1628239154815674}\n\nEpoch 36: accuracy improved from 0.21060 to 0.21155, saving model to best_weights_v1.weights.h5\n\nEpoch 36: val_accuracy did not improve from 0.23720\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2115 - loss: 3.2186 - val_accuracy: 0.2348 - val_loss: 3.1628 - learning_rate: 0.0010\nEpoch 37/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2127 - loss: 3.2138{'accuracy': 0.21274134516716003, 'loss': 3.214416027069092, 'val_accuracy': 0.24289999902248383, 'val_loss': 3.142672061920166}\n\nEpoch 37: accuracy improved from 0.21155 to 0.21274, saving model to best_weights_v1.weights.h5\n\nEpoch 37: val_accuracy improved from 0.23720 to 0.24290, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2127 - loss: 3.2138 - val_accuracy: 0.2429 - val_loss: 3.1427 - learning_rate: 0.0010\nEpoch 38/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2150 - loss: 3.2032{'accuracy': 0.21422307193279266, 'loss': 3.206573009490967, 'val_accuracy': 0.2361000031232834, 'val_loss': 3.1764421463012695}\n\nEpoch 38: accuracy improved from 0.21274 to 0.21422, saving model to best_weights_v1.weights.h5\n\nEpoch 38: val_accuracy did not improve from 0.24290\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2150 - loss: 3.2032 - val_accuracy: 0.2361 - val_loss: 3.1764 - learning_rate: 0.0010\nEpoch 39/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2160 - loss: 3.1969{'accuracy': 0.21485288441181183, 'loss': 3.2036731243133545, 'val_accuracy': 0.24079999327659607, 'val_loss': 3.171863317489624}\n\nEpoch 39: accuracy improved from 0.21422 to 0.21485, saving model to best_weights_v1.weights.h5\n\nEpoch 39: val_accuracy did not improve from 0.24290\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2160 - loss: 3.1969 - val_accuracy: 0.2408 - val_loss: 3.1719 - learning_rate: 0.0010\nEpoch 40/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2165 - loss: 3.1968{'accuracy': 0.2152259647846222, 'loss': 3.199073314666748, 'val_accuracy': 0.24230000376701355, 'val_loss': 3.162846565246582}\n\nEpoch 40: accuracy improved from 0.21485 to 0.21523, saving model to best_weights_v1.weights.h5\n\nEpoch 40: val_accuracy did not improve from 0.24290\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2165 - loss: 3.1968 - val_accuracy: 0.2423 - val_loss: 3.1628 - learning_rate: 0.0010\nEpoch 41/100\n\u001b[1m2025/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2168 - loss: 3.1912{'accuracy': 0.21630769968032837, 'loss': 3.1923999786376953, 'val_accuracy': 0.24160000681877136, 'val_loss': 3.1444764137268066}\n\nEpoch 41: accuracy improved from 0.21523 to 0.21631, saving model to best_weights_v1.weights.h5\n\nEpoch 41: val_accuracy did not improve from 0.24290\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2168 - loss: 3.1912 - val_accuracy: 0.2416 - val_loss: 3.1445 - learning_rate: 0.0010\nEpoch 42/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2188 - loss: 3.1835{'accuracy': 0.21798557043075562, 'loss': 3.186415433883667, 'val_accuracy': 0.24529999494552612, 'val_loss': 3.1475987434387207}\n\nEpoch 42: accuracy improved from 0.21631 to 0.21799, saving model to best_weights_v1.weights.h5\n\nEpoch 42: val_accuracy improved from 0.24290 to 0.24530, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2188 - loss: 3.1835 - val_accuracy: 0.2453 - val_loss: 3.1476 - learning_rate: 0.0010\nEpoch 43/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2180 - loss: 3.1816{'accuracy': 0.21818654239177704, 'loss': 3.1843979358673096, 'val_accuracy': 0.24289999902248383, 'val_loss': 3.1607422828674316}\n\nEpoch 43: accuracy improved from 0.21799 to 0.21819, saving model to best_weights_v1.weights.h5\n\nEpoch 43: val_accuracy did not improve from 0.24530\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2180 - loss: 3.1816 - val_accuracy: 0.2429 - val_loss: 3.1607 - learning_rate: 0.0010\nEpoch 44/100\n\u001b[1m2023/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2196 - loss: 3.1750{'accuracy': 0.21918557584285736, 'loss': 3.177856206893921, 'val_accuracy': 0.24230000376701355, 'val_loss': 3.145217180252075}\n\nEpoch 44: accuracy improved from 0.21819 to 0.21919, saving model to best_weights_v1.weights.h5\n\nEpoch 44: val_accuracy did not improve from 0.24530\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2196 - loss: 3.1750 - val_accuracy: 0.2423 - val_loss: 3.1452 - learning_rate: 0.0010\nEpoch 45/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2202 - loss: 3.1747{'accuracy': 0.21976730227470398, 'loss': 3.1758031845092773, 'val_accuracy': 0.24400000274181366, 'val_loss': 3.1523842811584473}\n\nEpoch 45: accuracy improved from 0.21919 to 0.21977, saving model to best_weights_v1.weights.h5\n\nEpoch 45: val_accuracy did not improve from 0.24530\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2202 - loss: 3.1747 - val_accuracy: 0.2440 - val_loss: 3.1524 - learning_rate: 0.0010\nEpoch 46/100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2212 - loss: 3.1659{'accuracy': 0.22084903717041016, 'loss': 3.1694719791412354, 'val_accuracy': 0.24160000681877136, 'val_loss': 3.14372181892395}\n\nEpoch 46: accuracy improved from 0.21977 to 0.22085, saving model to best_weights_v1.weights.h5\n\nEpoch 46: val_accuracy did not improve from 0.24530\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2212 - loss: 3.1659 - val_accuracy: 0.2416 - val_loss: 3.1437 - learning_rate: 0.0010\nEpoch 47/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2222 - loss: 3.1632{'accuracy': 0.2216951996088028, 'loss': 3.1659257411956787, 'val_accuracy': 0.24250000715255737, 'val_loss': 3.1591076850891113}\n\nEpoch 47: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 47: accuracy improved from 0.22085 to 0.22170, saving model to best_weights_v1.weights.h5\n\nEpoch 47: val_accuracy did not improve from 0.24530\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2222 - loss: 3.1633 - val_accuracy: 0.2425 - val_loss: 3.1591 - learning_rate: 0.0010\nEpoch 48/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2320 - loss: 3.1119{'accuracy': 0.23270288109779358, 'loss': 3.1047110557556152, 'val_accuracy': 0.2542000114917755, 'val_loss': 3.119722604751587}\n\nEpoch 48: accuracy improved from 0.22170 to 0.23270, saving model to best_weights_v1.weights.h5\n\nEpoch 48: val_accuracy improved from 0.24530 to 0.25420, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2320 - loss: 3.1119 - val_accuracy: 0.2542 - val_loss: 3.1197 - learning_rate: 5.0000e-04\nEpoch 49/100\n\u001b[1m2025/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2357 - loss: 3.0880{'accuracy': 0.2351461499929428, 'loss': 3.0893666744232178, 'val_accuracy': 0.25690001249313354, 'val_loss': 3.1117494106292725}\n\nEpoch 49: accuracy improved from 0.23270 to 0.23515, saving model to best_weights_v1.weights.h5\n\nEpoch 49: val_accuracy improved from 0.25420 to 0.25690, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2357 - loss: 3.0880 - val_accuracy: 0.2569 - val_loss: 3.1117 - learning_rate: 5.0000e-04\nEpoch 50/100\n\u001b[1m2026/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2365 - loss: 3.0810{'accuracy': 0.23608750104904175, 'loss': 3.0838427543640137, 'val_accuracy': 0.25519999861717224, 'val_loss': 3.11293888092041}\n\nEpoch 50: accuracy improved from 0.23515 to 0.23609, saving model to best_weights_v1.weights.h5\n\nEpoch 50: val_accuracy did not improve from 0.25690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2365 - loss: 3.0810 - val_accuracy: 0.2552 - val_loss: 3.1129 - learning_rate: 5.0000e-04\nEpoch 51/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2378 - loss: 3.0748{'accuracy': 0.2377384603023529, 'loss': 3.0766639709472656, 'val_accuracy': 0.25380000472068787, 'val_loss': 3.1207144260406494}\n\nEpoch 51: accuracy improved from 0.23609 to 0.23774, saving model to best_weights_v1.weights.h5\n\nEpoch 51: val_accuracy did not improve from 0.25690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2378 - loss: 3.0748 - val_accuracy: 0.2538 - val_loss: 3.1207 - learning_rate: 5.0000e-04\nEpoch 52/100\n\u001b[1m2024/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2397 - loss: 3.0684{'accuracy': 0.23880384862422943, 'loss': 3.071866035461426, 'val_accuracy': 0.25609999895095825, 'val_loss': 3.1199557781219482}\n\nEpoch 52: accuracy improved from 0.23774 to 0.23880, saving model to best_weights_v1.weights.h5\n\nEpoch 52: val_accuracy did not improve from 0.25690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2397 - loss: 3.0684 - val_accuracy: 0.2561 - val_loss: 3.1200 - learning_rate: 5.0000e-04\nEpoch 53/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2399 - loss: 3.0644{'accuracy': 0.23887500166893005, 'loss': 3.069429636001587, 'val_accuracy': 0.2506999969482422, 'val_loss': 3.110300302505493}\n\nEpoch 53: accuracy improved from 0.23880 to 0.23888, saving model to best_weights_v1.weights.h5\n\nEpoch 53: val_accuracy did not improve from 0.25690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2399 - loss: 3.0644 - val_accuracy: 0.2507 - val_loss: 3.1103 - learning_rate: 5.0000e-04\nEpoch 54/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2396 - loss: 3.0647{'accuracy': 0.23980769515037537, 'loss': 3.064436435699463, 'val_accuracy': 0.25519999861717224, 'val_loss': 3.1150996685028076}\n\nEpoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 54: accuracy improved from 0.23888 to 0.23981, saving model to best_weights_v1.weights.h5\n\nEpoch 54: val_accuracy did not improve from 0.25690\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2396 - loss: 3.0647 - val_accuracy: 0.2552 - val_loss: 3.1151 - learning_rate: 5.0000e-04\nEpoch 55/100\n\u001b[1m2026/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2455 - loss: 3.0308{'accuracy': 0.2455153912305832, 'loss': 3.0310661792755127, 'val_accuracy': 0.2572999894618988, 'val_loss': 3.0911917686462402}\n\nEpoch 55: accuracy improved from 0.23981 to 0.24552, saving model to best_weights_v1.weights.h5\n\nEpoch 55: val_accuracy improved from 0.25690 to 0.25730, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2455 - loss: 3.0308 - val_accuracy: 0.2573 - val_loss: 3.0912 - learning_rate: 2.5000e-04\nEpoch 56/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2478 - loss: 3.0230{'accuracy': 0.24719326198101044, 'loss': 3.0246293544769287, 'val_accuracy': 0.2578999996185303, 'val_loss': 3.0915427207946777}\n\nEpoch 56: accuracy improved from 0.24552 to 0.24719, saving model to best_weights_v1.weights.h5\n\nEpoch 56: val_accuracy improved from 0.25730 to 0.25790, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2478 - loss: 3.0230 - val_accuracy: 0.2579 - val_loss: 3.0915 - learning_rate: 2.5000e-04\nEpoch 57/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2483 - loss: 3.0196{'accuracy': 0.24815480411052704, 'loss': 3.018970012664795, 'val_accuracy': 0.25780001282691956, 'val_loss': 3.091738224029541}\n\nEpoch 57: accuracy improved from 0.24719 to 0.24815, saving model to best_weights_v1.weights.h5\n\nEpoch 57: val_accuracy did not improve from 0.25790\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2483 - loss: 3.0196 - val_accuracy: 0.2578 - val_loss: 3.0917 - learning_rate: 2.5000e-04\nEpoch 58/100\n\u001b[1m2025/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2490 - loss: 3.0158{'accuracy': 0.24877692759037018, 'loss': 3.0169341564178467, 'val_accuracy': 0.25780001282691956, 'val_loss': 3.0930707454681396}\n\nEpoch 58: accuracy improved from 0.24815 to 0.24878, saving model to best_weights_v1.weights.h5\n\nEpoch 58: val_accuracy did not improve from 0.25790\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2490 - loss: 3.0158 - val_accuracy: 0.2578 - val_loss: 3.0931 - learning_rate: 2.5000e-04\nEpoch 59/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2497 - loss: 3.0084{'accuracy': 0.24937692284584045, 'loss': 3.0134220123291016, 'val_accuracy': 0.2596000134944916, 'val_loss': 3.0929558277130127}\n\nEpoch 59: accuracy improved from 0.24878 to 0.24938, saving model to best_weights_v1.weights.h5\n\nEpoch 59: val_accuracy improved from 0.25790 to 0.25960, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2497 - loss: 3.0084 - val_accuracy: 0.2596 - val_loss: 3.0930 - learning_rate: 2.5000e-04\nEpoch 60/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2507 - loss: 3.0071{'accuracy': 0.2500047981739044, 'loss': 3.0102317333221436, 'val_accuracy': 0.2574999928474426, 'val_loss': 3.098883867263794}\n\nEpoch 60: accuracy improved from 0.24938 to 0.25000, saving model to best_weights_v1.weights.h5\n\nEpoch 60: val_accuracy did not improve from 0.25960\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2507 - loss: 3.0071 - val_accuracy: 0.2575 - val_loss: 3.0989 - learning_rate: 2.5000e-04\nEpoch 61/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2503 - loss: 3.0070{'accuracy': 0.25008270144462585, 'loss': 3.0098302364349365, 'val_accuracy': 0.2572000026702881, 'val_loss': 3.097986936569214}\n\nEpoch 61: accuracy improved from 0.25000 to 0.25008, saving model to best_weights_v1.weights.h5\n\nEpoch 61: val_accuracy did not improve from 0.25960\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2503 - loss: 3.0070 - val_accuracy: 0.2572 - val_loss: 3.0980 - learning_rate: 2.5000e-04\nEpoch 62/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2514 - loss: 3.0003{'accuracy': 0.2512115240097046, 'loss': 3.002845048904419, 'val_accuracy': 0.2597000002861023, 'val_loss': 3.0977814197540283}\n\nEpoch 62: accuracy improved from 0.25008 to 0.25121, saving model to best_weights_v1.weights.h5\n\nEpoch 62: val_accuracy improved from 0.25960 to 0.25970, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2514 - loss: 3.0003 - val_accuracy: 0.2597 - val_loss: 3.0978 - learning_rate: 2.5000e-04\nEpoch 63/100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2519 - loss: 2.9997{'accuracy': 0.2515327036380768, 'loss': 3.0024454593658447, 'val_accuracy': 0.2599000036716461, 'val_loss': 3.0972740650177}\n\nEpoch 63: accuracy improved from 0.25121 to 0.25153, saving model to best_weights_v1.weights.h5\n\nEpoch 63: val_accuracy improved from 0.25970 to 0.25990, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2519 - loss: 2.9997 - val_accuracy: 0.2599 - val_loss: 3.0973 - learning_rate: 2.5000e-04\nEpoch 64/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2520 - loss: 2.9990{'accuracy': 0.2518576979637146, 'loss': 3.0006635189056396, 'val_accuracy': 0.25540000200271606, 'val_loss': 3.095438241958618}\n\nEpoch 64: accuracy improved from 0.25153 to 0.25186, saving model to best_weights_v1.weights.h5\n\nEpoch 64: val_accuracy did not improve from 0.25990\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2520 - loss: 2.9990 - val_accuracy: 0.2554 - val_loss: 3.0954 - learning_rate: 2.5000e-04\nEpoch 65/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2525 - loss: 2.9988{'accuracy': 0.25183364748954773, 'loss': 2.999851703643799, 'val_accuracy': 0.2583000063896179, 'val_loss': 3.0897512435913086}\n\nEpoch 65: accuracy did not improve from 0.25186\n\nEpoch 65: val_accuracy did not improve from 0.25990\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2525 - loss: 2.9988 - val_accuracy: 0.2583 - val_loss: 3.0898 - learning_rate: 2.5000e-04\nEpoch 66/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2528 - loss: 2.9955{'accuracy': 0.2527278959751129, 'loss': 2.9961748123168945, 'val_accuracy': 0.2597000002861023, 'val_loss': 3.0906455516815186}\n\nEpoch 66: accuracy improved from 0.25186 to 0.25273, saving model to best_weights_v1.weights.h5\n\nEpoch 66: val_accuracy did not improve from 0.25990\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2528 - loss: 2.9955 - val_accuracy: 0.2597 - val_loss: 3.0906 - learning_rate: 2.5000e-04\nEpoch 67/100\n\u001b[1m2023/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2537 - loss: 2.9905{'accuracy': 0.25331634283065796, 'loss': 2.9929556846618652, 'val_accuracy': 0.2605000138282776, 'val_loss': 3.090466022491455}\n\nEpoch 67: accuracy improved from 0.25273 to 0.25332, saving model to best_weights_v1.weights.h5\n\nEpoch 67: val_accuracy improved from 0.25990 to 0.26050, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2537 - loss: 2.9906 - val_accuracy: 0.2605 - val_loss: 3.0905 - learning_rate: 2.5000e-04\nEpoch 68/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2529 - loss: 2.9920{'accuracy': 0.25318750739097595, 'loss': 2.9927358627319336, 'val_accuracy': 0.26030001044273376, 'val_loss': 3.086224317550659}\n\nEpoch 68: accuracy did not improve from 0.25332\n\nEpoch 68: val_accuracy did not improve from 0.26050\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2529 - loss: 2.9920 - val_accuracy: 0.2603 - val_loss: 3.0862 - learning_rate: 2.5000e-04\nEpoch 69/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2544 - loss: 2.9878{'accuracy': 0.2539125084877014, 'loss': 2.990382671356201, 'val_accuracy': 0.2614000141620636, 'val_loss': 3.0904860496520996}\n\nEpoch 69: accuracy improved from 0.25332 to 0.25391, saving model to best_weights_v1.weights.h5\n\nEpoch 69: val_accuracy improved from 0.26050 to 0.26140, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2544 - loss: 2.9878 - val_accuracy: 0.2614 - val_loss: 3.0905 - learning_rate: 2.5000e-04\nEpoch 70/100\n\u001b[1m2023/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2549 - loss: 2.9834{'accuracy': 0.254290372133255, 'loss': 2.9876949787139893, 'val_accuracy': 0.2567000091075897, 'val_loss': 3.086625099182129}\n\nEpoch 70: accuracy improved from 0.25391 to 0.25429, saving model to best_weights_v1.weights.h5\n\nEpoch 70: val_accuracy did not improve from 0.26140\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2549 - loss: 2.9834 - val_accuracy: 0.2567 - val_loss: 3.0866 - learning_rate: 2.5000e-04\nEpoch 71/100\n\u001b[1m2026/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2553 - loss: 2.9852{'accuracy': 0.2544230818748474, 'loss': 2.986359119415283, 'val_accuracy': 0.2581999897956848, 'val_loss': 3.0899360179901123}\n\nEpoch 71: accuracy improved from 0.25429 to 0.25442, saving model to best_weights_v1.weights.h5\n\nEpoch 71: val_accuracy did not improve from 0.26140\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2553 - loss: 2.9852 - val_accuracy: 0.2582 - val_loss: 3.0899 - learning_rate: 2.5000e-04\nEpoch 72/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2551 - loss: 2.9800{'accuracy': 0.25497883558273315, 'loss': 2.983142137527466, 'val_accuracy': 0.26030001044273376, 'val_loss': 3.0827863216400146}\n\nEpoch 72: accuracy improved from 0.25442 to 0.25498, saving model to best_weights_v1.weights.h5\n\nEpoch 72: val_accuracy did not improve from 0.26140\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2551 - loss: 2.9801 - val_accuracy: 0.2603 - val_loss: 3.0828 - learning_rate: 2.5000e-04\nEpoch 73/100\n\u001b[1m2026/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2551 - loss: 2.9825{'accuracy': 0.2550269365310669, 'loss': 2.9822921752929688, 'val_accuracy': 0.2599000036716461, 'val_loss': 3.096632242202759}\n\nEpoch 73: accuracy improved from 0.25498 to 0.25503, saving model to best_weights_v1.weights.h5\n\nEpoch 73: val_accuracy did not improve from 0.26140\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2551 - loss: 2.9825 - val_accuracy: 0.2599 - val_loss: 3.0966 - learning_rate: 2.5000e-04\nEpoch 74/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2553 - loss: 2.9774{'accuracy': 0.25536635518074036, 'loss': 2.980684518814087, 'val_accuracy': 0.2574999928474426, 'val_loss': 3.0977895259857178}\n\nEpoch 74: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 74: accuracy improved from 0.25503 to 0.25537, saving model to best_weights_v1.weights.h5\n\nEpoch 74: val_accuracy did not improve from 0.26140\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2553 - loss: 2.9774 - val_accuracy: 0.2575 - val_loss: 3.0978 - learning_rate: 2.5000e-04\nEpoch 75/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2582 - loss: 2.9646{'accuracy': 0.2584461569786072, 'loss': 2.9622325897216797, 'val_accuracy': 0.2619999945163727, 'val_loss': 3.0820963382720947}\n\nEpoch 75: accuracy improved from 0.25537 to 0.25845, saving model to best_weights_v1.weights.h5\n\nEpoch 75: val_accuracy improved from 0.26140 to 0.26200, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2582 - loss: 2.9646 - val_accuracy: 0.2620 - val_loss: 3.0821 - learning_rate: 1.2500e-04\nEpoch 76/100\n\u001b[1m2025/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2587 - loss: 2.9606{'accuracy': 0.2594461441040039, 'loss': 2.958298921585083, 'val_accuracy': 0.2587999999523163, 'val_loss': 3.081273078918457}\n\nEpoch 76: accuracy improved from 0.25845 to 0.25945, saving model to best_weights_v1.weights.h5\n\nEpoch 76: val_accuracy did not improve from 0.26200\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2587 - loss: 2.9606 - val_accuracy: 0.2588 - val_loss: 3.0813 - learning_rate: 1.2500e-04\nEpoch 77/100\n\u001b[1m2028/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2605 - loss: 2.9532{'accuracy': 0.2602144181728363, 'loss': 2.9562861919403076, 'val_accuracy': 0.26019999384880066, 'val_loss': 3.0848445892333984}\n\nEpoch 77: accuracy improved from 0.25945 to 0.26021, saving model to best_weights_v1.weights.h5\n\nEpoch 77: val_accuracy did not improve from 0.26200\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2605 - loss: 2.9532 - val_accuracy: 0.2602 - val_loss: 3.0848 - learning_rate: 1.2500e-04\nEpoch 78/100\n\u001b[1m2025/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2602 - loss: 2.9528{'accuracy': 0.25974902510643005, 'loss': 2.9547059535980225, 'val_accuracy': 0.2612000107765198, 'val_loss': 3.085946798324585}\n\nEpoch 78: accuracy did not improve from 0.26021\n\nEpoch 78: val_accuracy did not improve from 0.26200\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2602 - loss: 2.9528 - val_accuracy: 0.2612 - val_loss: 3.0859 - learning_rate: 1.2500e-04\nEpoch 79/100\n\u001b[1m2026/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2604 - loss: 2.9533{'accuracy': 0.2597105801105499, 'loss': 2.953913927078247, 'val_accuracy': 0.2590000033378601, 'val_loss': 3.0890681743621826}\n\nEpoch 79: accuracy did not improve from 0.26021\n\nEpoch 79: val_accuracy did not improve from 0.26200\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2604 - loss: 2.9533 - val_accuracy: 0.2590 - val_loss: 3.0891 - learning_rate: 1.2500e-04\nEpoch 80/100\n\u001b[1m2023/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2601 - loss: 2.9508{'accuracy': 0.2605576813220978, 'loss': 2.9524245262145996, 'val_accuracy': 0.26269999146461487, 'val_loss': 3.0867886543273926}\n\nEpoch 80: accuracy improved from 0.26021 to 0.26056, saving model to best_weights_v1.weights.h5\n\nEpoch 80: val_accuracy improved from 0.26200 to 0.26270, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2601 - loss: 2.9508 - val_accuracy: 0.2627 - val_loss: 3.0868 - learning_rate: 1.2500e-04\nEpoch 81/100\n\u001b[1m2025/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2617 - loss: 2.9501{'accuracy': 0.26086828112602234, 'loss': 2.9517714977264404, 'val_accuracy': 0.2612000107765198, 'val_loss': 3.0836310386657715}\n\nEpoch 81: accuracy improved from 0.26056 to 0.26087, saving model to best_weights_v1.weights.h5\n\nEpoch 81: val_accuracy did not improve from 0.26270\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2617 - loss: 2.9501 - val_accuracy: 0.2612 - val_loss: 3.0836 - learning_rate: 1.2500e-04\nEpoch 82/100\n\u001b[1m2025/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2612 - loss: 2.9474{'accuracy': 0.26115190982818604, 'loss': 2.9501140117645264, 'val_accuracy': 0.25949999690055847, 'val_loss': 3.0877864360809326}\n\nEpoch 82: accuracy improved from 0.26087 to 0.26115, saving model to best_weights_v1.weights.h5\n\nEpoch 82: val_accuracy did not improve from 0.26270\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2612 - loss: 2.9474 - val_accuracy: 0.2595 - val_loss: 3.0878 - learning_rate: 1.2500e-04\nEpoch 83/100\n\u001b[1m2029/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2622 - loss: 2.9461{'accuracy': 0.26138269901275635, 'loss': 2.9481494426727295, 'val_accuracy': 0.2621000111103058, 'val_loss': 3.0843822956085205}\n\nEpoch 83: accuracy improved from 0.26115 to 0.26138, saving model to best_weights_v1.weights.h5\n\nEpoch 83: val_accuracy did not improve from 0.26270\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2622 - loss: 2.9461 - val_accuracy: 0.2621 - val_loss: 3.0844 - learning_rate: 1.2500e-04\nEpoch 84/100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2628 - loss: 2.9428{'accuracy': 0.2615971267223358, 'loss': 2.947479248046875, 'val_accuracy': 0.26429998874664307, 'val_loss': 3.083523988723755}\n\nEpoch 84: accuracy improved from 0.26138 to 0.26160, saving model to best_weights_v1.weights.h5\n\nEpoch 84: val_accuracy improved from 0.26270 to 0.26430, saving model to best_weights_v2.weights.h5\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2628 - loss: 2.9428 - val_accuracy: 0.2643 - val_loss: 3.0835 - learning_rate: 1.2500e-04\nEpoch 85/100\n\u001b[1m2030/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2620 - loss: 2.9444{'accuracy': 0.2615942358970642, 'loss': 2.945917844772339, 'val_accuracy': 0.25999999046325684, 'val_loss': 3.0825095176696777}\n\nEpoch 85: accuracy did not improve from 0.26160\n\nEpoch 85: val_accuracy did not improve from 0.26430\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2620 - loss: 2.9444 - val_accuracy: 0.2600 - val_loss: 3.0825 - learning_rate: 1.2500e-04\nEpoch 86/100\n\u001b[1m2023/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2625 - loss: 2.9428{'accuracy': 0.26175960898399353, 'loss': 2.9451305866241455, 'val_accuracy': 0.26159998774528503, 'val_loss': 3.0852115154266357}\n\nEpoch 86: accuracy improved from 0.26160 to 0.26176, saving model to best_weights_v1.weights.h5\n\nEpoch 86: val_accuracy did not improve from 0.26430\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2625 - loss: 2.9428 - val_accuracy: 0.2616 - val_loss: 3.0852 - learning_rate: 1.2500e-04\nEpoch 87/100\n\u001b[1m2023/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2625 - loss: 2.9419{'accuracy': 0.26205191016197205, 'loss': 2.9429030418395996, 'val_accuracy': 0.2632000148296356, 'val_loss': 3.086405038833618}\n\nEpoch 87: accuracy improved from 0.26176 to 0.26205, saving model to best_weights_v1.weights.h5\n\nEpoch 87: val_accuracy did not improve from 0.26430\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2625 - loss: 2.9419 - val_accuracy: 0.2632 - val_loss: 3.0864 - learning_rate: 1.2500e-04\nEpoch 88/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2623 - loss: 2.9428{'accuracy': 0.26246923208236694, 'loss': 2.94309663772583, 'val_accuracy': 0.2603999972343445, 'val_loss': 3.0848336219787598}\n\nEpoch 88: accuracy improved from 0.26205 to 0.26247, saving model to best_weights_v1.weights.h5\n\nEpoch 88: val_accuracy did not improve from 0.26430\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2623 - loss: 2.9428 - val_accuracy: 0.2604 - val_loss: 3.0848 - learning_rate: 1.2500e-04\nEpoch 89/100\n\u001b[1m2031/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2629 - loss: 2.9403{'accuracy': 0.2623326778411865, 'loss': 2.942744255065918, 'val_accuracy': 0.26179999113082886, 'val_loss': 3.0857925415039062}\n\nEpoch 89: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 89: accuracy did not improve from 0.26247\n\nEpoch 89: val_accuracy did not improve from 0.26430\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2629 - loss: 2.9403 - val_accuracy: 0.2618 - val_loss: 3.0858 - learning_rate: 1.2500e-04\nEpoch 90/100\n\u001b[1m2023/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2640 - loss: 2.9334{'accuracy': 0.26416730880737305, 'loss': 2.9326562881469727, 'val_accuracy': 0.26170000433921814, 'val_loss': 3.0808629989624023}\n\nEpoch 90: accuracy improved from 0.26247 to 0.26417, saving model to best_weights_v1.weights.h5\n\nEpoch 90: val_accuracy did not improve from 0.26430\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2640 - loss: 2.9334 - val_accuracy: 0.2617 - val_loss: 3.0809 - learning_rate: 6.2500e-05\nEpoch 91/100\n\u001b[1m2027/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2637 - loss: 2.9297{'accuracy': 0.26401057839393616, 'loss': 2.93082332611084, 'val_accuracy': 0.2621000111103058, 'val_loss': 3.0849430561065674}\n\nEpoch 91: accuracy did not improve from 0.26417\n\nEpoch 91: val_accuracy did not improve from 0.26430\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2637 - loss: 2.9297 - val_accuracy: 0.2621 - val_loss: 3.0849 - learning_rate: 6.2500e-05\nEpoch 92/100\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2650 - loss: 2.9301{'accuracy': 0.26484519243240356, 'loss': 2.929786205291748, 'val_accuracy': 0.2637999951839447, 'val_loss': 3.0785632133483887}\n\nEpoch 92: accuracy improved from 0.26417 to 0.26485, saving model to best_weights_v1.weights.h5\n\nEpoch 92: val_accuracy did not improve from 0.26430\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2650 - loss: 2.9301 - val_accuracy: 0.2638 - val_loss: 3.0786 - learning_rate: 6.2500e-05\nEpoch 92: early stopping\nRestoring model weights from the end of the best epoch: 84.\n","output_type":"stream"}]}]}