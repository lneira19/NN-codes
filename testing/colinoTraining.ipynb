{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84511,"databundleVersionId":9468663,"sourceType":"competition"},{"sourceId":9731527,"sourceType":"datasetVersion","datasetId":5955397}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Librerías generales\n\nimport numpy as np\nimport os\nimport pickle\nimport matplotlib.pyplot as plt","metadata":{"id":"utceBhWGgYlM","executionInfo":{"status":"ok","timestamp":1729991889260,"user_tz":180,"elapsed":2,"user":{"displayName":"LUCAS ORBE","userId":"03038966733029419882"}},"execution":{"iopub.status.busy":"2024-10-28T17:31:04.454819Z","iopub.execute_input":"2024-10-28T17:31:04.455267Z","iopub.status.idle":"2024-10-28T17:31:04.460266Z","shell.execute_reply.started":"2024-10-28T17:31:04.455220Z","shell.execute_reply":"2024-10-28T17:31:04.459163Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Lectura de datos","metadata":{"id":"7Pz7thRjgYlN"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pickle\n\n# Define la carpeta de datos (ajusta esto según el nombre que reciban los datos en Kaggle)\ndata_folder_name = '../input/dataselected'  \n\n# Definir una función para obtener los nombres de archivos en una carpeta\ndef getFileNames(folder_name):\n    file_names = os.listdir(folder_name)\n    return file_names\n\nprint(getFileNames(data_folder_name))\n\n# Lectura de archivos '.npy'\nx_test = np.load(f'{data_folder_name}/x_sub_val.npy')\nx_train = np.load(f'{data_folder_name}/x_sub_train_aug.npy')\n\ny_train_coarse = np.load(f'{data_folder_name}/y_sub_train_aug_1.npy')\ny_train_fine = np.load(f'{data_folder_name}/y_sub_train_aug_0.npy')\n\ny_test_coarse = np.load(f'{data_folder_name}/y_sub_val_1.npy')\ny_test_fine = np.load(f'{data_folder_name}/y_sub_val_0.npy')\n\n# Lectura de archivos '.pck'\nwith open('/kaggle/input/dl-itba-cifar-100-2024-q-1/coarse_label_names.pck', \"rb\") as f:\n    coarse_label_names = pickle.load(f)\n\nwith open('/kaggle/input/dl-itba-cifar-100-2024-q-1/fine_label_names.pck', \"rb\") as f:\n    fine_label_names = pickle.load(f)\n\n# Información de las dimensiones de los datos\nprint('Dimensiones de los datos:')\nprint(x_test.shape)\nprint(x_train.shape)\nprint(y_train_coarse.shape)\nprint(y_train_fine.shape)\n\nprint('Cantidad de clases:')\nprint(np.shape(coarse_label_names))\nprint(np.shape(fine_label_names))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a5iVfJM3gYlO","executionInfo":{"status":"ok","timestamp":1729991890061,"user_tz":180,"elapsed":2,"user":{"displayName":"LUCAS ORBE","userId":"03038966733029419882"}},"outputId":"6b0a579c-1893-41fe-e13d-f0edab11b5f8","execution":{"iopub.status.busy":"2024-10-28T17:31:04.461706Z","iopub.execute_input":"2024-10-28T17:31:04.462083Z","iopub.status.idle":"2024-10-28T17:31:05.633759Z","shell.execute_reply.started":"2024-10-28T17:31:04.462040Z","shell.execute_reply":"2024-10-28T17:31:05.632753Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['x_sub_val.npy', 'y_sub_train_aug_0.npy', 'y_sub_train_aug_1.npy', 'y_sub_val_1.npy', 'x_sub_train_aug.npy', 'y_sub_val_0.npy']\nDimensiones de los datos:\n(10000, 32, 32, 3)\n(1040000, 32, 32, 3)\n(1040000,)\n(1040000,)\nCantidad de clases:\n(20,)\n(100,)\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.layers import Input, Dense, Dropout, Flatten, LayerNormalization,BatchNormalization, Conv2D, MaxPooling2D\nfrom keras.models import Model\nfrom keras.regularizers import l2","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:31:17.445034Z","iopub.execute_input":"2024-10-28T17:31:17.445770Z","iopub.status.idle":"2024-10-28T17:31:17.453367Z","shell.execute_reply.started":"2024-10-28T17:31:17.445718Z","shell.execute_reply":"2024-10-28T17:31:17.452475Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### MODELO 1","metadata":{}},{"cell_type":"code","source":"#OTRA ESTRUCTURA\n# Entrada y normalización\ninput_layer = Input(shape=(32, 32, 3), name=\"matrix_input\")\n\n# Estructura de la red\nx = BatchNormalization(axis=-1, name=\"normalization_layer\")(input_layer)\nflatten_layer = Flatten(name=\"flattened_input\")(x)\n\n# Ajustes de las capas ocultas y Dropout\ndense_1024 = Dense(1024, activation='relu', name=\"dense_1024\")(flatten_layer)\ndropout_1024 = Dropout(0.3)(dense_1024)\ndense_512 = Dense(512, activation='relu', name=\"dense_512\")(dropout_1024)\ndropout_512 = Dropout(0.2)(dense_512)\ndense_256 = Dense(256, activation='relu', name=\"dense_256\")(dropout_512)\ndropout_256 = Dropout(0.2)(dense_256)\ndense_128 = Dense(128, activation='relu', name=\"dense_128\")(dropout_256)\ndense_64 = Dense(64, activation='relu', name=\"dense_64\")(dense_128)\n\n# Salidas\nfine_output = Dense(100, activation='softmax', name='fine_output')(dense_64)\n\n# Fine-grain prediction branch (100 classes)\nfine_output = Dense(100,\n                           activation='softmax',\n                           name='fine_output')(dense_64)\n\n# Coarse-grain prediction branch (20 classes)\ncoarse_output = Dense(20,\n                             activation='softmax',\n                             name='coarse_output')(dropout_512)\n\n# Defino el modelo con dos salidas\nmyModel = Model(\n    inputs                  = input_layer,\n    #outputs                 = [fine_output, coarse_output]\n    outputs                 = [fine_output]\n)\n\"\"\"myModel2 = Model(\n    inputs                  = input_layer,\n    outputs                 = [coarse_output]\n)\"\"\"\n\n# Print model summary\nmyModel.summary()\n\n#myModel2.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:31:17.454484Z","iopub.execute_input":"2024-10-28T17:31:17.454817Z","iopub.status.idle":"2024-10-28T17:31:18.363906Z","shell.execute_reply.started":"2024-10-28T17:31:17.454782Z","shell.execute_reply":"2024-10-28T17:31:18.362892Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ matrix_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ normalization_layer             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │            \u001b[38;5;34m12\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flattened_input (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1024 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m3,146,752\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_512 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_256 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_128 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m6,500\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ matrix_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ normalization_layer             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flattened_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1024 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,146,752</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_512 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_256 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,850,544\u001b[0m (14.69 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,544</span> (14.69 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,850,538\u001b[0m (14.69 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,538</span> (14.69 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Shuffle de los datos\nindexes_train   = np.arange(len(x_train))\nindexes_test    = np.arange(len(x_test))\n\nnp.random.shuffle(indexes_train)\nnp.random.shuffle(indexes_test)\n\n# Shuffle de datos de train\n\nx_train_dup         = x_train[indexes_train]\ny_train_coarse_dup  = y_train_coarse[indexes_train]\ny_train_fine_dup    = y_train_fine[indexes_train]\n\n# Shuffle de datos de test\nx_test_dup         = x_test[indexes_test]\ny_test_coarse_dup  = y_test_coarse[indexes_test]\ny_test_fine_dup    = y_test_fine[indexes_test]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:31:18.365242Z","iopub.execute_input":"2024-10-28T17:31:18.365558Z","iopub.status.idle":"2024-10-28T17:31:19.466179Z","shell.execute_reply.started":"2024-10-28T17:31:18.365524Z","shell.execute_reply":"2024-10-28T17:31:19.465194Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## CALLBACKS\n","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard, LambdaCallback\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:31:19.467707Z","iopub.execute_input":"2024-10-28T17:31:19.468081Z","iopub.status.idle":"2024-10-28T17:31:19.540716Z","shell.execute_reply.started":"2024-10-28T17:31:19.468044Z","shell.execute_reply":"2024-10-28T17:31:19.539779Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Learning rate decay\ninitial_learning_rate = 1e-4\ndecay_steps = 4063  # número de pasos ajustado al dataset, podría ser un número mayor si el learning rate baja muy rápido\ndecay_rate = 0.96   # una tasa de decay ligeramente menor para un ajuste más gradual\n\nlr_schedule = ExponentialDecay(\n    initial_learning_rate=initial_learning_rate,\n    decay_steps=decay_steps,\n    decay_rate=decay_rate,\n    staircase=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:31:19.542676Z","iopub.execute_input":"2024-10-28T17:31:19.543116Z","iopub.status.idle":"2024-10-28T17:31:19.548782Z","shell.execute_reply.started":"2024-10-28T17:31:19.543067Z","shell.execute_reply":"2024-10-28T17:31:19.547688Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\n\nrlrop = ReduceLROnPlateau(\n    monitor = \"val_accuracy\",\n    factor = 0.2,\n    patience = 5,\n    verbose = 1,\n    min_lr = 1e-6\n)\n\n\nrlrop2 = ReduceLROnPlateau(\n    monitor = \"accuracy\",\n    factor = 0.2,\n    patience = 5,\n    verbose = 1,\n    min_lr = 1e-6\n)\n\nes = EarlyStopping(\n    monitor = \"val_accuracy\",\n    patience = 8,\n    verbose = 1,\n    restore_best_weights = True\n)\n\nes2 = EarlyStopping(\n    monitor = \"accuracy\",\n    patience = 10,\n    verbose = 1,\n    restore_best_weights = True\n)\n\nmc2 = ModelCheckpoint(\n    \"best_weights_v1.weights.h5\",\n    monitor = \"accuracy\",\n    verbose = 1,\n    save_best_only = True,\n    save_weights_only = True,\n\n)\n\n\nmc = ModelCheckpoint(\n    \"best_weights_v2.weights.h5\",\n    monitor = \"val_accuracy\",\n    verbose = 1,\n    save_best_only = True,\n    save_weights_only = True,\n\n)\n\n\n\ntb = TensorBoard(\n    log_dir = \"logs\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:31:19.551800Z","iopub.execute_input":"2024-10-28T17:31:19.552253Z","iopub.status.idle":"2024-10-28T17:31:19.561141Z","shell.execute_reply.started":"2024-10-28T17:31:19.552218Z","shell.execute_reply":"2024-10-28T17:31:19.559899Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### MODELO 1 COMPILE Y FIT","metadata":{}},{"cell_type":"code","source":"myModel.compile(\n    optimizer               = Adam(learning_rate=initial_learning_rate),\n    #loss                    = {'fine_output': 'sparse_categorical_crossentropy', 'coarse_output': 'sparse_categorical_crossentropy'},\n    loss                    = {'fine_output': 'sparse_categorical_crossentropy'},\n    loss_weights            = None,\n    #metrics                 = {'fine_output': 'categorical_accuracy', 'coarse_output': 'categorical_accuracy'},\n    metrics                 = {'fine_output': 'accuracy'},\n    weighted_metrics        = None,\n    run_eagerly             = False,\n    steps_per_execution     = 1,\n    jit_compile             = \"auto\",\n    auto_scale_loss         = True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:31:19.562391Z","iopub.execute_input":"2024-10-28T17:31:19.562742Z","iopub.status.idle":"2024-10-28T17:31:19.581026Z","shell.execute_reply.started":"2024-10-28T17:31:19.562707Z","shell.execute_reply":"2024-10-28T17:31:19.579880Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#FIT PRUEBA\nhistory = myModel.fit(\n    x                       = x_train_dup,\n    y                       = {'fine_output': y_train_fine_dup},\n    batch_size              = 256,\n    epochs                  = 50,\n    verbose                 = \"auto\",\n    callbacks               = [LambdaCallback(on_epoch_end=lambda epoch, logs: print(logs if logs is not None else \"No logs available\")),rlrop,es,mc2,mc],\n    validation_split        = 0.0,\n    validation_data         = (x_test_dup, {'fine_output': y_test_fine_dup}),\n    shuffle                 = True,\n    class_weight            = None,\n    sample_weight           = None,\n    initial_epoch           = 0,\n    steps_per_epoch         = None,\n    validation_steps        = None,\n    validation_batch_size   = None,\n    validation_freq         = 1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:31:19.582153Z","iopub.execute_input":"2024-10-28T17:31:19.582436Z","iopub.status.idle":"2024-10-28T17:45:53.775007Z","shell.execute_reply.started":"2024-10-28T17:31:19.582404Z","shell.execute_reply":"2024-10-28T17:45:53.774033Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730136689.126677     100 service.cc:145] XLA service 0x7eb74c004f20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730136689.126722     100 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730136689.126726     100 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  27/4063\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 6ms/step - accuracy: 0.0094 - loss: 4.6858  ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730136695.934316     100 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_slice_fusion_1', 16 bytes spill stores, 16 bytes spill loads\n\nI0000 00:00:1730136695.943977     100 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0455 - loss: 4.3340","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1730136718.421589      99 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_slice_fusion_1', 16 bytes spill stores, 16 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"{'accuracy': 0.06500384956598282, 'loss': 4.1670331954956055, 'val_accuracy': 0.12349999696016312, 'val_loss': 3.7529399394989014}\n\nEpoch 1: accuracy improved from -inf to 0.06500, saving model to best_weights_v1.weights.h5\n\nEpoch 1: val_accuracy improved from -inf to 0.12350, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - accuracy: 0.0455 - loss: 4.3340 - val_accuracy: 0.1235 - val_loss: 3.7529 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m4059/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0949 - loss: 3.9363{'accuracy': 0.099704809486866, 'loss': 3.904357433319092, 'val_accuracy': 0.14730000495910645, 'val_loss': 3.613696575164795}\n\nEpoch 2: accuracy improved from 0.06500 to 0.09970, saving model to best_weights_v1.weights.h5\n\nEpoch 2: val_accuracy improved from 0.12350 to 0.14730, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.0949 - loss: 3.9363 - val_accuracy: 0.1473 - val_loss: 3.6137 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1112 - loss: 3.8234{'accuracy': 0.11501538753509521, 'loss': 3.804177761077881, 'val_accuracy': 0.1598999947309494, 'val_loss': 3.5081534385681152}\n\nEpoch 3: accuracy improved from 0.09970 to 0.11502, saving model to best_weights_v1.weights.h5\n\nEpoch 3: val_accuracy improved from 0.14730 to 0.15990, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1112 - loss: 3.8234 - val_accuracy: 0.1599 - val_loss: 3.5082 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m4053/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1238 - loss: 3.7480{'accuracy': 0.12607210874557495, 'loss': 3.735029935836792, 'val_accuracy': 0.17159999907016754, 'val_loss': 3.4579663276672363}\n\nEpoch 4: accuracy improved from 0.11502 to 0.12607, saving model to best_weights_v1.weights.h5\n\nEpoch 4: val_accuracy improved from 0.15990 to 0.17160, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1238 - loss: 3.7480 - val_accuracy: 0.1716 - val_loss: 3.4580 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m4056/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1336 - loss: 3.6894{'accuracy': 0.13523750007152557, 'loss': 3.6793861389160156, 'val_accuracy': 0.18289999663829803, 'val_loss': 3.4041695594787598}\n\nEpoch 5: accuracy improved from 0.12607 to 0.13524, saving model to best_weights_v1.weights.h5\n\nEpoch 5: val_accuracy improved from 0.17160 to 0.18290, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1336 - loss: 3.6894 - val_accuracy: 0.1829 - val_loss: 3.4042 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m4054/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1406 - loss: 3.6410{'accuracy': 0.14214423298835754, 'loss': 3.632213592529297, 'val_accuracy': 0.19009999930858612, 'val_loss': 3.3675625324249268}\n\nEpoch 6: accuracy improved from 0.13524 to 0.14214, saving model to best_weights_v1.weights.h5\n\nEpoch 6: val_accuracy improved from 0.18290 to 0.19010, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1406 - loss: 3.6410 - val_accuracy: 0.1901 - val_loss: 3.3676 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1489 - loss: 3.5954{'accuracy': 0.14929135143756866, 'loss': 3.5907928943634033, 'val_accuracy': 0.19760000705718994, 'val_loss': 3.3265371322631836}\n\nEpoch 7: accuracy improved from 0.14214 to 0.14929, saving model to best_weights_v1.weights.h5\n\nEpoch 7: val_accuracy improved from 0.19010 to 0.19760, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1489 - loss: 3.5954 - val_accuracy: 0.1976 - val_loss: 3.3265 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m4054/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1545 - loss: 3.5574{'accuracy': 0.15495288372039795, 'loss': 3.5543837547302246, 'val_accuracy': 0.20469999313354492, 'val_loss': 3.304274559020996}\n\nEpoch 8: accuracy improved from 0.14929 to 0.15495, saving model to best_weights_v1.weights.h5\n\nEpoch 8: val_accuracy improved from 0.19760 to 0.20470, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1545 - loss: 3.5574 - val_accuracy: 0.2047 - val_loss: 3.3043 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1596 - loss: 3.5258{'accuracy': 0.16033846139907837, 'loss': 3.520068645477295, 'val_accuracy': 0.20730000734329224, 'val_loss': 3.2783796787261963}\n\nEpoch 9: accuracy improved from 0.15495 to 0.16034, saving model to best_weights_v1.weights.h5\n\nEpoch 9: val_accuracy improved from 0.20470 to 0.20730, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1596 - loss: 3.5257 - val_accuracy: 0.2073 - val_loss: 3.2784 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m4058/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1652 - loss: 3.4920{'accuracy': 0.16522404551506042, 'loss': 3.4902091026306152, 'val_accuracy': 0.20919999480247498, 'val_loss': 3.250671625137329}\n\nEpoch 10: accuracy improved from 0.16034 to 0.16522, saving model to best_weights_v1.weights.h5\n\nEpoch 10: val_accuracy improved from 0.20730 to 0.20920, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1652 - loss: 3.4920 - val_accuracy: 0.2092 - val_loss: 3.2507 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1686 - loss: 3.4679{'accuracy': 0.16971442103385925, 'loss': 3.460361957550049, 'val_accuracy': 0.2134000062942505, 'val_loss': 3.230043411254883}\n\nEpoch 11: accuracy improved from 0.16522 to 0.16971, saving model to best_weights_v1.weights.h5\n\nEpoch 11: val_accuracy improved from 0.20920 to 0.21340, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1686 - loss: 3.4679 - val_accuracy: 0.2134 - val_loss: 3.2300 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m4056/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1737 - loss: 3.4399{'accuracy': 0.17450480163097382, 'loss': 3.4341535568237305, 'val_accuracy': 0.21469999849796295, 'val_loss': 3.221534252166748}\n\nEpoch 12: accuracy improved from 0.16971 to 0.17450, saving model to best_weights_v1.weights.h5\n\nEpoch 12: val_accuracy improved from 0.21340 to 0.21470, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1737 - loss: 3.4399 - val_accuracy: 0.2147 - val_loss: 3.2215 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1788 - loss: 3.4112{'accuracy': 0.17871730029582977, 'loss': 3.408926010131836, 'val_accuracy': 0.22139999270439148, 'val_loss': 3.194838523864746}\n\nEpoch 13: accuracy improved from 0.17450 to 0.17872, saving model to best_weights_v1.weights.h5\n\nEpoch 13: val_accuracy improved from 0.21470 to 0.22140, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1788 - loss: 3.4112 - val_accuracy: 0.2214 - val_loss: 3.1948 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m4056/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1826 - loss: 3.3881{'accuracy': 0.18283461034297943, 'loss': 3.386110305786133, 'val_accuracy': 0.2231999933719635, 'val_loss': 3.188908576965332}\n\nEpoch 14: accuracy improved from 0.17872 to 0.18283, saving model to best_weights_v1.weights.h5\n\nEpoch 14: val_accuracy improved from 0.22140 to 0.22320, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1826 - loss: 3.3881 - val_accuracy: 0.2232 - val_loss: 3.1889 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m4059/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1853 - loss: 3.3672{'accuracy': 0.18607211112976074, 'loss': 3.3644473552703857, 'val_accuracy': 0.2305999994277954, 'val_loss': 3.170712471008301}\n\nEpoch 15: accuracy improved from 0.18283 to 0.18607, saving model to best_weights_v1.weights.h5\n\nEpoch 15: val_accuracy improved from 0.22320 to 0.23060, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1853 - loss: 3.3672 - val_accuracy: 0.2306 - val_loss: 3.1707 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m4051/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1893 - loss: 3.3481{'accuracy': 0.18976442515850067, 'loss': 3.3443562984466553, 'val_accuracy': 0.2337000072002411, 'val_loss': 3.1574723720550537}\n\nEpoch 16: accuracy improved from 0.18607 to 0.18976, saving model to best_weights_v1.weights.h5\n\nEpoch 16: val_accuracy improved from 0.23060 to 0.23370, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1893 - loss: 3.3481 - val_accuracy: 0.2337 - val_loss: 3.1575 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m4061/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1922 - loss: 3.3256{'accuracy': 0.19290095567703247, 'loss': 3.3251426219940186, 'val_accuracy': 0.23270000517368317, 'val_loss': 3.1414010524749756}\n\nEpoch 17: accuracy improved from 0.18976 to 0.19290, saving model to best_weights_v1.weights.h5\n\nEpoch 17: val_accuracy did not improve from 0.23370\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1922 - loss: 3.3256 - val_accuracy: 0.2327 - val_loss: 3.1414 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m4056/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1966 - loss: 3.3054{'accuracy': 0.19572114944458008, 'loss': 3.308032989501953, 'val_accuracy': 0.23720000684261322, 'val_loss': 3.1213815212249756}\n\nEpoch 18: accuracy improved from 0.19290 to 0.19572, saving model to best_weights_v1.weights.h5\n\nEpoch 18: val_accuracy improved from 0.23370 to 0.23720, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1966 - loss: 3.3054 - val_accuracy: 0.2372 - val_loss: 3.1214 - learning_rate: 1.0000e-04\nEpoch 19/50\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1984 - loss: 3.2907{'accuracy': 0.19874615967273712, 'loss': 3.2912826538085938, 'val_accuracy': 0.23430000245571136, 'val_loss': 3.122929573059082}\n\nEpoch 19: accuracy improved from 0.19572 to 0.19875, saving model to best_weights_v1.weights.h5\n\nEpoch 19: val_accuracy did not improve from 0.23720\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.1984 - loss: 3.2907 - val_accuracy: 0.2343 - val_loss: 3.1229 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m4058/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2011 - loss: 3.2737{'accuracy': 0.201328843832016, 'loss': 3.274559259414673, 'val_accuracy': 0.24199999868869781, 'val_loss': 3.1161882877349854}\n\nEpoch 20: accuracy improved from 0.19875 to 0.20133, saving model to best_weights_v1.weights.h5\n\nEpoch 20: val_accuracy improved from 0.23720 to 0.24200, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2011 - loss: 3.2737 - val_accuracy: 0.2420 - val_loss: 3.1162 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m4061/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2040 - loss: 3.2594{'accuracy': 0.2041826993227005, 'loss': 3.260171890258789, 'val_accuracy': 0.24490000307559967, 'val_loss': 3.1014323234558105}\n\nEpoch 21: accuracy improved from 0.20133 to 0.20418, saving model to best_weights_v1.weights.h5\n\nEpoch 21: val_accuracy improved from 0.24200 to 0.24490, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2040 - loss: 3.2594 - val_accuracy: 0.2449 - val_loss: 3.1014 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m4062/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2072 - loss: 3.2434{'accuracy': 0.2071894258260727, 'loss': 3.244523286819458, 'val_accuracy': 0.24449999630451202, 'val_loss': 3.0923373699188232}\n\nEpoch 22: accuracy improved from 0.20418 to 0.20719, saving model to best_weights_v1.weights.h5\n\nEpoch 22: val_accuracy did not improve from 0.24490\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2072 - loss: 3.2434 - val_accuracy: 0.2445 - val_loss: 3.0923 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m4051/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2095 - loss: 3.2290{'accuracy': 0.209203839302063, 'loss': 3.2298061847686768, 'val_accuracy': 0.24770000576972961, 'val_loss': 3.0934369564056396}\n\nEpoch 23: accuracy improved from 0.20719 to 0.20920, saving model to best_weights_v1.weights.h5\n\nEpoch 23: val_accuracy improved from 0.24490 to 0.24770, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2095 - loss: 3.2290 - val_accuracy: 0.2477 - val_loss: 3.0934 - learning_rate: 1.0000e-04\nEpoch 24/50\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2113 - loss: 3.2166{'accuracy': 0.2118692249059677, 'loss': 3.2169129848480225, 'val_accuracy': 0.2484000027179718, 'val_loss': 3.080650568008423}\n\nEpoch 24: accuracy improved from 0.20920 to 0.21187, saving model to best_weights_v1.weights.h5\n\nEpoch 24: val_accuracy improved from 0.24770 to 0.24840, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2113 - loss: 3.2166 - val_accuracy: 0.2484 - val_loss: 3.0807 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m4053/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2145 - loss: 3.2036{'accuracy': 0.2142682671546936, 'loss': 3.2038304805755615, 'val_accuracy': 0.2484000027179718, 'val_loss': 3.090993642807007}\n\nEpoch 25: accuracy improved from 0.21187 to 0.21427, saving model to best_weights_v1.weights.h5\n\nEpoch 25: val_accuracy did not improve from 0.24840\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2145 - loss: 3.2036 - val_accuracy: 0.2484 - val_loss: 3.0910 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m4054/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2167 - loss: 3.1904{'accuracy': 0.21639615297317505, 'loss': 3.1918158531188965, 'val_accuracy': 0.25040000677108765, 'val_loss': 3.0686426162719727}\n\nEpoch 26: accuracy improved from 0.21427 to 0.21640, saving model to best_weights_v1.weights.h5\n\nEpoch 26: val_accuracy improved from 0.24840 to 0.25040, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2167 - loss: 3.1904 - val_accuracy: 0.2504 - val_loss: 3.0686 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m4051/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2191 - loss: 3.1757{'accuracy': 0.2187182754278183, 'loss': 3.1784543991088867, 'val_accuracy': 0.2558000087738037, 'val_loss': 3.048847198486328}\n\nEpoch 27: accuracy improved from 0.21640 to 0.21872, saving model to best_weights_v1.weights.h5\n\nEpoch 27: val_accuracy improved from 0.25040 to 0.25580, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2191 - loss: 3.1757 - val_accuracy: 0.2558 - val_loss: 3.0488 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2204 - loss: 3.1654{'accuracy': 0.22003653645515442, 'loss': 3.167757034301758, 'val_accuracy': 0.2515999972820282, 'val_loss': 3.0643703937530518}\n\nEpoch 28: accuracy improved from 0.21872 to 0.22004, saving model to best_weights_v1.weights.h5\n\nEpoch 28: val_accuracy did not improve from 0.25580\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2204 - loss: 3.1654 - val_accuracy: 0.2516 - val_loss: 3.0644 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m4054/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2224 - loss: 3.1562{'accuracy': 0.22203364968299866, 'loss': 3.157687187194824, 'val_accuracy': 0.259799987077713, 'val_loss': 3.045273542404175}\n\nEpoch 29: accuracy improved from 0.22004 to 0.22203, saving model to best_weights_v1.weights.h5\n\nEpoch 29: val_accuracy improved from 0.25580 to 0.25980, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2224 - loss: 3.1562 - val_accuracy: 0.2598 - val_loss: 3.0453 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m4054/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2253 - loss: 3.1460{'accuracy': 0.2250211536884308, 'loss': 3.145941734313965, 'val_accuracy': 0.26019999384880066, 'val_loss': 3.0418992042541504}\n\nEpoch 30: accuracy improved from 0.22203 to 0.22502, saving model to best_weights_v1.weights.h5\n\nEpoch 30: val_accuracy improved from 0.25980 to 0.26020, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2253 - loss: 3.1460 - val_accuracy: 0.2602 - val_loss: 3.0419 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2272 - loss: 3.1343{'accuracy': 0.22594903409481049, 'loss': 3.1378612518310547, 'val_accuracy': 0.2614000141620636, 'val_loss': 3.0268731117248535}\n\nEpoch 31: accuracy improved from 0.22502 to 0.22595, saving model to best_weights_v1.weights.h5\n\nEpoch 31: val_accuracy improved from 0.26020 to 0.26140, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2272 - loss: 3.1343 - val_accuracy: 0.2614 - val_loss: 3.0269 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m4057/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2289 - loss: 3.1259{'accuracy': 0.22820672392845154, 'loss': 3.1268746852874756, 'val_accuracy': 0.26019999384880066, 'val_loss': 3.030858039855957}\n\nEpoch 32: accuracy improved from 0.22595 to 0.22821, saving model to best_weights_v1.weights.h5\n\nEpoch 32: val_accuracy did not improve from 0.26140\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2289 - loss: 3.1259 - val_accuracy: 0.2602 - val_loss: 3.0309 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m4059/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2301 - loss: 3.1159{'accuracy': 0.22953461110591888, 'loss': 3.117340326309204, 'val_accuracy': 0.26080000400543213, 'val_loss': 3.029311418533325}\n\nEpoch 33: accuracy improved from 0.22821 to 0.22953, saving model to best_weights_v1.weights.h5\n\nEpoch 33: val_accuracy did not improve from 0.26140\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2301 - loss: 3.1159 - val_accuracy: 0.2608 - val_loss: 3.0293 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2318 - loss: 3.1032{'accuracy': 0.2317173033952713, 'loss': 3.1073386669158936, 'val_accuracy': 0.2635999917984009, 'val_loss': 3.016364336013794}\n\nEpoch 34: accuracy improved from 0.22953 to 0.23172, saving model to best_weights_v1.weights.h5\n\nEpoch 34: val_accuracy improved from 0.26140 to 0.26360, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2318 - loss: 3.1033 - val_accuracy: 0.2636 - val_loss: 3.0164 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2328 - loss: 3.0981{'accuracy': 0.23322884738445282, 'loss': 3.0999927520751953, 'val_accuracy': 0.26429998874664307, 'val_loss': 3.037108898162842}\n\nEpoch 35: accuracy improved from 0.23172 to 0.23323, saving model to best_weights_v1.weights.h5\n\nEpoch 35: val_accuracy improved from 0.26360 to 0.26430, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2328 - loss: 3.0981 - val_accuracy: 0.2643 - val_loss: 3.0371 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m4056/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2351 - loss: 3.0877{'accuracy': 0.2343798130750656, 'loss': 3.090210437774658, 'val_accuracy': 0.2671999931335449, 'val_loss': 3.022080898284912}\n\nEpoch 36: accuracy improved from 0.23323 to 0.23438, saving model to best_weights_v1.weights.h5\n\nEpoch 36: val_accuracy improved from 0.26430 to 0.26720, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2351 - loss: 3.0877 - val_accuracy: 0.2672 - val_loss: 3.0221 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m4059/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2368 - loss: 3.0801{'accuracy': 0.2359105795621872, 'loss': 3.0823817253112793, 'val_accuracy': 0.25999999046325684, 'val_loss': 3.0333802700042725}\n\nEpoch 37: accuracy improved from 0.23438 to 0.23591, saving model to best_weights_v1.weights.h5\n\nEpoch 37: val_accuracy did not improve from 0.26720\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2368 - loss: 3.0802 - val_accuracy: 0.2600 - val_loss: 3.0334 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2387 - loss: 3.0677{'accuracy': 0.23763366043567657, 'loss': 3.074117422103882, 'val_accuracy': 0.2671000063419342, 'val_loss': 3.0155537128448486}\n\nEpoch 38: accuracy improved from 0.23591 to 0.23763, saving model to best_weights_v1.weights.h5\n\nEpoch 38: val_accuracy did not improve from 0.26720\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2387 - loss: 3.0677 - val_accuracy: 0.2671 - val_loss: 3.0156 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m4058/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2392 - loss: 3.0631{'accuracy': 0.23874038457870483, 'loss': 3.0661840438842773, 'val_accuracy': 0.2653999924659729, 'val_loss': 3.0118954181671143}\n\nEpoch 39: accuracy improved from 0.23763 to 0.23874, saving model to best_weights_v1.weights.h5\n\nEpoch 39: val_accuracy did not improve from 0.26720\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2391 - loss: 3.0631 - val_accuracy: 0.2654 - val_loss: 3.0119 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2409 - loss: 3.0561{'accuracy': 0.24034038186073303, 'loss': 3.0597825050354004, 'val_accuracy': 0.2660999894142151, 'val_loss': 3.0121450424194336}\n\nEpoch 40: accuracy improved from 0.23874 to 0.24034, saving model to best_weights_v1.weights.h5\n\nEpoch 40: val_accuracy did not improve from 0.26720\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2409 - loss: 3.0561 - val_accuracy: 0.2661 - val_loss: 3.0121 - learning_rate: 1.0000e-04\nEpoch 41/50\n\u001b[1m4056/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2418 - loss: 3.0491{'accuracy': 0.24110865592956543, 'loss': 3.0519213676452637, 'val_accuracy': 0.2653999924659729, 'val_loss': 3.014200448989868}\n\nEpoch 41: accuracy improved from 0.24034 to 0.24111, saving model to best_weights_v1.weights.h5\n\nEpoch 41: val_accuracy did not improve from 0.26720\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2418 - loss: 3.0491 - val_accuracy: 0.2654 - val_loss: 3.0142 - learning_rate: 1.0000e-04\nEpoch 42/50\n\u001b[1m4060/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2422 - loss: 3.0431{'accuracy': 0.24232885241508484, 'loss': 3.0442347526550293, 'val_accuracy': 0.2676999866962433, 'val_loss': 3.007519245147705}\n\nEpoch 42: accuracy improved from 0.24111 to 0.24233, saving model to best_weights_v1.weights.h5\n\nEpoch 42: val_accuracy improved from 0.26720 to 0.26770, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2422 - loss: 3.0431 - val_accuracy: 0.2677 - val_loss: 3.0075 - learning_rate: 1.0000e-04\nEpoch 43/50\n\u001b[1m4059/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2446 - loss: 3.0348{'accuracy': 0.24376443028450012, 'loss': 3.0388615131378174, 'val_accuracy': 0.26919999718666077, 'val_loss': 2.99176025390625}\n\nEpoch 43: accuracy improved from 0.24233 to 0.24376, saving model to best_weights_v1.weights.h5\n\nEpoch 43: val_accuracy improved from 0.26770 to 0.26920, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2446 - loss: 3.0348 - val_accuracy: 0.2692 - val_loss: 2.9918 - learning_rate: 1.0000e-04\nEpoch 44/50\n\u001b[1m4056/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2453 - loss: 3.0311{'accuracy': 0.24479134380817413, 'loss': 3.0326783657073975, 'val_accuracy': 0.2687000036239624, 'val_loss': 3.0019917488098145}\n\nEpoch 44: accuracy improved from 0.24376 to 0.24479, saving model to best_weights_v1.weights.h5\n\nEpoch 44: val_accuracy did not improve from 0.26920\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2453 - loss: 3.0311 - val_accuracy: 0.2687 - val_loss: 3.0020 - learning_rate: 1.0000e-04\nEpoch 45/50\n\u001b[1m4058/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2471 - loss: 3.0214{'accuracy': 0.24658942222595215, 'loss': 3.024623394012451, 'val_accuracy': 0.2696000039577484, 'val_loss': 2.997249126434326}\n\nEpoch 45: accuracy improved from 0.24479 to 0.24659, saving model to best_weights_v1.weights.h5\n\nEpoch 45: val_accuracy improved from 0.26920 to 0.26960, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2471 - loss: 3.0214 - val_accuracy: 0.2696 - val_loss: 2.9972 - learning_rate: 1.0000e-04\nEpoch 46/50\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2480 - loss: 3.0147{'accuracy': 0.24729423224925995, 'loss': 3.018718957901001, 'val_accuracy': 0.26910001039505005, 'val_loss': 3.0023322105407715}\n\nEpoch 46: accuracy improved from 0.24659 to 0.24729, saving model to best_weights_v1.weights.h5\n\nEpoch 46: val_accuracy did not improve from 0.26960\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2480 - loss: 3.0147 - val_accuracy: 0.2691 - val_loss: 3.0023 - learning_rate: 1.0000e-04\nEpoch 47/50\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2488 - loss: 3.0144{'accuracy': 0.24873173236846924, 'loss': 3.015348434448242, 'val_accuracy': 0.26930001378059387, 'val_loss': 3.0004780292510986}\n\nEpoch 47: accuracy improved from 0.24729 to 0.24873, saving model to best_weights_v1.weights.h5\n\nEpoch 47: val_accuracy did not improve from 0.26960\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2488 - loss: 3.0144 - val_accuracy: 0.2693 - val_loss: 3.0005 - learning_rate: 1.0000e-04\nEpoch 48/50\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2501 - loss: 3.0022{'accuracy': 0.24999038875102997, 'loss': 3.0078256130218506, 'val_accuracy': 0.27149999141693115, 'val_loss': 2.9844093322753906}\n\nEpoch 48: accuracy improved from 0.24873 to 0.24999, saving model to best_weights_v1.weights.h5\n\nEpoch 48: val_accuracy improved from 0.26960 to 0.27150, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2501 - loss: 3.0022 - val_accuracy: 0.2715 - val_loss: 2.9844 - learning_rate: 1.0000e-04\nEpoch 49/50\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2505 - loss: 3.0001{'accuracy': 0.25020864605903625, 'loss': 3.00262713432312, 'val_accuracy': 0.27390000224113464, 'val_loss': 2.988661050796509}\n\nEpoch 49: accuracy improved from 0.24999 to 0.25021, saving model to best_weights_v1.weights.h5\n\nEpoch 49: val_accuracy improved from 0.27150 to 0.27390, saving model to best_weights_v2.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2505 - loss: 3.0001 - val_accuracy: 0.2739 - val_loss: 2.9887 - learning_rate: 1.0000e-04\nEpoch 50/50\n\u001b[1m4051/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2517 - loss: 2.9956{'accuracy': 0.2514423131942749, 'loss': 2.997481346130371, 'val_accuracy': 0.27239999175071716, 'val_loss': 2.983220338821411}\n\nEpoch 50: accuracy improved from 0.25021 to 0.25144, saving model to best_weights_v1.weights.h5\n\nEpoch 50: val_accuracy did not improve from 0.27390\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.2517 - loss: 2.9956 - val_accuracy: 0.2724 - val_loss: 2.9832 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 49.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### MODELO 2","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.regularizers import l2","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:19:20.382885Z","iopub.execute_input":"2024-10-28T17:19:20.383251Z","iopub.status.idle":"2024-10-28T17:19:20.387696Z","shell.execute_reply.started":"2024-10-28T17:19:20.383215Z","shell.execute_reply":"2024-10-28T17:19:20.386864Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\n\n#OTRA ESTRUCTURA\n# Entrada y normalización\ninput_layer = Input(shape=(32, 32, 3), name=\"matrix_input\")\n\n# Estructura de la red\nx = BatchNormalization(axis=-1, name=\"normalization_layer\")(input_layer)\nflatten_layer = Flatten(name=\"flattened_input\")(x)\n\n\n# Ajustes de las capas ocultas y Dropout con regularización l2\ndense_1024 = Dense(1024, activation='relu', kernel_regularizer=l2(0.01), name=\"dense_1024\")(flatten_layer)\ndropout_1024 = Dropout(0.3)(dense_1024)\ndense_512 = Dense(512, activation='relu', kernel_regularizer=l2(0.01), name=\"dense_512\")(dropout_1024)\ndropout_512 = Dropout(0.2)(dense_512)\ndense_256 = Dense(256, activation='relu', kernel_regularizer=l2(0.01), name=\"dense_256\")(dropout_512)\ndropout_256 = Dropout(0.2)(dense_256)\ndense_128 = Dense(128, activation='relu', kernel_regularizer=l2(0.01), name=\"dense_128\")(dropout_256)\ndense_64 = Dense(64, activation='relu', name=\"dense_64\")(dense_128)\n\n# Salida\nfine_output = Dense(100, activation='softmax', name='fine_output')(dense_64)\n\n# Modelo\nmyModel = Model(inputs=input_layer, outputs=[fine_output])\n\n# Print model summary\nmyModel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:19:21.496027Z","iopub.execute_input":"2024-10-28T17:19:21.496397Z","iopub.status.idle":"2024-10-28T17:19:22.463557Z","shell.execute_reply.started":"2024-10-28T17:19:21.496361Z","shell.execute_reply":"2024-10-28T17:19:22.462606Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ matrix_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ normalization_layer             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │            \u001b[38;5;34m12\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flattened_input (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1024 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m3,146,752\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_512 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_256 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_128 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m6,500\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ matrix_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ normalization_layer             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flattened_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1024 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,146,752</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_512 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_256 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,850,544\u001b[0m (14.69 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,544</span> (14.69 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,850,538\u001b[0m (14.69 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,538</span> (14.69 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Shuffle de los datos\nindexes_train   = np.arange(len(x_train))\nindexes_test    = np.arange(len(x_test))\n\nnp.random.shuffle(indexes_train)\nnp.random.shuffle(indexes_test)\n\n# Shuffle de datos de train\n\nx_train_dup         = x_train[indexes_train]\ny_train_coarse_dup  = y_train_coarse[indexes_train]\ny_train_fine_dup    = y_train_fine[indexes_train]\n\n# Shuffle de datos de test\nx_test_dup         = x_test[indexes_test]\ny_test_coarse_dup  = y_test_coarse[indexes_test]\ny_test_fine_dup    = y_test_fine[indexes_test]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:19:25.955341Z","iopub.execute_input":"2024-10-28T17:19:25.956086Z","iopub.status.idle":"2024-10-28T17:19:27.070403Z","shell.execute_reply.started":"2024-10-28T17:19:25.956045Z","shell.execute_reply":"2024-10-28T17:19:27.069611Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard, LambdaCallback\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:19:30.083090Z","iopub.execute_input":"2024-10-28T17:19:30.083433Z","iopub.status.idle":"2024-10-28T17:19:30.087954Z","shell.execute_reply.started":"2024-10-28T17:19:30.083400Z","shell.execute_reply":"2024-10-28T17:19:30.086991Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Scheduler para el Learning Rate\ninitial_learning_rate = 1e-4\nlr_schedule = ExponentialDecay(\n    initial_learning_rate, decay_steps=10000, decay_rate=0.9, staircase=True\n)\n\n\nrlrop = ReduceLROnPlateau(\n    monitor = \"val_accuracy\",\n    factor = 0.5,\n    patience = 3,\n    verbose = 1,\n    min_lr = 1e-6\n)\n\nes = EarlyStopping(\n    monitor = \"val_accuracy\",\n    patience = 10,\n    verbose = 1,\n    restore_best_weights = True\n)\n\n\nrlrop2 = ReduceLROnPlateau(\n    monitor = \"accuracy\",\n    factor = 0.2,\n    patience = 5,\n    verbose = 1,\n    min_lr = 1e-6\n)\n\nes2 = EarlyStopping(\n    monitor = \"accuracy\",\n    patience = 10,\n    verbose = 1,\n    restore_best_weights = True\n)\n\nmc2 = ModelCheckpoint(\n    \"best_weights.weights.h5\",\n    monitor = \"accuracy\",\n    verbose = 1,\n    save_best_only = True,\n    save_weights_only = True,\n\n)\n\nmc = ModelCheckpoint(\n    \"best_weights.weights.h5\",\n    monitor = \"val_accuracy\",\n    verbose = 1,\n    save_best_only = True,\n    save_weights_only = True,\n\n)\n\n\n\ntb = TensorBoard(\n    log_dir = \"logs\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:21:27.640431Z","iopub.execute_input":"2024-10-28T17:21:27.640817Z","iopub.status.idle":"2024-10-28T17:21:27.649788Z","shell.execute_reply.started":"2024-10-28T17:21:27.640781Z","shell.execute_reply":"2024-10-28T17:21:27.648694Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"myModel.compile(\n    optimizer               = Adam(learning_rate=lr_schedule),\n    #loss                    = {'fine_output': 'sparse_categorical_crossentropy', 'coarse_output': 'sparse_categorical_crossentropy'},\n    loss                    = {'fine_output': 'sparse_categorical_crossentropy'},\n    loss_weights            = None,\n    #metrics                 = {'fine_output': 'categorical_accuracy', 'coarse_output': 'categorical_accuracy'},\n    metrics                 = {'fine_output': 'accuracy'},\n    weighted_metrics        = None,\n    run_eagerly             = False,\n    steps_per_execution     = 1,\n    jit_compile             = \"auto\",\n    auto_scale_loss         = True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:21:31.218717Z","iopub.execute_input":"2024-10-28T17:21:31.219644Z","iopub.status.idle":"2024-10-28T17:21:31.232104Z","shell.execute_reply.started":"2024-10-28T17:21:31.219581Z","shell.execute_reply":"2024-10-28T17:21:31.230940Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"history2 = myModel.fit(\n    x                       = x_train_dup,\n    y                       = {'fine_output': y_train_fine_dup},\n    batch_size              = 256,\n    epochs                  = 50,\n    verbose                 = \"auto\",\n    callbacks               = [LambdaCallback(on_epoch_end=lambda epoch, logs: print(logs if logs is not None else \"No logs available\")),rlrop,es,mc2,mc],\n    validation_split        = 0.0,\n    validation_data         = (x_test_dup, {'fine_output': y_test_fine_dup}),\n    shuffle                 = True,\n    class_weight            = None,\n    sample_weight           = None,\n    initial_epoch           = 0,\n    steps_per_epoch         = None,\n    validation_steps        = None,\n    validation_batch_size   = None,\n    validation_freq         = 1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:21:34.174608Z","iopub.execute_input":"2024-10-28T17:21:34.175281Z","iopub.status.idle":"2024-10-28T17:23:41.101741Z","shell.execute_reply.started":"2024-10-28T17:21:34.175243Z","shell.execute_reply":"2024-10-28T17:23:41.099992Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730136103.363549     119 service.cc:145] XLA service 0x7e2a7c8b50a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730136103.363613     119 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730136103.363617     119 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  27/4063\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - accuracy: 0.0089 - loss: 31.4053","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1730136109.813902     119 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0405 - loss: 9.9476{'accuracy': 0.053404808044433594, 'loss': 5.980325222015381, 'val_accuracy': 0.08089999854564667, 'val_loss': 4.147796630859375}\n\nEpoch 1: accuracy improved from -inf to 0.05340, saving model to best_weights.weights.h5\n\nEpoch 1: val_accuracy improved from -inf to 0.08090, saving model to best_weights.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 6ms/step - accuracy: 0.0405 - loss: 9.9466 - val_accuracy: 0.0809 - val_loss: 4.1478 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m4051/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0686 - loss: 4.2481{'accuracy': 0.07013557851314545, 'loss': 4.230656147003174, 'val_accuracy': 0.093299999833107, 'val_loss': 4.054381847381592}\n\nEpoch 2: accuracy improved from 0.05340 to 0.07014, saving model to best_weights.weights.h5\n\nEpoch 2: val_accuracy improved from 0.08090 to 0.09330, saving model to best_weights.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.0686 - loss: 4.2480 - val_accuracy: 0.0933 - val_loss: 4.0544 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m4055/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0738 - loss: 4.1921{'accuracy': 0.07510577142238617, 'loss': 4.184003829956055, 'val_accuracy': 0.09539999812841415, 'val_loss': 4.000469207763672}\n\nEpoch 3: accuracy improved from 0.07014 to 0.07511, saving model to best_weights.weights.h5\n\nEpoch 3: val_accuracy improved from 0.09330 to 0.09540, saving model to best_weights.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.0739 - loss: 4.1920 - val_accuracy: 0.0954 - val_loss: 4.0005 - learning_rate: 9.0000e-05\nEpoch 4/50\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0786 - loss: 4.1568{'accuracy': 0.07960288226604462, 'loss': 4.148836612701416, 'val_accuracy': 0.1031000018119812, 'val_loss': 3.954038381576538}\n\nEpoch 4: accuracy improved from 0.07511 to 0.07960, saving model to best_weights.weights.h5\n\nEpoch 4: val_accuracy improved from 0.09540 to 0.10310, saving model to best_weights.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.0786 - loss: 4.1568 - val_accuracy: 0.1031 - val_loss: 3.9540 - learning_rate: 9.0000e-05\nEpoch 5/50\n\u001b[1m4052/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0832 - loss: 4.1239{'accuracy': 0.08451154083013535, 'loss': 4.117427349090576, 'val_accuracy': 0.10939999669790268, 'val_loss': 3.927964925765991}\n\nEpoch 5: accuracy improved from 0.07960 to 0.08451, saving model to best_weights.weights.h5\n\nEpoch 5: val_accuracy improved from 0.10310 to 0.10940, saving model to best_weights.weights.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.0833 - loss: 4.1239 - val_accuracy: 0.1094 - val_loss: 3.9280 - learning_rate: 8.1000e-05\nEpoch 6/50\n\u001b[1m4058/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0876 - loss: 4.1001{'accuracy': 0.08835769444704056, 'loss': 4.093389511108398, 'val_accuracy': 0.11630000174045563, 'val_loss': 3.9018712043762207}\n\nEpoch 6: accuracy improved from 0.08451 to 0.08836, saving model to best_weights.weights.h5\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history2 \u001b[38;5;241m=\u001b[39m \u001b[43mmyModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_train_dup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfine_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fine_dup\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mLambdaCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_epoch_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNo logs available\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrlrop\u001b[49m\u001b[43m,\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_dup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfine_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_fine_dup\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:354\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    349\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    351\u001b[0m     }\n\u001b[1;32m    352\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[0;32m--> 354\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks/callback_list.py:96\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     94\u001b[0m logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m---> 96\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks/model_checkpoint.py:206\u001b[0m, in \u001b[0;36mModelCheckpoint.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 206\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks/model_checkpoint.py:271\u001b[0m, in \u001b[0;36mModelCheckpoint._save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest \u001b[38;5;241m=\u001b[39m current\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_weights_only:\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave(filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/model.py:318\u001b[0m, in \u001b[0;36mModel.save_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    309\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Saves all layer weights to a `.weights.h5` file.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m            via an interactive prompt.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_api.py:223\u001b[0m, in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proceed:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:229\u001b[0m, in \u001b[0;36msave_weights_only\u001b[0;34m(model, filepath, objects_to_skip)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     visited_saveables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 229\u001b[0m \u001b[43m_save_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43massets_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisited_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m weights_store\u001b[38;5;241m.\u001b[39mclose()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:374\u001b[0m, in \u001b[0;36m_save_state\u001b[0;34m(saveable, weights_store, assets_store, inner_path, visited_saveables)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_attr, child_obj \u001b[38;5;129;01min\u001b[39;00m _walk_saveable(saveable):\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child_obj, KerasSaveable):\n\u001b[0;32m--> 374\u001b[0m         \u001b[43m_save_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchild_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m            \u001b[49m\u001b[43massets_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m            \u001b[49m\u001b[43minner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_attr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvisited_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child_obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mset\u001b[39m)):\n\u001b[1;32m    384\u001b[0m         _save_container_state(\n\u001b[1;32m    385\u001b[0m             child_obj,\n\u001b[1;32m    386\u001b[0m             weights_store,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m             visited_saveables\u001b[38;5;241m=\u001b[39mvisited_saveables,\n\u001b[1;32m    392\u001b[0m         )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:365\u001b[0m, in \u001b[0;36m_save_state\u001b[0;34m(saveable, weights_store, assets_store, inner_path, visited_saveables)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(saveable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_own_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m weights_store:\n\u001b[0;32m--> 365\u001b[0m     \u001b[43msaveable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_own_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(saveable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_assets\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m assets_store:\n\u001b[1;32m    367\u001b[0m     saveable\u001b[38;5;241m.\u001b[39msave_assets(assets_store\u001b[38;5;241m.\u001b[39mmake(inner_path))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:565\u001b[0m, in \u001b[0;36mBaseOptimizer.save_own_variables\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the state of this optimizer object.\"\"\"\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, variable \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables):\n\u001b[0;32m--> 565\u001b[0m     \u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mnumpy()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:700\u001b[0m, in \u001b[0;36mH5Entry.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    698\u001b[0m     ds\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/group.py:483\u001b[0m, in \u001b[0;36mGroup.__setitem__\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    480\u001b[0m     htype\u001b[38;5;241m.\u001b[39mcommit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, name, lcpl\u001b[38;5;241m=\u001b[39mlcpl)\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 483\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m     h5o\u001b[38;5;241m.\u001b[39mlink(ds\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, name, lcpl\u001b[38;5;241m=\u001b[39mlcpl)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/dataset.py:166\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[1;32m    163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m h5d\u001b[38;5;241m.\u001b[39mcreate(parent\u001b[38;5;241m.\u001b[39mid, name, tid, sid, dcpl\u001b[38;5;241m=\u001b[39mdcpl, dapl\u001b[38;5;241m=\u001b[39mdapl)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m--> 166\u001b[0m     \u001b[43mdset_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh5s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset_id\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}